<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0ebf6b2290db55dbf2d10cc49655523b",
  "translation_date": "2025-09-30T06:20:54+00:00",
  "source_file": "05-agentic-rag/README.md",
  "language_code": "fa"
}
-->
[![Agentic RAG](../../../translated_images/fa/lesson-5-thumbnail.20ba9d0c0ae64fae.webp)](https://youtu.be/WcjAARvdL7I?si=BCgwjwFb2yCkEhR9)

> _(برای مشاهده ویدئوی این درس، روی تصویر بالا کلیک کنید)_

# Agentic RAG

این درس یک مرور جامع از "تولید مبتنی بر بازیابی عامل‌محور" (Agentic Retrieval-Augmented Generation یا Agentic RAG) ارائه می‌دهد، یک پارادایم نوظهور در هوش مصنوعی که در آن مدل‌های زبانی بزرگ (LLMs) به صورت خودکار مراحل بعدی خود را برنامه‌ریزی می‌کنند و اطلاعات را از منابع خارجی استخراج می‌کنند. برخلاف الگوهای ایستا مانند "بازیابی-سپس-خواندن"، Agentic RAG شامل تماس‌های تکراری با LLM است که با استفاده از ابزارها یا توابع و خروجی‌های ساختاریافته همراه می‌شود. سیستم نتایج را ارزیابی می‌کند، پرسش‌ها را اصلاح می‌کند، در صورت نیاز ابزارهای اضافی را فراخوانی می‌کند و این چرخه را تا رسیدن به یک راه‌حل رضایت‌بخش ادامه می‌دهد.

## مقدمه

این درس شامل موارد زیر خواهد بود:

- **درک Agentic RAG:** آشنایی با پارادایم نوظهور در هوش مصنوعی که در آن مدل‌های زبانی بزرگ (LLMs) به صورت خودکار مراحل بعدی خود را برنامه‌ریزی می‌کنند و اطلاعات را از منابع داده خارجی استخراج می‌کنند.
- **سبک تکراری Maker-Checker:** فهم چرخه تماس‌های تکراری با LLM که با استفاده از ابزارها یا توابع و خروجی‌های ساختاریافته همراه است، طراحی شده برای بهبود صحت و مدیریت پرسش‌های ناقص.
- **بررسی کاربردهای عملی:** شناسایی سناریوهایی که Agentic RAG در آن‌ها برجسته است، مانند محیط‌های مبتنی بر صحت، تعاملات پیچیده با پایگاه‌های داده و جریان‌های کاری طولانی‌مدت.

## اهداف یادگیری

پس از تکمیل این درس، شما قادر خواهید بود:

- **درک Agentic RAG:** آشنایی با پارادایم نوظهور در هوش مصنوعی که در آن مدل‌های زبانی بزرگ (LLMs) به صورت خودکار مراحل بعدی خود را برنامه‌ریزی می‌کنند و اطلاعات را از منابع داده خارجی استخراج می‌کنند.
- **سبک تکراری Maker-Checker:** فهم مفهوم چرخه تماس‌های تکراری با LLM که با استفاده از ابزارها یا توابع و خروجی‌های ساختاریافته همراه است، طراحی شده برای بهبود صحت و مدیریت پرسش‌های ناقص.
- **مالکیت فرآیند استدلال:** درک توانایی سیستم در مالکیت فرآیند استدلال خود، تصمیم‌گیری در مورد نحوه برخورد با مشکلات بدون تکیه بر مسیرهای از پیش تعریف‌شده.
- **جریان کاری:** فهم اینکه چگونه یک مدل عامل‌محور به صورت مستقل تصمیم می‌گیرد گزارش‌های روند بازار را بازیابی کند، داده‌های رقبا را شناسایی کند، معیارهای فروش داخلی را مرتبط کند، یافته‌ها را ترکیب کند و استراتژی را ارزیابی کند.
- **چرخه‌های تکراری، یکپارچه‌سازی ابزار و حافظه:** آشنایی با وابستگی سیستم به الگوی تعامل چرخه‌ای، حفظ حالت و حافظه در مراحل مختلف برای جلوگیری از چرخه‌های تکراری و اتخاذ تصمیمات آگاهانه.
- **مدیریت حالت‌های شکست و خودتصحیح:** بررسی مکانیسم‌های خودتصحیح قوی سیستم، از جمله تکرار و پرسش مجدد، استفاده از ابزارهای تشخیصی و بازگشت به نظارت انسانی.
- **مرزهای عامل‌محوری:** درک محدودیت‌های Agentic RAG، تمرکز بر خودمختاری خاص دامنه، وابستگی به زیرساخت‌ها و احترام به محدودیت‌ها.
- **موارد استفاده عملی و ارزش:** شناسایی سناریوهایی که Agentic RAG در آن‌ها برجسته است، مانند محیط‌های مبتنی بر صحت، تعاملات پیچیده با پایگاه‌های داده و جریان‌های کاری طولانی‌مدت.
- **حاکمیت، شفافیت و اعتماد:** آشنایی با اهمیت حاکمیت و شفافیت، از جمله استدلال قابل توضیح، کنترل تعصب و نظارت انسانی.

## Agentic RAG چیست؟

"تولید مبتنی بر بازیابی عامل‌محور" (Agentic Retrieval-Augmented Generation یا Agentic RAG) یک پارادایم نوظهور در هوش مصنوعی است که در آن مدل‌های زبانی بزرگ (LLMs) به صورت خودکار مراحل بعدی خود را برنامه‌ریزی می‌کنند و اطلاعات را از منابع خارجی استخراج می‌کنند. برخلاف الگوهای ایستا مانند "بازیابی-سپس-خواندن"، Agentic RAG شامل تماس‌های تکراری با LLM است که با استفاده از ابزارها یا توابع و خروجی‌های ساختاریافته همراه می‌شود. سیستم نتایج را ارزیابی می‌کند، پرسش‌ها را اصلاح می‌کند، در صورت نیاز ابزارهای اضافی را فراخوانی می‌کند و این چرخه را تا رسیدن به یک راه‌حل رضایت‌بخش ادامه می‌دهد. این سبک تکراری "سازنده-بازبین" برای بهبود صحت، مدیریت پرسش‌های ناقص و تضمین نتایج با کیفیت بالا طراحی شده است.

سیستم به صورت فعال مالکیت فرآیند استدلال خود را بر عهده می‌گیرد، پرسش‌های ناموفق را بازنویسی می‌کند، روش‌های بازیابی مختلف را انتخاب می‌کند و ابزارهای متعددی مانند جستجوی برداری در Azure AI Search، پایگاه‌های داده SQL یا API‌های سفارشی را یکپارچه می‌کند تا پاسخ نهایی خود را ارائه دهد. ویژگی متمایز یک سیستم عامل‌محور توانایی آن در مالکیت فرآیند استدلال خود است. پیاده‌سازی‌های سنتی RAG به مسیرهای از پیش تعریف‌شده متکی هستند، اما یک سیستم عامل‌محور به صورت خودکار ترتیب مراحل را بر اساس کیفیت اطلاعاتی که پیدا می‌کند تعیین می‌کند.

## تعریف "تولید مبتنی بر بازیابی عامل‌محور" (Agentic RAG)

"تولید مبتنی بر بازیابی عامل‌محور" (Agentic Retrieval-Augmented Generation یا Agentic RAG) یک پارادایم نوظهور در توسعه هوش مصنوعی است که در آن مدل‌های زبانی بزرگ (LLMs) نه تنها اطلاعات را از منابع داده خارجی استخراج می‌کنند، بلکه به صورت خودکار مراحل بعدی خود را برنامه‌ریزی می‌کنند. برخلاف الگوهای ایستا مانند "بازیابی-سپس-خواندن" یا دنباله‌های پرسش‌نامه‌ای دقیق، Agentic RAG شامل چرخه تماس‌های تکراری با LLM است که با استفاده از ابزارها یا توابع و خروجی‌های ساختاریافته همراه می‌شود. در هر مرحله، سیستم نتایج به دست آمده را ارزیابی می‌کند، تصمیم می‌گیرد که آیا پرسش‌ها را اصلاح کند، ابزارهای اضافی را فراخوانی کند و این چرخه را تا رسیدن به یک راه‌حل رضایت‌بخش ادامه می‌دهد.

این سبک تکراری "سازنده-بازبین" برای بهبود صحت، مدیریت پرسش‌های ناقص به پایگاه‌های داده ساختاریافته (مانند NL2SQL) و تضمین نتایج متعادل و با کیفیت بالا طراحی شده است. به جای تکیه بر زنجیره‌های پرسش‌نامه‌ای پیچیده، سیستم به صورت فعال مالکیت فرآیند استدلال خود را بر عهده می‌گیرد. این سیستم می‌تواند پرسش‌های ناموفق را بازنویسی کند، روش‌های بازیابی مختلف را انتخاب کند و ابزارهای متعددی مانند جستجوی برداری در Azure AI Search، پایگاه‌های داده SQL یا API‌های سفارشی را یکپارچه کند تا پاسخ نهایی خود را ارائه دهد. این امر نیاز به چارچوب‌های ارکستراسیون پیچیده را از بین می‌برد. در عوض، یک چرخه نسبتاً ساده از "تماس با LLM → استفاده از ابزار → تماس با LLM → ..." می‌تواند خروجی‌های پیچیده و مستدل ارائه دهد.

![Agentic RAG Core Loop](../../../translated_images/fa/agentic-rag-core-loop.c8f4b85c26920f71.webp)

## مالکیت فرآیند استدلال

ویژگی متمایزی که یک سیستم را "عامل‌محور" می‌کند توانایی آن در مالکیت فرآیند استدلال خود است. پیاده‌سازی‌های سنتی RAG اغلب به انسان‌ها متکی هستند تا مسیر مدل را از پیش تعریف کنند: یک زنجیره تفکر که مشخص می‌کند چه چیزی را بازیابی کند و چه زمانی.
اما زمانی که یک سیستم واقعاً عامل‌محور باشد، به صورت داخلی تصمیم می‌گیرد که چگونه به مشکل نزدیک شود. این فقط اجرای یک اسکریپت نیست؛ بلکه به صورت خودکار ترتیب مراحل را بر اساس کیفیت اطلاعاتی که پیدا می‌کند تعیین می‌کند.
برای مثال، اگر از آن خواسته شود یک استراتژی راه‌اندازی محصول ایجاد کند، فقط به یک پرسش‌نامه که کل جریان تحقیق و تصمیم‌گیری را مشخص می‌کند متکی نیست. در عوض، مدل عامل‌محور به صورت مستقل تصمیم می‌گیرد:

1. گزارش‌های روند بازار فعلی را با استفاده از Bing Web Grounding بازیابی کند.
2. داده‌های رقبا را با استفاده از Azure AI Search شناسایی کند.
3. معیارهای فروش داخلی تاریخی را با استفاده از Azure SQL Database مرتبط کند.
4. یافته‌ها را به یک استراتژی منسجم ترکیب کند که از طریق Azure OpenAI Service هماهنگ شده است.
5. استراتژی را برای شکاف‌ها یا ناسازگاری‌ها ارزیابی کند و در صورت لزوم یک دور دیگر بازیابی را آغاز کند.
تمام این مراحل—اصلاح پرسش‌ها، انتخاب منابع، تکرار تا زمانی که از پاسخ "راضی" باشد—توسط مدل تصمیم‌گیری می‌شود، نه اینکه از پیش توسط انسان اسکریپت شده باشد.

## چرخه‌های تکراری، یکپارچه‌سازی ابزار و حافظه

![Tool Integration Architecture](../../../translated_images/fa/tool-integration.0f569710b5c17c10.webp)

یک سیستم عامل‌محور به یک الگوی تعامل چرخه‌ای متکی است:

- **تماس اولیه:** هدف کاربر (یعنی پرسش کاربر) به LLM ارائه می‌شود.
- **فراخوانی ابزار:** اگر مدل اطلاعات ناقص یا دستورالعمل‌های مبهم را شناسایی کند، یک ابزار یا روش بازیابی را انتخاب می‌کند—مانند پرسش از پایگاه داده برداری (مانند Azure AI Search Hybrid search بر روی داده‌های خصوصی) یا یک تماس SQL ساختاریافته—برای جمع‌آوری زمینه بیشتر.
- **ارزیابی و اصلاح:** پس از بررسی داده‌های بازگشتی، مدل تصمیم می‌گیرد که آیا اطلاعات کافی است. اگر نه، پرسش را اصلاح می‌کند، ابزار دیگری را امتحان می‌کند یا رویکرد خود را تنظیم می‌کند.
- **تکرار تا رضایت:** این چرخه ادامه می‌یابد تا زمانی که مدل تعیین کند که وضوح و شواهد کافی برای ارائه یک پاسخ نهایی و مستدل دارد.
- **حافظه و حالت:** از آنجا که سیستم حالت و حافظه را در مراحل مختلف حفظ می‌کند، می‌تواند تلاش‌های قبلی و نتایج آن‌ها را به یاد بیاورد، از چرخه‌های تکراری جلوگیری کند و تصمیمات آگاهانه‌تری در ادامه بگیرد.

با گذشت زمان، این امر حس درک تکاملی ایجاد می‌کند و به مدل امکان می‌دهد وظایف پیچیده و چندمرحله‌ای را بدون نیاز به دخالت مداوم انسان یا تغییر شکل پرسش انجام دهد.

## مدیریت حالت‌های شکست و خودتصحیح

خودمختاری Agentic RAG همچنین شامل مکانیسم‌های خودتصحیح قوی است. زمانی که سیستم به بن‌بست می‌رسد—مانند بازیابی اسناد نامربوط یا مواجهه با پرسش‌های ناقص—می‌تواند:

- **تکرار و پرسش مجدد:** به جای ارائه پاسخ‌های کم‌ارزش، مدل استراتژی‌های جستجوی جدیدی را امتحان می‌کند، پرسش‌های پایگاه داده را بازنویسی می‌کند یا به مجموعه داده‌های جایگزین نگاه می‌کند.
- **استفاده از ابزارهای تشخیصی:** سیستم ممکن است توابع اضافی را فراخوانی کند که برای کمک به اشکال‌زدایی مراحل استدلال یا تأیید صحت داده‌های بازیابی شده طراحی شده‌اند. ابزارهایی مانند Azure AI Tracing برای امکان‌پذیر کردن مشاهده‌پذیری و نظارت قوی مهم خواهند بود.
- **بازگشت به نظارت انسانی:** برای سناریوهای حساس یا شکست‌های مکرر، مدل ممکن است عدم قطعیت را علامت‌گذاری کند و درخواست راهنمایی انسانی کند. پس از ارائه بازخورد اصلاحی توسط انسان، مدل می‌تواند آن درس را در آینده به کار گیرد.

این رویکرد تکراری و پویا به مدل امکان می‌دهد به طور مداوم بهبود یابد و اطمینان حاصل کند که فقط یک سیستم تک‌مرحله‌ای نیست بلکه سیستمی است که از اشتباهات خود در طول یک جلسه یاد می‌گیرد.

![Self Correction Mechanism](../../../translated_images/fa/self-correction.da87f3783b7f174b.webp)

## مرزهای عامل‌محوری

با وجود خودمختاری در یک وظیفه، Agentic RAG معادل هوش مصنوعی عمومی نیست. قابلیت‌های "عامل‌محور" آن محدود به ابزارها، منابع داده و سیاست‌هایی است که توسط توسعه‌دهندگان انسانی ارائه شده‌اند. این سیستم نمی‌تواند ابزارهای خود را اختراع کند یا از مرزهای دامنه‌ای که تعیین شده‌اند فراتر رود. بلکه در هماهنگی پویا منابع موجود برجسته است.
تفاوت‌های کلیدی با اشکال پیشرفته‌تر هوش مصنوعی شامل موارد زیر است:

1. **خودمختاری خاص دامنه:** سیستم‌های Agentic RAG بر دستیابی به اهداف تعریف‌شده توسط کاربر در یک دامنه شناخته‌شده تمرکز دارند و از استراتژی‌هایی مانند بازنویسی پرسش یا انتخاب ابزار برای بهبود نتایج استفاده می‌کنند.
2. **وابسته به زیرساخت:** قابلیت‌های سیستم به ابزارها و داده‌هایی که توسط توسعه‌دهندگان یکپارچه شده‌اند بستگی دارد. این سیستم نمی‌تواند بدون دخالت انسانی از این مرزها فراتر رود.
3. **احترام به محدودیت‌ها:** دستورالعمل‌های اخلاقی، قوانین انطباق و سیاست‌های کسب‌وکار همچنان بسیار مهم هستند. آزادی عامل همیشه توسط اقدامات ایمنی و مکانیسم‌های نظارتی محدود می‌شود (امیدواریم؟).

## موارد استفاده عملی و ارزش

Agentic RAG در سناریوهایی که نیاز به اصلاح تکراری و دقت دارند برجسته است:

1. **محیط‌های مبتنی بر صحت:** در بررسی‌های انطباق، تحلیل‌های نظارتی یا تحقیقات حقوقی، مدل عامل‌محور می‌تواند به طور مکرر حقایق را تأیید کند، منابع متعدد را مشورت کند و پرسش‌ها را بازنویسی کند تا پاسخی کاملاً بررسی‌شده ارائه دهد.
2. **تعاملات پیچیده با پایگاه‌های داده:** هنگام کار با داده‌های ساختاریافته که پرسش‌ها ممکن است اغلب شکست بخورند یا نیاز به تنظیم داشته باشند، سیستم می‌تواند پرسش‌های خود را به صورت خودکار با استفاده از Azure SQL یا Microsoft Fabric OneLake اصلاح کند و اطمینان حاصل کند که بازیابی نهایی با هدف کاربر هماهنگ است.
3. **جریان‌های کاری طولانی‌مدت:** جلسات طولانی‌تر ممکن است با ظهور اطلاعات جدید تکامل یابند. Agentic RAG می‌تواند به طور مداوم داده‌های جدید را وارد کند و استراتژی‌ها را با یادگیری بیشتر درباره فضای مشکل تغییر دهد.

## حاکمیت، شفافیت و اعتماد

با افزایش خودمختاری این سیستم‌ها در استدلال، حاکمیت و شفافیت بسیار مهم هستند:

- **استدلال قابل توضیح:** مدل می‌تواند یک مسیر حسابرسی از پرسش‌هایی که انجام داده، منابعی که مشورت کرده و مراحل استدلالی که برای رسیدن به نتیجه طی کرده ارائه دهد. ابزارهایی مانند Azure AI Content Safety و Azure AI Tracing / GenAIOps می‌توانند به حفظ شفافیت و کاهش ریسک‌ها کمک کنند.
- **کنترل تعصب و بازیابی متعادل:** توسعه‌دهندگان می‌توانند استراتژی‌های بازیابی را تنظیم کنند تا اطمینان حاصل شود که منابع داده متعادل و نماینده در نظر گرفته می‌شوند و خروجی‌ها را به طور منظم بررسی کنند تا تعصب یا الگوهای منحرف را شناسایی کنند، با استفاده از مدل‌های سفارشی برای سازمان‌های پیشرفته داده‌محور با استفاده از Azure Machine Learning.
- **نظارت انسانی و انطباق:** برای وظایف حساس، بررسی انسانی همچنان ضروری است. Agentic RAG جایگزین قضاوت انسانی در تصمیمات حساس نمی‌شود—بلکه آن را با ارائه گزینه‌های کاملاً بررسی‌شده تقویت می‌کند.

داشتن ابزارهایی که یک رکورد واضح از اقدامات ارائه دهند ضروری است. بدون آن‌ها، اشکال‌زدایی یک فرآیند چندمرحله‌ای می‌تواند بسیار دشوار باشد. مثال زیر از Literal AI (شرکت پشت Chainlit) را برای یک اجرای عامل ببینید:

![AgentRunExample](../../../translated_images/fa/AgentRunExample.471a94bc40cbdc0c.webp)

## نتیجه‌گیری

Agentic RAG نمایانگر یک تکامل طبیعی در نحوه برخورد سیستم‌های هوش مصنوعی با وظایف پیچیده و داده‌محور است. با اتخاذ یک الگوی تعامل چرخه‌ای، انتخاب خودکار ابزارها و اصلاح پرسش‌ها تا رسیدن به یک نتیجه با کیفیت بالا، سیستم از پیروی ایستا از پرسش‌نامه‌ها به یک تصمیم‌گیرنده تطبیق‌پذیر و آگاه به زمینه حرکت می‌کند. در حالی که همچنان محدود به زیرساخت‌ها و دستورالعمل‌های اخلاقی تعریف‌شده توسط انسان است، این قابلیت‌های عامل‌محور تعاملات غنی‌تر، پویا‌تر و در نهایت مفیدتر هوش مصنوعی را برای شرکت‌ها و کاربران نهایی امکان‌پذیر می‌کند.

### سوالات بیشتری درباره Agentic RAG دارید؟

به [Discord Azure AI Foundry](https://aka.ms/ai-agents/discord) بپیوندید تا با دیگر یادگیرندگان ملاقات کنید، در ساعات اداری شرکت کنید و سوالات خود درباره عوامل هوش مصنوعی را مطرح کنید.

## منابع اضافی

- <a href="https://learn.microsoft.com/training/modules/use-own-data-azure-openai" target="_blank">پیاده‌سازی تولید مبتنی بر بازیابی (RAG) با سرویس Azure OpenAI: یاد بگی
- <a href="https://ragaboutit.com/agentic-rag-a-complete-guide-to-agent-based-retrieval-augmented-generation/" target="_blank">راهنمای کامل RAG عامل‌محور: اخبار مربوط به نسل RAG</a>
- <a href="https://huggingface.co/learn/cookbook/agent_rag" target="_blank">RAG عامل‌محور: تقویت RAG با اصلاح پرسش و پرسش خودکار! کتابخانه هوش مصنوعی متن‌باز Hugging Face</a>
- <a href="https://youtu.be/aQ4yQXeB1Ss?si=2HUqBzHoeB5tR04U" target="_blank">افزودن لایه‌های عامل‌محور به RAG</a>
- <a href="https://www.youtube.com/watch?v=zeAyuLc_f3Q&t=244s" target="_blank">آینده دستیاران دانش: جری لیو</a>
- <a href="https://www.youtube.com/watch?v=AOSjiXP1jmQ" target="_blank">چگونه سیستم‌های RAG عامل‌محور بسازیم</a>
- <a href="https://ignite.microsoft.com/sessions/BRK102?source=sessions" target="_blank">استفاده از سرویس عامل Azure AI Foundry برای مقیاس‌گذاری عوامل هوش مصنوعی</a>

### مقالات علمی

- <a href="https://arxiv.org/abs/2303.17651" target="_blank">2303.17651 Self-Refine: اصلاح تدریجی با بازخورد خود</a>
- <a href="https://arxiv.org/abs/2303.11366" target="_blank">2303.11366 Reflexion: عوامل زبانی با یادگیری تقویتی کلامی</a>
- <a href="https://arxiv.org/abs/2305.11738" target="_blank">2305.11738 CRITIC: مدل‌های زبانی بزرگ می‌توانند با نقد تعاملی ابزار خود را اصلاح کنند</a>
- <a href="https://arxiv.org/abs/2501.09136" target="_blank">2501.09136 RAG عامل‌محور: یک بررسی درباره RAG عامل‌محور</a>

## درس قبلی

[الگوی طراحی استفاده از ابزار](../04-tool-use/README.md)

## درس بعدی

[ساخت عوامل هوش مصنوعی قابل اعتماد](../06-building-trustworthy-agents/README.md)

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه انسانی حرفه‌ای استفاده کنید. ما مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.