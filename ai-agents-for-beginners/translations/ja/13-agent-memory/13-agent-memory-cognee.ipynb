{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Cogneeを使った永続メモリを持つAIエージェントの構築\n",
    "\n",
    "このノートブックでは、[**cognee**](https://www.cognee.ai/) を使用して、高度なメモリ機能を備えたインテリジェントなAIエージェントを構築する方法を示します。[cognee]は、ナレッジグラフ、セマンティック検索、セッション管理を組み合わせて、コンテキスト認識型のAIシステムを作成するオープンソースのAIメモリです。\n",
    "\n",
    "## 🎯 学習目標\n",
    "\n",
    "このチュートリアルの終わりまでに、以下のことを理解できるようになります：\n",
    "- **埋め込みを活用したナレッジグラフの構築**: 非構造化テキストを構造化されたクエリ可能な知識に変換する\n",
    "- **セッションメモリの実装**: 自動的にコンテキストを保持するマルチターンの会話を作成する\n",
    "- **会話の永続化**: 重要なやり取りを長期記憶に保存し、将来参照できるようにする\n",
    "- **自然言語でのクエリ**: 新しい会話で過去のコンテキストを活用する\n",
    "- **メモリの可視化**: エージェントのナレッジグラフ内の関係を探索する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## 🏗️ 作成するもの\n",
    "\n",
    "このチュートリアルでは、以下の機能を持つ**コーディングアシスタント**を作成します。特徴として、持続的な記憶を備えています。\n",
    "\n",
    "### 1. **ナレッジベースの構築**\n",
    "   - 開発者のプロフィールや専門知識情報を取り込む\n",
    "   - Pythonのプログラミング原則やベストプラクティスを処理する\n",
    "   - 開発者とAIアシスタント間の過去の会話を保存する\n",
    "\n",
    "### 2. **セッション対応の会話**\n",
    "   - 同じセッション内で複数の質問にわたる文脈を維持する\n",
    "   - 各質問と回答のペアを自動的にキャッシュして効率的に取得する\n",
    "   - 会話履歴に基づいて一貫性のある文脈的な応答を提供する\n",
    "\n",
    "### 3. **長期記憶**\n",
    "   - 重要な会話を長期記憶に保存する\n",
    "   - ナレッジベースや過去のセッションから関連する記憶を取得し、新しいやり取りに活用する\n",
    "   - 時間とともに成長するナレッジベースを構築する\n",
    "\n",
    "### 4. **インテリジェントな記憶検索**\n",
    "   - グラフ対応のセマンティック検索を使用して、保存されたすべての知識から関連情報を見つける\n",
    "   - データのサブグループ（開発者情報 vs. 原則）で検索をフィルタリングする\n",
    "   - 複数のデータソースを組み合わせて包括的な回答を提供する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## 📋 前提条件とセットアップ\n",
    "\n",
    "### システム要件\n",
    "\n",
    "開始する前に、以下を確認してください：\n",
    "\n",
    "1. **Python環境**\n",
    "   - Python 3.9以上\n",
    "   - 仮想環境（推奨）\n",
    "\n",
    "2. **Redisキャッシュ**（セッション管理に必要）\n",
    "   - ローカルRedis: `docker run -d -p 6379:6379 redis`\n",
    "   - または、マネージドRedisサービスを使用\n",
    "\n",
    "3. **LLM APIアクセス**\n",
    "   - OpenAI APIキーまたは他のプロバイダー（[ドキュメント](https://docs.cognee.ai/setup-configuration/llm-providers)を参照）\n",
    "\n",
    "4. **データベース構成**\n",
    "   - デフォルトでは構成不要。Cogneeはファイルベースのデータベース（LanceDBとKuzu）を使用\n",
    "   - オプションで、Azure AI Searchをベクトルストアとして設定可能（[ドキュメント](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch)を参照）\n",
    "\n",
    "### 環境設定\n",
    "\n",
    "プロジェクトディレクトリに `.env` ファイルを作成し、以下の変数を記述してください：\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## 🏛️ Cogneeのメモリアーキテクチャを理解する\n",
    "\n",
    "### Cogneeの仕組み\n",
    "\n",
    "Cogneeは、単純なキーと値のストレージを超えた高度なメモリシステムを提供します:\n",
    "\n",
    "```\n",
    "┌──────────────────────────┐\n",
    "│      30+ data sources    │\n",
    "└───────────┬──────────────┘\n",
    "            │\n",
    "            ▼\n",
    "┌──────────────────────────────────────────┐\n",
    "│  Dynamically evolving memory layers      │\n",
    "│                                          │\n",
    "│  ┌────────────────────────────────────┐  │\n",
    "│  │ Knowledge Graph in Graph Database  │  │\n",
    "│  └────────────────────────────────────┘  │\n",
    "│  ┌────────────────────────────────────┐  │\n",
    "│  │ Embeddings in Vector Store         │  │\n",
    "│  │   (e.g., Azure AI Search)          │  │\n",
    "│  └────────────────────────────────────┘  │\n",
    "└───────────┬──────────────────────────────┘\n",
    "            │                      ▲   \n",
    "            ▼                      │(optional)\n",
    "┌────────────────┐           ┌────────────────┐\n",
    "│     cognee     │(optional) │ Cognee Session │\n",
    "│    retrievers  │──────────▶│     Cache      │\n",
    "│                │           │    (Redis)     │\n",
    "└───────┬────────┘           └────────────────┘\n",
    "        ▲\n",
    "        │\n",
    "┌──────────────────────────┐\n",
    "│          Agents          │\n",
    "└──────────────────────────┘\n",
    "\n",
    "```\n",
    "\n",
    "### 主な構成要素:\n",
    "\n",
    "1. **ナレッジグラフ**: エンティティ、関係、意味的な接続を保存\n",
    "2. **ベクトル埋め込み**: 保存されたすべての情報に対する意味検索を可能にする\n",
    "3. **セッションキャッシュ**: セッション内およびセッション間で会話の文脈を保持\n",
    "4. **NodeSets**: データを論理的なカテゴリに整理し、ターゲットを絞った取得を可能にする\n",
    "\n",
    "### このチュートリアルでのメモリタイプ:\n",
    "\n",
    "- **永続メモリ**: ナレッジグラフ内の長期保存\n",
    "- **セッションメモリ**: Redisキャッシュ内の一時的な会話文脈\n",
    "- **セマンティックメモリ**: すべてのデータにわたるベースの類似性検索\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## 📦 必要なパッケージをインストール\n",
    "\n",
    "セッション管理のためにRedisサポート付きのCogneeをインストールします:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## 🔧 環境の初期化とライブラリの読み込み\n",
    "\n",
    "以下を確認してください:\n",
    "1. Redisが稼働していること（例: Dockerを使用する場合 `docker run -d -p 6379:6379 redis`）\n",
    "2. 環境変数がキャッシュモジュールをインポートする前に設定されていること\n",
    "3. 必要に応じてカーネルを再起動し、セルを順番に実行すること\n",
    "\n",
    "以下のセルでは以下を行います:\n",
    "1. `.env`から環境変数を読み込む\n",
    "2. CogneeをLLM設定で構成する\n",
    "3. セッション管理のためのキャッシュを有効化する\n",
    "4. すべてのコンポーネントが正しく接続されていることを検証する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## 📁 ストレージディレクトリの設定\n",
    "\n",
    "Cogneeはその操作のために2つの異なるディレクトリを使用します：\n",
    "- **データルート**: 取り込まれたドキュメントや処理済みデータを保存\n",
    "- **システムルート**: ナレッジグラフデータベースとシステムメタデータを含む\n",
    "\n",
    "このチュートリアルでは、以下のように分離されたディレクトリを作成します：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## 🧹 メモリ状態のリセット\n",
    "\n",
    "メモリシステムを構築する前に、まずは新しい状態から始めるようにしましょう。\n",
    "\n",
    "> 💡 **ヒント**: このノートブックを後で使用する際に、以前の実行からの既存のメモリを保持したい場合は、このステップをスキップすることができます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## 📚 パート1: ナレッジベースの構築\n",
    "\n",
    "### 開発者アシスタントのためのデータソース\n",
    "\n",
    "包括的なナレッジベースを作成するために、以下の3種類のデータを取り込みます:\n",
    "\n",
    "1. **開発者プロフィール**: 個人の専門知識や技術的な背景  \n",
    "2. **Pythonのベストプラクティス**: Pythonの哲学（The Zen of Python）と実践的なガイドライン  \n",
    "3. **過去の会話履歴**: 開発者とAIアシスタント間の過去のQ&Aセッション  \n",
    "\n",
    "この多様なデータにより、エージェントは以下を実現できます:\n",
    "- ユーザーの技術的な背景を理解する  \n",
    "- 推奨事項にベストプラクティスを適用する  \n",
    "- 過去の成功したやり取りから学ぶ  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## 🔄 データをナレッジグラフに変換\n",
    "\n",
    "ここでは、生のテキストを構造化された記憶に変換します。このプロセスでは以下を行います：\n",
    "\n",
    "1. **データをNodeSetsに追加**: 情報を論理的なカテゴリに整理\n",
    "   - `developer_data`: 開発者のプロフィールと会話\n",
    "   - `principles_data`: Pythonのベストプラクティスとガイドライン\n",
    "\n",
    "2. **Cognify Pipelineを実行**: エンティティや関係を抽出し、埋め込みを作成\n",
    "   - 重要な概念を特定\n",
    "   - 関連情報間のセマンティックなつながりを作成\n",
    "   - ベクトル埋め込みを生成\n",
    "\n",
    "LLMがテキストを処理し、グラフ構造を構築するため、少し時間がかかる場合があります：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## 📊 ナレッジグラフの可視化\n",
    "\n",
    "ナレッジグラフの構造を見てみましょう。この可視化では以下を示しています：\n",
    "- **ノード**: テキストから抽出されたエンティティ（概念、技術、人など）\n",
    "- **エッジ**: エンティティ間の関係や接続\n",
    "- **クラスター**: 意味的な類似性によってグループ化された関連する概念\n",
    "\n",
    "生成されたHTMLファイルをブラウザで開いて、グラフをインタラクティブに探索してください:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## 🧠 Memifyで記憶を強化\n",
    "\n",
    "`memify()`関数は、ナレッジグラフを分析し、データに関する知的なルールを生成します。このプロセスでは以下を行います：\n",
    "- パターンやベストプラクティスを特定\n",
    "- コンテンツに基づいた実行可能なガイドラインを作成\n",
    "- 異なる知識領域間の関係を確立\n",
    "\n",
    "これらのルールは、エージェントが質問に答える際に、より情報に基づいた意思決定を行うのに役立ちます。2回目のビジュアライゼーションをキャプチャすることで、グラフが強化された後にどのように密度が増したかを比較できます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## 🔍 パート2: インテリジェントなメモリ検索\n",
    "\n",
    "### デモンストレーション1: 複数ドキュメントの知識統合\n",
    "\n",
    "知識グラフが構築されたので、Cogneeが複数の情報源から情報を組み合わせて複雑な質問に答える方法をテストしてみましょう。\n",
    "\n",
    "最初のクエリでは以下を示します:\n",
    "- **セマンティック理解**: 明示的に言及されていなくても関連する概念を見つける\n",
    "- **クロスリファレンス**: 開発者のプロフィールとPythonの原則を組み合わせる\n",
    "- **文脈的推論**: ベストプラクティスを特定の実装に適用する\n",
    "\n",
    "### デモンストレーション2: NodeSetsを使ったフィルタ検索\n",
    "\n",
    "2つ目のクエリでは、知識グラフの特定のサブセットをターゲットにする方法を示します:\n",
    "- `node_name`パラメータを使用して`principles_data`内のみを検索\n",
    "- 特定の知識分野から焦点を絞った回答を提供\n",
    "- 分野特化の情報が必要な場合に便利\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## 🔐 パート3: セッション管理のセットアップ\n",
    "\n",
    "### 会話メモリの有効化\n",
    "\n",
    "セッション管理は、複数のやり取りにおいてコンテキストを維持するために重要です。ここでは以下を行います:\n",
    "\n",
    "1. **ユーザーコンテキストの初期化**: セッション追跡のためにユーザープロファイルを作成または取得します\n",
    "2. **キャッシュエンジンの設定**: 会話履歴を保存するためにRedisに接続します\n",
    "3. **セッション変数の有効化**: クエリ間で持続するコンテキスト変数を設定します\n",
    "\n",
    "> ⚠️ **重要**: Redisが稼働しており、環境で`CACHING=true`が設定されている必要があります\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## 🛠️ ヘルパー関数: セッション履歴の表示\n",
    "\n",
    "このユーティリティ関数は、Redisに保存されている会話履歴を確認するためのものです。以下の用途に役立ちます:\n",
    "- セッション管理のデバッグ\n",
    "- 会話がキャッシュされていることの確認\n",
    "- エージェントが利用可能なコンテキストの把握\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## セッション1: 非同期サポートラボ — 最初の質問\n",
    "\n",
    "`async-support-lab`セッションを開始し、大規模なウェブスクレイパー向けのテレメトリ対応のasyncioパターンについて質問してください。グラフはすでにasyncio、aiohttp、モニタリングの実践について知っているので、回答は以前の会話を反映しつつ、新しい質問に合わせた内容になるべきです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## セッション1のメモリを最初のやり取り後に確認する\n",
    "\n",
    "最初の質問の直後に `show_history(session_1)` を実行すると、Cogneeがプロンプトと応答の両方をRedisに書き込んだことが確認できます。同時実行ガイダンスを含む1つのエントリが表示されるはずです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## セッション1: データモデルのフォローアップ\n",
    "\n",
    "次に、「dataclassesとPydanticのどちらを選ぶべきかはいつか？」という質問をします。同じセッションIDを使用します。CogneeはPythonの原則と以前のFastAPIの会話を組み合わせて、文脈が名前付きセッション内で引き継がれることを示しながら、詳細なアドバイスを提供する必要があります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## セッション1の履歴に両方のターンが含まれていることを確認\n",
    "\n",
    "もう一度 `show_history(session_1)` を呼び出すと、2つのQ&Aエントリが表示されるはずです。これはMem0ラボの「メモリ再生」ステップと一致し、追加のターンが同じトランスクリプトを拡張することを証明します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## セッション 2: デザインレビューのスレッド — 新しいセッション\n",
    "\n",
    "スレッド間の分離を示すために、`design-review-session` を起動し、インシデントレビューのためのログガイダンスを求めます。基礎となる知識ベースは同じですが、新しいセッションIDによってトランスクリプトが分離されます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## レビューセッション2の履歴\n",
    "\n",
    "`show_history(session_2)` は、デザインレビューのプロンプト/レスポンスペアのみをリストする必要があります。セッション1と比較して、Cogneeが共有ナレッジグラフを再利用しながら、独立したトランスクリプトをどのように保持しているかを強調してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "おめでとうございます！あなたのコーディングアシスタントに、Cogneeによる本格的な長期記憶レイヤーを追加しました。\n",
    "\n",
    "このチュートリアルでは、開発者向けの生データ（コード、ドキュメント、チャット）をグラフ＋ベクトルメモリに変換し、エージェントが検索、推論、そして継続的に改善できるようにする方法を学びました。\n",
    "\n",
    "学んだこと\n",
    "\n",
    "1. **生テキストからAIメモリへ**: Cogneeが非構造化データを取り込み、ベクトル＋知識グラフアーキテクチャを使用してインテリジェントで検索可能なメモリに変換する方法。\n",
    "\n",
    "2. **memifyによるグラフの強化**: 基本的なグラフ作成を超えて、memifyを使用して既存のグラフに派生した事実やより豊かな関係を追加する方法。\n",
    "\n",
    "3. **複数の検索戦略**: エージェントのニーズに応じて、異なる検索タイプ（グラフ対応のQ&A、RAGスタイルの補完、インサイト、生データのチャンク、コード検索など）を使用してメモリをクエリする方法。\n",
    "\n",
    "4. **視覚的な探索**: グラフの可視化やCognee UIを使用して、Cogneeが構築した内容を検査・デバッグし、知識がどのように構造化されているかを実際に確認する方法。\n",
    "\n",
    "5. **セッション対応のメモリ**: セッションごとのコンテキストを永続的なセマンティックメモリと組み合わせることで、エージェントがユーザー間で情報を漏らすことなく、複数回の実行にわたって記憶できるようにする方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## 重要なポイント\n",
    "1. 埋め込みを活用した知識グラフとしてのメモリ\n",
    "\n",
    "    - **構造化された理解**: Cogneeはベクトルストアとグラフストアを組み合わせることで、データを意味で検索可能にし、関係性で接続します。Cogneeはデフォルトでファイルベースのデータベースを使用します（ベクトルにはLanceDB、グラフデータベースにはKuzu）。\n",
    "\n",
    "    - **関係性を考慮した検索**: 回答は「類似したテキスト」だけでなく、エンティティ間の関係性に基づいて導き出されます。\n",
    "\n",
    "    - **進化するメモリ**: メモリ層は進化し、成長し、1つの接続されたグラフとして常にクエリ可能な状態を維持します。\n",
    "\n",
    "2. 検索と推論モード\n",
    "    - **ハイブリッド検索**: 検索はベクトル類似性、グラフ構造、LLM推論を組み合わせ、生のチャンク検索からグラフを考慮した質問応答まで対応します。\n",
    "\n",
    "    - **目的に応じたモード選択**: 自然言語での回答が必要な場合は補完型モードを使用し、エージェントが生のコンテキストを必要とする場合や独自の推論を行う場合はチャンク/要約/グラフモードを使用します。\n",
    "\n",
    "3. 個別化されたセッション対応エージェント\n",
    "    - **セッションコンテキスト + 長期メモリ**: Cogneeは短期的な「スレッド」コンテキストを、長期的なユーザーや組織レベルのメモリから分離して保持します。\n",
    "\n",
    "## 実際の応用例\n",
    "\n",
    "1. **特定分野向けAIエージェント**\n",
    "\n",
    "    このノートブックのパターンを使用して、Cogneeを検索と推論のコアとして活用する分野特化型のコパイロットを構築できます:\n",
    "\n",
    "- **開発者向けコパイロット**: コードレビュー、インシデント分析、アーキテクチャ支援を行い、コード、API、設計文書、チケットを1つのメモリグラフとして横断します。\n",
    "\n",
    "- **顧客対応コパイロット**: 製品文書、FAQ、CRMノート、過去のチケットをグラフ対応検索で引き出し、引用付きの回答を提供します。\n",
    "\n",
    "- **内部専門家向けコパイロット**: ポリシー、法務、セキュリティ支援を行い、孤立したPDFではなく、相互に関連するルール、ガイドライン、過去の決定を基に推論します。\n",
    "\n",
    "    CogneeはAIエージェントのための永続的で正確なメモリとして明確に位置付けられており、エージェントの背後にある生きた知識グラフを提供し、ベクトルストアやカスタムグラフコードのアドホックな組み合わせを置き換えます。\n",
    "\n",
    "2. **データサイロを統一して1つのメモリに**\n",
    "\n",
    "    同じアプローチで、分散したソースを統一したメモリ層に構築することも可能です:\n",
    "\n",
    "- **サイロから1つのグラフへ**: 構造化データ（例: データベース）や非構造化データ（例: 文書、チャット）を埋め込みに基づいた単一のグラフに取り込み、各システムごとのインデックスを分離する代わりに統合します。\n",
    "\n",
    "- **引用付きのクロスソース推論**: ログ、メトリクス、文書をグラフを介して「結合」し、すべてにわたる多段階推論を実行しながら、根拠のある回答を返します。\n",
    "\n",
    "- **知識ハブ**: 銀行や教育のような分野では、CogneeはすでにPDF、内部システム、アプリデータを統一し、ベクトルを活用した知識グラフを構築しており、エージェントが正確で引用付きのコンテキストで質問に答えることができます。\n",
    "\n",
    "## 次のステップ\n",
    "\n",
    "コアメモリループを実装しました。以下は独自に試せる自然な拡張案です（詳細は[Cogneeのドキュメント](https://docs.cognee.ai/)をご覧ください）:\n",
    "\n",
    "1. **時間認識の実験**: 時間認識をオンにして、テキストからイベントやタイムスタンプを抽出します。\n",
    "\n",
    "2. **オントロジー駆動型推論の導入**: 自分の分野に合わせたOWLオントロジーを定義します。Cogneeのオントロジーサポートを活用して、抽出されたエンティティや関係をそのスキーマに基づいて整理し、グラフの品質や分野特化型の回答を向上させます。\n",
    "\n",
    "3. **フィードバックループの追加**: 実際のユーザーフィードバックからCogneeがグラフのエッジウェイトを調整できるようにし、検索が静的ではなく時間とともに改善されるようにします。\n",
    "\n",
    "4. **個別化とセッション動作の調整**: ユーザーID、テナント、データセットを使用して、共有メモリエンジン上で各個人やチームに独自のビューを提供します。\n",
    "\n",
    "5. **より複雑なエージェントへの拡張**: Cogneeをエージェントフレームワークに接続し、同じメモリ層を共有するマルチエージェントシステムを構築します。*Microsoft Agent Framework x Cogneeプラグインが近日公開予定です。*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**免責事項**:  \nこの文書はAI翻訳サービス[Co-op Translator](https://github.com/Azure/co-op-translator)を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解について、当社は責任を負いません。\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:33:14+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "ja"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}