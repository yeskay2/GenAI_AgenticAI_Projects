{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# роЪрпЖрооро╛рогрпНроЯро┐роХрпН роХро░рпНройро▓ро┐ро▓рпН роПроЬрпЖройрпНроЯрпН ро╕рпНроХрпНро░ро╛роЯрпНроЪрпНрокрпЗроЯрпБроЯройрпН роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпНро▒рпИ роХрпБро▒рпИрокрпНрокродрпБ\n",
    "\n",
    "роЗроирпНрод роирпЛроЯрпНрокрпБроХрпН роЪрпЖрооро╛рогрпНроЯро┐роХрпН роХро░рпНройро▓ро┐ройрпН роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпНро▒рпИ роХрпБро▒рпИроХрпНроХрпБроорпН роЕроорпНроЪродрпНродрпИропрпБроорпН, роПроЬрпЖройрпНроЯрпН ро╕рпНроХрпНро░ро╛роЯрпНроЪрпНрокрпЗроЯрпБроЯройрпН роЙро░рпИропро╛роЯро▓рпНроХро│ро┐ро▓рпН роиро┐ро▓рпИропро╛рой роЪрпВро┤ро▓рпИ рокро░ро╛рооро░ро┐роХрпНроХ рокропройрпНрокроЯрпБродрпНродрпБро╡родрпБ роОрокрпНрокроЯро┐ роОройрпНрокродрпИ ро╡ро┐ро│роХрпНроХрпБроХро┐ро▒родрпБ. роЗродрпБ роирпАрогрпНроЯ роЙро░рпИропро╛роЯро▓рпНроХро│рпИ роХрпИропро╛ро│рпБроорпН родро┐ро▒ройрпН роХрпКрогрпНроЯ родро┐ро▒роорпИропро╛рой AI роПроЬрпЖройрпНроЯрпНроХро│рпИ роЙро░рпБро╡ро╛роХрпНроХ роорпБроХрпНроХро┐ропрооро╛ройродрпБ, роХрпБро▒ро┐рокрпНрокрпБроХро│ро┐ройрпН ро╡ро░роорпНрокрпБроХро│рпИ роорпАро▒ро╛рооро▓рпН.\n",
    "\n",
    "## роирпАроЩрпНроХро│рпН роХро▒рпНро▒рпБроХрпНроХрпКро│рпНро│рокрпНрокрпЛроХро┐ро▒рпАро░рпНроХро│рпН:\n",
    "1. **роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпНро▒рпИ роХрпБро▒рпИрокрпНрокродрпБ**: роХрпБро▒ро┐рокрпНрокрпБроХро│рпИ рокропройрпНрокроЯрпБродрпНродрпБро╡родро┐ро▓рпН роорпЗро▓ро╛рогрпНроорпИ роЪрпЖропрпНроп роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпНро▒рпИ родро╛ройро╛роХ роЪрпБро░рпБроХрпНроХрпБро╡родрпБ роОрокрпНрокроЯро┐\n",
    "2. **роПроЬрпЖройрпНроЯрпН ро╕рпНроХрпНро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН**: рокропройро░рпН ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпН рооро▒рпНро▒рпБроорпН роорпБроЯро┐роХрпНроХрокрпНрокроЯрпНроЯ рокрогро┐роХро│рпИ роХрогрпНроХро╛рогро┐роХрпНроХ роТро░рпБ роиро┐ро▓рпИропро╛рой роиро┐ройрпИро╡роХ роЕроорпИрокрпНрокрпБ\n",
    "3. **роХрпБро▒ро┐рокрпНрокрпБроХро│рпН рокропройрпНрокро╛роЯрпНроЯрпИ роХрогрпНроХро╛рогро┐родрпНродро▓рпН**: ро╡ро░ро▓ро╛ро▒рпНро▒рпИ роХрпБро▒рпИрокрпНрокродрпБроЯройрпН рооро▒рпНро▒рпБроорпН роЗро▓рпНро▓ро╛рооро▓рпН роХрпБро▒ро┐рокрпНрокрпБроХро│рпН рокропройрпНрокро╛роЯрпНроЯро┐ро▓рпН рооро╛ро▒рпНро▒роЩрпНроХро│рпИ роХрогрпНроХро╛рогро┐роХрпНроХ\n",
    "\n",
    "## роорпБройрпН родрпЗро╡рпИроХро│рпН:\n",
    "- роЪрпВро┤ро▓рпН рооро╛ро▒ро┐роХро│рпН роЕроорпИроХрпНроХрокрпНрокроЯрпНроЯ Azure OpenAI роЕроорпИрокрпНрокрпБ\n",
    "- роорпБроирпНродрпИроп рокро╛роЯроЩрпНроХро│ро┐ро▓рпН роЗро░рпБроирпНродрпБ роЕроЯро┐рокрпНрокроЯрпИ роПроЬрпЖройрпНроЯрпН роХро░рпБродрпНродрпБроХро│рпИрокрпН рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро╡родрпБ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## родрпЗро╡рпИропро╛рой родрпКроХрпБрокрпНрокрпБроХро│рпИ роЗро▒роХрпНроХрпБроородро┐ роЪрпЖропрпНропро╡рпБроорпН\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import json\n",
    "import os\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from typing import Annotated, Optional\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.completion_usage import CompletionUsage\n",
    "from semantic_kernel.contents import ChatHistorySummarizationReducer\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## роПроЬрпЖройрпНроЯрпН ро╕рпНроХрпНро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН рокро▒рпНро▒ро┐ рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро╡родрпБ\n",
    "\n",
    "### роПроЬрпЖройрпНроЯрпН ро╕рпНроХрпНро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН роОройрпНро▒ро╛ро▓рпН роОройрпНрой?\n",
    "\n",
    "**роПроЬрпЖройрпНроЯрпН ро╕рпНроХрпНро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН** роОройрпНрокродрпБ роПроЬрпЖройрпНроЯрпНроХро│рпН рокропройрпНрокроЯрпБродрпНродрпБроорпН роТро░рпБ роиро┐ро▓рпИропро╛рой роиро┐ройрпИро╡роХ роЕроорпИрокрпНрокрпБ, роЗродрпБ:\n",
    "- **роорпБроЯро┐роХрпНроХрокрпНрокроЯрпНроЯ рокрогро┐роХро│рпИ роХрогрпНроХро╛рогро┐роХрпНроХ**: рокропройро░рпБроХрпНроХро╛роХ роОройрпНрой роЪрпЖропрпНропрокрпНрокроЯрпНроЯродрпБ роОройрпНрокродрпИ рокродро┐ро╡рпБ роЪрпЖропрпНроп\n",
    "- **рокропройро░рпН ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпИ роЪрпЗрооро┐роХрпНроХ**: ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпН, ро╡ро┐ро░рпБрокрпНрокрооро▒рпНро▒ро╡рпИ рооро▒рпНро▒рпБроорпН родрпЗро╡рпИроХро│рпИ роиро┐ройрпИро╡ро┐ро▓рпН ро╡рпИродрпНродро┐ро░рпБроХрпНроХ\n",
    "- **роЪрпВро┤ро▓роорпИрокрпНрокрпИ рокро░ро╛рооро░ро┐роХрпНроХ**: роорпБроХрпНроХро┐ропрооро╛рой родроХро╡ро▓рпНроХро│рпИ роЙро░рпИропро╛роЯро▓рпНроХро│ро┐ро▓рпН роОро│ро┐родро╛роХ роЕрогрпБроХроХрпНроХрпВроЯро┐ропродро╛роХ ро╡рпИродрпНродро┐ро░рпБроХрпНроХ\n",
    "- **роорпАрогрпНроЯрпБроорпН роорпАрогрпНроЯрпБроорпН роХрпЗро│рпНро╡ро┐роХро│рпН роХрпЗроЯрпНрокродрпИ родро╡ро┐ро░рпНроХрпНроХ**: роТро░рпЗ роХрпЗро│рпНро╡ро┐роХро│рпИ роорпАрогрпНроЯрпБроорпН роХрпЗроЯрпНроХро╛рооро▓рпН роЗро░рпБроХрпНроХ\n",
    "\n",
    "### роЗродрпБ роОрокрпНрокроЯро┐ роЪрпЖропро▓рпНрокроЯрпБроХро┐ро▒родрпБ:\n",
    "1. **роОро┤рпБродрпБроорпН роЪрпЖропро▓рпНрокро╛роЯрпБроХро│рпН**: роПроЬрпЖройрпНроЯрпН рокрпБродро┐роп родроХро╡ро▓рпИроХрпН роХро▒рпНро▒рпБроХрпНроХрпКрогрпНроЯ рокро┐ро▒роХрпБ ро╕рпНроХрпНро░ро╛роЯрпНроЪрпНрокрпЗроЯрпНроЯро┐ро▓рпН рокрпБродрпБрокрпНрокро┐роХрпНроХро┐ро▒родрпБ\n",
    "2. **рокроЯро┐роХрпНроХрпБроорпН роЪрпЖропро▓рпНрокро╛роЯрпБроХро│рпН**: роорпБроЯро┐ро╡рпБроХро│рпИ роОроЯрпБроХрпНроХрпБроорпН рокрпЛродрпБ роПроЬрпЖройрпНроЯрпН ро╕рпНроХрпНро░ро╛роЯрпНроЪрпНрокрпЗроЯрпНроЯрпИ роЕрогрпБроХрпБроХро┐ро▒родрпБ\n",
    "3. **роиро┐ро▓рпИродрпНродройрпНроорпИ**: роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпБ роХрпБро▒рпИроХрпНроХрокрпНрокроЯрпНроЯро╛ро▓рпБроорпН родроХро╡ро▓рпН роирпАроЯро┐роХрпНроХро┐ро▒родрпБ\n",
    "\n",
    "роЗродрпИ роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпНро▒рпИродрпН родрпБрогрпИ роЪрпЖропрпНропрпБроорпН роПроЬрпЖройрпНроЯро┐ройрпН родройро┐рокрпНрокроЯрпНроЯ роХрпБро▒ро┐рокрпНрокрпЗроЯро╛роХроХрпН роХро░рпБродро▓ро╛роорпН.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## роЪрпВро┤ро▓рпН роХроЯрпНроЯроорпИрокрпНрокрпБ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create Azure OpenAI service\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "print(\"тЬЕ Azure OpenAI service configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## роПроЬрпЖройрпНроЯрпН ро╕рпНроХро┐ро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН рокро┐ро│роХро┐ройрпН роЙро░рпБро╡ро╛роХрпНроХро╡рпБроорпН\n",
    "\n",
    "роЗроирпНрод рокро┐ро│роХро┐ройрпН роПроЬрпЖройрпНроЯрпБроХрпНроХрпБ роиро┐ро▓рпИропро╛рой ро╕рпНроХро┐ро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН роХрпЛрокрпНрокрпИ рокроЯро┐роХрпНроХро╡рпБроорпН роОро┤рпБродро╡рпБроорпН роЕройрпБроородро┐роХрпНроХро┐ро▒родрпБ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchpadPlugin:\n",
    "    \"\"\"Plugin for managing agent scratchpad - a persistent memory for user preferences and completed tasks\"\"\"\n",
    "    \n",
    "    def __init__(self, filepath: str = \"agent_scratchpad.md\"):\n",
    "        self.filepath = Path(filepath)\n",
    "        # Initialize scratchpad if it doesn't exist\n",
    "        if not self.filepath.exists():\n",
    "            self.filepath.write_text(\"# Agent Scratchpad\\n\\n## User Preferences\\n\\n## Completed Tasks\\n\\n\")\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Read the current agent scratchpad to get user's travel preferences and completed tasks\"\n",
    "    )\n",
    "    def read_scratchpad(self) -> Annotated[str, \"The contents of the agent scratchpad\"]:\n",
    "        \"\"\"Read the current scratchpad contents\"\"\"\n",
    "        return self.filepath.read_text()\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Update the agent scratchpad with new user's travel preference or completed tasks\"\n",
    "    )\n",
    "    def update_scratchpad(\n",
    "        self,\n",
    "        category: Annotated[str, \"Category to update: 'preferences' or 'tasks'\"],\n",
    "        content: Annotated[str, \"The new content to add\"]\n",
    "    ) -> Annotated[str, \"Confirmation of the update\"]:\n",
    "        \"\"\"Update the scratchpad with new information\"\"\"\n",
    "        current_content = self.filepath.read_text()\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        if category.lower() == \"preferences\":\n",
    "            # Find the preferences section and append\n",
    "            lines = current_content.split(\"\\n\")\n",
    "            for i, line in enumerate(lines):\n",
    "                if \"## User Preferences\" in line:\n",
    "                    lines.insert(i + 1, f\"\\n- [{timestamp}] {content}\")\n",
    "                    break\n",
    "            current_content = \"\\n\".join(lines)\n",
    "        elif category.lower() == \"tasks\":\n",
    "            # Find the tasks section and append\n",
    "            lines = current_content.split(\"\\n\")\n",
    "            for i, line in enumerate(lines):\n",
    "                if \"## Completed Tasks\" in line:\n",
    "                    lines.insert(i + 1, f\"\\n- [{timestamp}] {content}\")\n",
    "                    break\n",
    "            current_content = \"\\n\".join(lines)\n",
    "        \n",
    "        self.filepath.write_text(current_content)\n",
    "        return f\"тЬЕ Scratchpad updated with {category}: {content}\"\n",
    "\n",
    "# Create the scratchpad plugin\n",
    "scratchpad_plugin = ScratchpadPlugin(\"vacation_agent_scratchpad.md\")\n",
    "print(\"ЁЯУЭ Scratchpad plugin created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## роЪроирпНродрпИ ро╡ро░ро▓ро╛ро▒рпНро▒рпИ роХрпБро▒рпИрокрпНрокродро▒рпНроХро╛рой родрпКроЯроХрпНроХроорпН\n",
    "\n",
    "ChatHistorySummarizationReducer, роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпБ роТро░рпБ ро╡ро░роорпНрокрпИ роорпАро▒рпБроорпНрокрпЛродрпБ родро╛ройро╛роХро╡рпЗ роЪрпБро░рпБроХрпНроХрооро╛роХ рооро╛ро▒рпНро▒рпБроХро┐ро▒родрпБ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure reduction parameters\n",
    "REDUCER_TARGET_COUNT = 5  # Target number of messages to keep after reduction\n",
    "REDUCER_THRESHOLD = 15    # Trigger reduction when message count exceeds this\n",
    "\n",
    "# Create the history summarization reducer\n",
    "history_reducer = ChatHistorySummarizationReducer(\n",
    "    service=chat_service,\n",
    "    target_count=REDUCER_TARGET_COUNT,\n",
    "    threshold_count=REDUCER_THRESHOLD,\n",
    ")\n",
    "\n",
    "print(f\"ЁЯФД Chat History Reducer configured:\")\n",
    "print(f\"   - Reduction triggered at: {REDUCER_THRESHOLD} messages\")\n",
    "print(f\"   - Reduces history to: {REDUCER_TARGET_COUNT} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ро╡ро┐роЯрпБроорпБро▒рпИ родро┐роЯрпНроЯрооро┐роЯрпБроорпН роорпБроХро╡ро░ро┐ропрпИ роЙро░рпБро╡ро╛роХрпНроХро╡рпБроорпН\n",
    "\n",
    "роЗроирпНрод роорпБроХро╡ро░рпН рокропройро░рпНроХро│рпБроХрпНроХрпБ ро╡ро┐роЯрпБроорпБро▒рпИ родро┐роЯрпНроЯрооро┐роЯ роЙродро╡рпБро╡родрпБроЯройрпН, ро╕рпНроХро┐ро░ро╛роЯрпНроЪрпНрокрпЗроЯро┐ройрпН роорпВро▓роорпН роЪрпВро┤ро▓рпИ рокро░ро╛рооро░ро┐роХрпНроХро╡рпБроорпН роЪрпЖропрпНропрпБроорпН.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vacation planning agent with detailed instructions\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=\"VacationPlannerAgent\",\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful vacation planning assistant. Your job is to help users plan their perfect vacation.\n",
    "    \n",
    "    CRITICAL SCRATCHPAD RULES - YOU MUST FOLLOW THESE:\n",
    "    1. FIRST ACTION: When starting ANY conversation, immedi ately call read_scratchpad() to check existing preferences\n",
    "    2. AFTER LEARNING PREFERENCES: When user mentions ANY preference (destinations, activities, budget, dates), \n",
    "       immediately call update_scratchpad() with category 'preferences'\n",
    "    3. AFTER COMPLETING TASKS: When you finish creating an itinerary or completing any task,\n",
    "       immediately call update_scratchpad() with category 'tasks'\n",
    "    4. BEFORE NEW ITINERARY: Always call read_scratchpad() before creating any itinerary\n",
    "    \n",
    "    EXAMPLES OF WHEN TO UPDATE SCRATCHPAD:\n",
    "    - User says \"I love beaches\" тЖТ update_scratchpad('preferences', 'Loves beach destinations')\n",
    "    - User says \"budget is $3000\" тЖТ update_scratchpad('preferences', 'Budget: $3000 per person for a week')\n",
    "    - You create an itinerary тЖТ update_scratchpad('tasks', 'Created Bali itinerary for beach vacation')\n",
    "    \n",
    "    PLANNING PROCESS:\n",
    "    1. Read scratchpad first\n",
    "    2. Ask about preferences if not found\n",
    "    3. Update scratchpad with new information\n",
    "    4. Create detailed itineraries\n",
    "    5. Update scratchpad with completed tasks\n",
    "    \n",
    "    BE EXPLICIT: Always announce when you're checking or updating the scratchpad.\n",
    "    \"\"\",\n",
    "    plugins=[scratchpad_plugin],\n",
    ")\n",
    "\n",
    "print(\"ЁЯдЦ Vacation Planning Agent created with enhanced scratchpad instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## роЙродро╡ро┐ роЪрпЖропро▓рпНрокро╛роЯрпБроХро│рпН роХро╛роЯрпНроЪро┐роХрпНроХрпБроорпН роЯрпЛроХрпНроХройрпН роХрогрпНроХро╛рогро┐рокрпНрокро┐ро▒рпНроХрпБроорпН\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token tracking class\n",
    "class TokenTracker:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "        self.total_usage = CompletionUsage()\n",
    "        self.reduction_events = []  # Track when reductions occur\n",
    "\n",
    "    def add_usage(self, usage: CompletionUsage, message_num: int, thread_length: int = None):\n",
    "        if usage:\n",
    "            self.total_usage += usage\n",
    "            entry = {\n",
    "                \"message_num\": message_num,\n",
    "                \"prompt_tokens\": usage.prompt_tokens,\n",
    "                \"completion_tokens\": usage.completion_tokens,\n",
    "                \"total_tokens\": usage.prompt_tokens + usage.completion_tokens,\n",
    "                \"cumulative_tokens\": self.total_usage.prompt_tokens + self.total_usage.completion_tokens,\n",
    "                \"thread_length\": thread_length\n",
    "            }\n",
    "            self.history.append(entry)\n",
    "\n",
    "    def mark_reduction(self, message_num: int):\n",
    "        self.reduction_events.append(message_num)\n",
    "\n",
    "    def display_chart(self):\n",
    "        \"\"\"Display a chart showing token usage per message and the impact of reduction\"\"\"\n",
    "        if not self.history:\n",
    "            return\n",
    "\n",
    "        html = \"<div style='font-family: monospace; background: #2d2d2d; color: #f0f0f0; padding: 15px; border-radius: 8px; border: 1px solid #444;'>\"\n",
    "        html += \"<h4 style='color: #4fc3f7; margin-top: 0;'>ЁЯУК Token Usage Analysis</h4>\"\n",
    "        html += \"<pre style='color: #f0f0f0; margin: 0;'>\"\n",
    "\n",
    "        # Show prompt tokens per message to see reduction impact\n",
    "        html += \"<span style='color: #81c784;'>Prompt Tokens per Message (shows conversation context size):</span>\\n\"\n",
    "        max_prompt = max(h[\"prompt_tokens\"] for h in self.history)\n",
    "        scale = 50 / max_prompt if max_prompt > 0 else 1\n",
    "\n",
    "        for i, h in enumerate(self.history):\n",
    "            bar_length = int(h[\"prompt_tokens\"] * scale)\n",
    "            bar = \"тЦИ\" * bar_length\n",
    "            reduction_marker = \" <span style='color: #ff6b6b;'>тЖР REDUCTION!</span>\" if h[\n",
    "                \"message_num\"] in self.reduction_events else \"\"\n",
    "            html += f\"<span style='color: #aaa;'>Msg {h['message_num']:2d}:</span> <span style='color: #4fc3f7;'>{bar}</span> <span style='color: #ffd93d;'>{h['prompt_tokens']:,} tokens</span>{reduction_marker}\\n\"\n",
    "\n",
    "        html += \"\\n</pre></div>\"\n",
    "        display(HTML(html))\n",
    "\n",
    "        # Calculate reduction impact\n",
    "        if self.reduction_events:\n",
    "            # Find the message before and after first reduction\n",
    "            first_reduction_msg = self.reduction_events[0]\n",
    "            before_reduction = None\n",
    "            after_reduction = None\n",
    "\n",
    "            for h in self.history:\n",
    "                if h[\"message_num\"] == first_reduction_msg - 1:\n",
    "                    before_reduction = h[\"prompt_tokens\"]\n",
    "                elif h[\"message_num\"] == first_reduction_msg:\n",
    "                    after_reduction = h[\"prompt_tokens\"]\n",
    "\n",
    "            if before_reduction and after_reduction:\n",
    "                reduction_amount = before_reduction - after_reduction\n",
    "                reduction_percent = (reduction_amount / before_reduction * 100)\n",
    "                print(f\"\\nЁЯФД Actual Reduction Impact:\")\n",
    "                print(f\"Prompt tokens before reduction: {before_reduction:,}\")\n",
    "                print(f\"Prompt tokens after reduction: {after_reduction:,}\")\n",
    "                print(\n",
    "                    f\"Tokens saved: {reduction_amount:,} ({reduction_percent:.1f}%)\")\n",
    "\n",
    "# Display function for clean output\n",
    "\n",
    "\n",
    "def display_message(role: str, content: str, color: str = \"#2E8B57\"):\n",
    "    \"\"\"Display a message with nice formatting that works in both light and dark themes\"\"\"\n",
    "    # Use a semi-transparent background that adapts to the theme\n",
    "    html = f\"\"\"\n",
    "    <div style='\n",
    "        margin: 10px 0; \n",
    "        padding: 12px 15px; \n",
    "        border-left: 4px solid {color}; \n",
    "        background: rgba(128, 128, 128, 0.1); \n",
    "        border-radius: 4px;\n",
    "        color: inherit;\n",
    "    '>\n",
    "        <strong style='color: {color}; font-size: 14px;'>{role}:</strong><br>\n",
    "        <div style='margin-top: 8px; white-space: pre-wrap; color: inherit; font-size: 14px;'>{content}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "\n",
    "# Initialize token tracker\n",
    "token_tracker = TokenTracker()\n",
    "print(\"ЁЯУК Token tracking initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ро╡ро┐роЯрпБроорпБро▒рпИ родро┐роЯрпНроЯрооро┐роЯро▓рпН роЙро░рпИропро╛роЯро▓рпИ роЗропроХрпНроХро╡рпБроорпН\n",
    "\n",
    "роЗрокрпНрокрпЛродрпБ роорпБро┤рпБроорпИропро╛рой роЙро░рпИропро╛роЯро▓рпИ роЗропроХрпНроХро┐ рокро╛ро░рпНрокрпНрокрпЛроорпН, роЗродрпБ роХрпАро┤рпНроХрогрпНроЯро╡ро▒рпНро▒рпИ ро╡ро┐ро│роХрпНроХрпБроХро┐ро▒родрпБ:\n",
    "1. роЖро░роорпНрок родро┐роЯрпНроЯрооро┐роЯро▓рпН роХрпЛро░ро┐роХрпНроХрпИ\n",
    "2. ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпИ роЪрпЗроХро░ро┐родрпНродро▓рпН\n",
    "3. рокропрог родро┐роЯрпНроЯроорпН роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН\n",
    "4. роЗроЯроорпН рооро╛ро▒рпНро▒роорпН\n",
    "5. роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпНро▒рпИ роХрпБро▒рпИродрпНродро▓рпН\n",
    "6. ро╕рпНроХро┐ро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН рокропройрпНрокро╛роЯрпБ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conversation flow\n",
    "user_inputs = [\n",
    "    \"I'm thinking about planning a vacation. Can you help me?\",\n",
    "    \"I love beach destinations with great food and culture. I enjoy water sports, exploring local markets, and trying authentic cuisine. My budget is around $3000 per person for a week.\",\n",
    "    \"That sounds perfect! Please create a detailed itinerary for Bali.\",\n",
    "    \"Actually, I've changed my mind. I'd prefer to go to the Greek islands instead. Can you create a new itinerary?\",\n",
    "    \"What's the weather like there?\",\n",
    "    \"What should I pack?\",\n",
    "    \"Are there any cultural customs I should know about?\",\n",
    "    \"What's the best way to get around?\"\n",
    "]\n",
    "\n",
    "\n",
    "async def run_vacation_planning():\n",
    "    \"\"\"Run the vacation planning conversation with token tracking and history reduction\"\"\"\n",
    "\n",
    "    # Create thread with history reducer\n",
    "    thread = ChatHistoryAgentThread(chat_history=history_reducer)\n",
    "    message_count = 0\n",
    "    scratchpad_operations = 0  # Track scratchpad usage\n",
    "\n",
    "    print(\"ЁЯЪА Starting Vacation Planning Session\\n\")\n",
    "\n",
    "    # Process conversation\n",
    "    for i, user_input in enumerate(user_inputs):\n",
    "        message_count += 1\n",
    "        display_message(\"User\", user_input, \"#4fc3f7\")  # Blue for user\n",
    "\n",
    "        # Get agent response\n",
    "        full_response = \"\"\n",
    "        usage = None\n",
    "        function_calls = []  # Track function calls\n",
    "\n",
    "        async for response in agent.invoke(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        ):\n",
    "            if response.content:\n",
    "                full_response += str(response.content)\n",
    "            if response.metadata.get(\"usage\"):\n",
    "                usage = response.metadata[\"usage\"]\n",
    "            thread = response.thread\n",
    "\n",
    "        display_message(f\"{agent.name}\", full_response,\n",
    "                        \"#81c784\")  # Green for agent\n",
    "\n",
    "        # Track tokens with thread length\n",
    "        if usage:\n",
    "            token_tracker.add_usage(usage, message_count, len(thread))\n",
    "\n",
    "        # Check thread status and look for scratchpad operations\n",
    "        print(f\"ЁЯУЭ Thread has {len(thread)} messages\")\n",
    "\n",
    "        # Count scratchpad operations in this turn\n",
    "        turn_scratchpad_ops = 0\n",
    "        async for msg in thread.get_messages():\n",
    "            if hasattr(msg, 'content') and msg.content:\n",
    "                content_str = str(msg.content)\n",
    "                if 'read_scratchpad' in content_str or 'update_scratchpad' in content_str:\n",
    "                    turn_scratchpad_ops += 1\n",
    "\n",
    "        if turn_scratchpad_ops > scratchpad_operations:\n",
    "            print(\n",
    "                f\"   ЁЯУЭ Scratchpad operations detected: {turn_scratchpad_ops - scratchpad_operations} new operations\")\n",
    "            scratchpad_operations = turn_scratchpad_ops\n",
    "\n",
    "        # Show message types for first message\n",
    "        if i == 0:\n",
    "            message_types = []\n",
    "            async for msg in thread.get_messages():\n",
    "                msg_type = msg.role.value if hasattr(\n",
    "                    msg.role, 'value') else str(msg.role)\n",
    "                message_types.append(msg_type)\n",
    "            print(f\"   Message types: {message_types[:10]}...\" if len(\n",
    "                message_types) > 10 else f\"   Message types: {message_types}\")\n",
    "\n",
    "        # Check if reduction should happen\n",
    "        if len(thread) > REDUCER_THRESHOLD:\n",
    "            print(\n",
    "                f\"   тЪая╕П Thread length ({len(thread)}) exceeds threshold ({REDUCER_THRESHOLD})\")\n",
    "\n",
    "            # Attempt reduction\n",
    "            is_reduced = await thread.reduce()\n",
    "            if is_reduced:\n",
    "                print(\n",
    "                    f\"\\nЁЯФД HISTORY REDUCED! Thread now has {len(thread)} messages\\n\")\n",
    "                token_tracker.mark_reduction(message_count + 1)\n",
    "\n",
    "                # Show summary if available\n",
    "                async for msg in thread.get_messages():\n",
    "                    if msg.metadata and msg.metadata.get(\"__summary__\"):\n",
    "                        display_message(\"System Summary\", str(\n",
    "                            msg.content), \"#ff6b6b\")\n",
    "                        break\n",
    "\n",
    "    # Display final token usage chart\n",
    "    print(\"\\n--- Token Usage Analysis ---\")\n",
    "    token_tracker.display_chart()\n",
    "\n",
    "    # Show final scratchpad contents\n",
    "    print(\"\\n--- Final Scratchpad Contents ---\")\n",
    "    scratchpad_contents = scratchpad_plugin.read_scratchpad()\n",
    "    display(Markdown(scratchpad_contents))\n",
    "\n",
    "    print(f\"\\nЁЯУК Total scratchpad operations: {scratchpad_operations}\")\n",
    "\n",
    "    return thread\n",
    "\n",
    "# Run the conversation\n",
    "thread = await run_vacation_planning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## роорпБроЯро┐ро╡рпБроХро│рпИ рокроХрпБрокрпНрокро╛ропрпНро╡рпБ роЪрпЖропрпНро╡родрпБ\n",
    "\n",
    "роироородрпБ роЙро░рпИропро╛роЯро▓ро┐ройрпН рокрпЛродрпБ роОройрпНрой роироЯроирпНродродрпБ роОройрпНрокродрпИрокрпН рокро╛ро░рпНрокрпНрокрпЛроорпН:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze token usage\n",
    "print(\"ЁЯУК Total Token Usage Summary\\n\")\n",
    "print(f\"Total Prompt Tokens: {token_tracker.total_usage.prompt_tokens:,}\")\n",
    "print(\n",
    "    f\"Total Completion Tokens: {token_tracker.total_usage.completion_tokens:,}\")\n",
    "print(\n",
    "    f\"Total Tokens Used: {token_tracker.total_usage.prompt_tokens + token_tracker.total_usage.completion_tokens:,}\")\n",
    "\n",
    "print(\"\\nЁЯТб Note: The reduction impact is shown in the chart above.\")\n",
    "print(\"Look for the dramatic drop in prompt tokens after the REDUCTION marker.\")\n",
    "print(\"This shows how chat history summarization reduces the context size for future messages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## роорпБроХрпНроХро┐роп роХрпБро▒ро┐рокрпНрокрпБроХро│рпН\n",
    "\n",
    "### 1. роЙро░рпИропро╛роЯро▓рпН ро╡ро░ро▓ро╛ро▒рпНро▒рпИ роХрпБро▒рпИродрпНродро▓рпН\n",
    "- **родро╛ройро┐ропроЩрпНроХро┐ропро╛роХ роЪрпЖропро▓рпНрокроЯрпБродрпНродро▓рпН**: роЪрпЖропрпНродро┐роХро│ро┐ройрпН роОрогрпНрогро┐роХрпНроХрпИ ро╡ро░роорпНрокрпИ роорпАро▒рпБроорпНрокрпЛродрпБ роХрпБро▒рпИрокрпНрокрпБ роиро┐роХро┤рпНроХро┐ро▒родрпБ\n",
    "- **роЯрпЛроХрпНроХройрпН роЪрпЗрооро┐рокрпНрокрпБ**: роЪрпБро░рпБроХрпНроХродрпНродро┐ро▒рпНроХрпБрокрпН рокро┐ро▒роХрпБ роЯрпЛроХрпНроХройрпН рокропройрпНрокро╛роЯрпНроЯро┐ро▓рпН роХрпБро▒ро┐рокрпНрокро┐роЯродрпНродроХрпНроХ роХрпБро▒рпИрокрпНрокрпБ\n",
    "- **роЪрпВро┤ро▓рпН рокро╛родрпБроХро╛рокрпНрокрпБ**: роорпБроХрпНроХро┐ропрооро╛рой родроХро╡ро▓рпНроХро│рпН роЪрпБро░рпБроХрпНроХроЩрпНроХро│ро┐ро▓рпН рокро╛родрпБроХро╛роХрпНроХрокрпНрокроЯрпБроХро┐ройрпНро▒рой\n",
    "\n",
    "### 2. роПроЬрпЖройрпНроЯрпН ро╕рпНроХро┐ро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН роиройрпНроорпИроХро│рпН\n",
    "- **роиро┐ро▓рпИропро╛рой роиро┐ройрпИро╡роХроорпН**: рокропройро░рпН ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпН ро╡ро░ро▓ро╛ро▒рпНро▒рпБ роХрпБро▒рпИрокрпНрокро┐ро▒рпНроХрпБрокрпН рокро┐ро▒роХрпБроорпН роиро┐ро▓рпИродрпНродро┐ро░рпБроХрпНроХро┐ройрпНро▒рой\n",
    "- **рокрогро┐роХро│рпИ роХрогрпНроХро╛рогро┐родрпНродро▓рпН**: роПроЬрпЖройрпНроЯрпН роорпБроЯро┐роХрпНроХрокрпНрокроЯрпНроЯ рокрогро┐роХро│ро┐ройрпН рокродро┐ро╡рпИ рокро░ро╛рооро░ро┐роХрпНроХро┐ро▒родрпБ\n",
    "- **роорпЗроорпНрокроЯрпНроЯ роЕройрпБрокро╡роорпН**: ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпИ роорпАрогрпНроЯрпБроорпН роХрпВро▒ родрпЗро╡рпИропро┐ро▓рпНро▓рпИ\n",
    "\n",
    "### 3. роЯрпЛроХрпНроХройрпН рокропройрпНрокро╛роЯрпНроЯрпБ роорпБро▒рпИ\n",
    "- **роирпЗро░ро┐ропро▓рпН ро╡ро│ро░рпНроЪрпНроЪро┐**: роТро╡рпНро╡рпКро░рпБ роЪрпЖропрпНродро┐ропрпБроЯройрпН роЯрпЛроХрпНроХройрпНроХро│рпН роЕродро┐роХро░ро┐роХрпНроХро┐ройрпНро▒рой\n",
    "- **роХрпБро▒ро┐рокрпНрокро┐роЯродрпНродроХрпНроХ роХрпБро▒рпИро╡рпБ**: роХрпБро▒рпИрокрпНрокрпБ роЯрпЛроХрпНроХройрпН роОрогрпНрогро┐роХрпНроХрпИропрпИ рокрпЖро░ро┐родрпБроорпН роХрпБро▒рпИроХрпНроХро┐ро▒родрпБ\n",
    "- **роиро┐ро▓рпИропро╛рой роЙро░рпИропро╛роЯро▓рпНроХро│рпН**: ро╡ро░роорпНрокрпБроХро│рпБроХрпНроХрпБро│рпН роирпАрогрпНроЯ роЙро░рпИропро╛роЯро▓рпНроХро│рпИ роЪро╛родрпНродро┐ропрооро╛роХрпНроХрпБроХро┐ро▒родрпБ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## роЪрпБродрпНродроорпН роЪрпЖропрпНропрпБродро▓рпН\n",
    "\n",
    "роЗроирпНрод роЯрпЖроорпЛро╡ро┐ройрпН рокрпЛродрпБ роЙро░рпБро╡ро╛роХрпНроХрокрпНрокроЯрпНроЯ ро╕рпНроХро┐ро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН роХрпЛрокрпНрокрпИ роЪрпБродрпНродроорпН роЪрпЖропрпНропро╡рпБроорпН:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up the scratchpad file\n",
    "# Uncomment the next line to delete the scratchpad\n",
    "# Path(\"vacation_agent_scratchpad.md\").unlink(missing_ok=True)\n",
    "\n",
    "print(\"тЬЕ Demo complete! The scratchpad file 'vacation_agent_scratchpad.md' has been preserved for your review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# роЪрпБро░рпБроХрпНроХроорпН\n",
    "\n",
    "ро╡ро╛ро┤рпНродрпНродрпБроХрпНроХро│рпН! роирпАроЩрпНроХро│рпН роорпЗроорпНрокроЯрпНроЯ роЪрпВро┤ро▓рпН роорпЗро▓ро╛рогрпНроорпИ родро┐ро▒ройрпНроХро│рпБроЯройрпН AI роорпБроХро╡ро░ро┐ропрпИ ро╡рпЖро▒рпНро▒ро┐роХро░рооро╛роХ роЪрпЖропро▓рпНрокроЯрпБродрпНродро┐ропрпБро│рпНро│рпАро░рпНроХро│рпН:\n",
    "\n",
    "## роирпАроЩрпНроХро│рпН роХро▒рпНро▒рпБроХрпНроХрпКрогрпНроЯро╡рпИ:\n",
    "- **роЪрпЖропрпНродро┐ ро╡ро░ро▓ро╛ро▒рпНро▒рпИ роЪрпБро░рпБроХрпНроХрпБродро▓рпН**: роЯрпЛроХрпНроХройрпН ро╡ро░роорпНрокрпБроХро│рпИ роиро┐ро░рпНро╡роХро┐роХрпНроХ роЙро░рпИропро╛роЯро▓рпНроХро│рпИ родро╛ройро╛роХ роЪрпБро░рпБроХрпНроХрпБродро▓рпН\n",
    "- **роорпБроХро╡ро░рпН ро╕рпНроХро┐ро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН**: рокропройро░рпН ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпН рооро▒рпНро▒рпБроорпН роорпБроЯро┐роХрпНроХрокрпНрокроЯрпНроЯ рокрогро┐роХро│рпБроХрпНроХро╛рой роиро┐ро▓рпИропро╛рой роиро┐ройрпИро╡роХродрпНродрпИ роЪрпЖропро▓рпНрокроЯрпБродрпНродрпБродро▓рпН\n",
    "- **роЯрпЛроХрпНроХройрпН роорпЗро▓ро╛рогрпНроорпИ**: роирпАрогрпНроЯ роЙро░рпИропро╛роЯро▓рпНроХро│ро┐ро▓рпН роЯрпЛроХрпНроХройрпН рокропройрпНрокро╛роЯрпНроЯрпИ роХрогрпНроХро╛рогро┐родрпНродрпБ роорпЗроорпНрокроЯрпБродрпНродрпБродро▓рпН\n",
    "- **роЪрпВро┤ро▓рпН рокро╛родрпБроХро╛рокрпНрокрпБ**: роЙро░рпИропро╛роЯро▓рпН роЪрпБро░рпБроХрпНроХроЩрпНроХро│ро┐ро▓рпН роорпБроХрпНроХро┐роп родроХро╡ро▓рпНроХро│рпИ рокро░ро╛рооро░ро┐родрпНродро▓рпН\n",
    "\n",
    "## роиро┐роЬ ро╡ро╛ро┤рпНроХрпНроХрпИ рокропройрпНрокро╛роЯрпБроХро│рпН:\n",
    "- **ро╡ро╛роЯро┐роХрпНроХрпИропро╛ро│ро░рпН роЪрпЗро╡рпИ рокро╛роЯрпНроЯрпБроХро│рпН**: роЕрооро░рпНро╡рпБроХро│рпБроХрпНроХрпБ роЗроЯрпИропро┐ро▓рпН ро╡ро╛роЯро┐роХрпНроХрпИропро╛ро│ро░рпН ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпИ роиро┐ройрпИро╡ро┐ро▓рпН роХрпКро│рпНро│рпБродро▓рпН\n",
    "- **родройро┐рокрпНрокроЯрпНроЯ роЙродро╡ро┐ропро╛ро│ро░рпНроХро│рпН**: роироЯроирпНродрпБ роХрпКрогрпНроЯро┐ро░рпБроХрпНроХрпБроорпН родро┐роЯрпНроЯроЩрпНроХро│рпН рооро▒рпНро▒рпБроорпН рокропройро░рпН рокро┤роХрпНроХроЩрпНроХро│рпИ роХрогрпНроХро╛рогро┐родрпНродро▓рпН\n",
    "- **роХро▓рпНро╡ро┐ роЖроЪро┐ро░ро┐ропро░рпНроХро│рпН**: рооро╛рогро╡ро░рпН роорпБройрпНройрпЗро▒рпНро▒роорпН рооро▒рпНро▒рпБроорпН роХро▒рпНро▒ро▓рпН ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпИ рокро░ро╛рооро░ро┐родрпНродро▓рпН\n",
    "- **роЪрпБроХро╛родро╛ро░ роЙродро╡ро┐ропро╛ро│ро░рпНроХро│рпН**: роЯрпЛроХрпНроХройрпН ро╡ро░роорпНрокрпБроХро│рпИ роородро┐роХрпНроХрпБроорпНрокрпЛродрпБ роирпЛропро╛ро│ро┐ ро╡ро░ро▓ро╛ро▒рпНро▒рпИ ро╡рпИродрпНродро┐ро░рпБродрпНродро▓рпН\n",
    "\n",
    "## роЕроЯрпБродрпНрод рокроЯро┐роХро│рпН:\n",
    "- роорпЗро▓рпБроорпН роорпЗроорпНрокроЯрпНроЯ ро╕рпНроХро┐ро░ро╛роЯрпНроЪрпНрокрпЗроЯрпН ро╕рпНроХрпАрооро╛роХрпНроХро│рпИ роЪрпЖропро▓рпНрокроЯрпБродрпНродрпБродро▓рпН\n",
    "- рокро▓ рокропройро░рпН роЪрпВро┤ро▓рпНроХро│рпБроХрпНроХрпБ родро░ро╡рпБродрпНродрпКроХрпБрокрпНрокрпБ роЪрпЗрооро┐рокрпНрокрпИ роЪрпЗро░рпНродрпНродро▓рпН\n",
    "- родрпБро▒рпИроХрпНроХрпБ роЪро┐ро▒рокрпНрокро╛рой родрпЗро╡рпИроХро│рпБроХрпНроХро╛рой родройро┐рокрпНрокропройрпН роЪрпБро░рпБроХрпНроХ роЙродрпНродро┐роХро│рпИ роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН\n",
    "- роЕро░рпНродрпНродрооро╛рой роиро┐ройрпИро╡роХ родрпЗроЯро▓рпБроХрпНроХро╛роХ ро╡рпЖроХрпНроЯро░рпН родро░ро╡рпБродрпНродрпКроХрпБрокрпНрокрпБроХро│рпБроЯройрпН роЗрогрпИродрпНродро▓рпН\n",
    "- роорпБро┤рпБ роЪрпВро┤ро▓рпБроЯройрпН роиро╛роЯрпНроХро│рпБроХрпНроХрпБ рокро┐ро▒роХрпБ роЙро░рпИропро╛роЯро▓рпНроХро│рпИ роорпАрогрпНроЯрпБроорпН родрпКроЯроЩрпНроХрпБроорпН роорпБроХро╡ро░рпНроХро│рпИ роЙро░рпБро╡ро╛роХрпНроХрпБродро▓рпН\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**роХрпБро▒ро┐рокрпНрокрпБ**:  \nроЗроирпНрод роЖро╡рогроорпН [Co-op Translator](https://github.com/Azure/co-op-translator) роОройрпНро▒ AI роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ роЪрпЗро╡рпИропрпИрокрпН рокропройрпНрокроЯрпБродрпНродро┐ роорпКро┤ро┐рокрпЖропро░рпНроХрпНроХрокрпНрокроЯрпНроЯрпБро│рпНро│родрпБ. роиро╛роЩрпНроХро│рпН родрпБро▓рпНро▓ро┐ропродрпНродро┐ро▒рпНроХро╛роХ роорпБропро▒рпНроЪро┐роХрпНроХро┐ройрпНро▒рпЛроорпН, роЖройро╛ро▓рпН родро╛ройро┐ропроХрпНроХ роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБроХро│ро┐ро▓рпН рокро┐ро┤рпИроХро│рпН роЕро▓рпНро▓родрпБ родро╡ро▒ро╛рой родроХро╡ро▓рпНроХро│рпН роЗро░рпБроХрпНроХроХрпНроХрпВроЯрпБроорпН роОройрпНрокродрпИ родропро╡рпБроЪрпЖропрпНродрпБ роХро╡ройродрпНродро┐ро▓рпН роХрпКро│рпНро│рпБроЩрпНроХро│рпН. роЕродройрпН родро╛ропрпНроорпКро┤ро┐ропро┐ро▓рпН роЙро│рпНро│ роорпВро▓ роЖро╡рогроорпН роЕродро┐роХро╛ро░рокрпНрокрпВро░рпНро╡ роЖродро╛ро░рооро╛роХ роХро░рпБродрокрпНрокроЯ ро╡рпЗрогрпНроЯрпБроорпН. роорпБроХрпНроХро┐ропрооро╛рой родроХро╡ро▓рпНроХро│рпБроХрпНроХрпБ, родрпКро┤ро┐ро▓рпНроорпБро▒рпИ рооройро┐род роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ рокро░ро┐роирпНродрпБро░рпИроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ. роЗроирпНрод роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпИрокрпН рокропройрпНрокроЯрпБродрпНродрпБро╡родро╛ро▓рпН роПро▒рпНрокроЯрпБроорпН роОроирпНрод родро╡ро▒ро╛рой рокрпБро░ро┐родро▓рпНроХро│рпН роЕро▓рпНро▓родрпБ родро╡ро▒ро╛рой ро╡ро┐ро│роХрпНроХроЩрпНроХро│рпБроХрпНроХрпБ роиро╛роЩрпНроХро│рпН рокрпКро▒рпБрокрпНрокро▓рпНро▓.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "5734816b6bfc1849034b4c4ef0267d18",
   "translation_date": "2025-10-11T11:59:08+00:00",
   "source_file": "12-context-engineering/code_samples/12-chat_summarization.ipynb",
   "language_code": "ta"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}