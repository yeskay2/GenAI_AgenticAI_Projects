{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Construir Agentes de IA com Mem√≥ria Persistente usando Cognee\n",
    "\n",
    "Este notebook demonstra como criar agentes de IA inteligentes com capacidades avan√ßadas de mem√≥ria utilizando [**cognee**](https://www.cognee.ai/) - uma mem√≥ria de IA de c√≥digo aberto que combina grafos de conhecimento, pesquisa sem√¢ntica e gest√£o de sess√µes para criar sistemas de IA com consci√™ncia de contexto.\n",
    "\n",
    "## üéØ Objetivos de Aprendizagem\n",
    "\n",
    "Ao final deste tutorial, voc√™ entender√° como:\n",
    "- **Construir Grafos de Conhecimento Baseados em Embeddings**: Transformar texto n√£o estruturado em conhecimento estruturado e consult√°vel\n",
    "- **Implementar Mem√≥ria de Sess√£o**: Criar conversas de m√∫ltiplas intera√ß√µes com reten√ß√£o autom√°tica de contexto\n",
    "- **Persistir Conversas**: Armazenar opcionalmente intera√ß√µes importantes em mem√≥ria de longo prazo para refer√™ncia futura\n",
    "- **Consultar Usando Linguagem Natural**: Acessar e aproveitar o contexto hist√≥rico em novas conversas\n",
    "- **Visualizar Mem√≥ria**: Explorar as rela√ß√µes no grafo de conhecimento do seu agente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è O Que Ir√° Construir\n",
    "\n",
    "Neste tutorial, vamos criar um **Assistente de Programa√ß√£o** com mem√≥ria persistente que:\n",
    "\n",
    "### 1. **Constru√ß√£o de Base de Conhecimento**\n",
    "   - Recolhe informa√ß√µes sobre o perfil e a experi√™ncia do programador\n",
    "   - Processa princ√≠pios e boas pr√°ticas de programa√ß√£o em Python\n",
    "   - Armazena conversas hist√≥ricas entre programadores e assistentes de IA\n",
    "\n",
    "### 2. **Conversas Sens√≠veis ao Contexto**\n",
    "   - Mant√©m o contexto ao longo de v√°rias perguntas na mesma sess√£o\n",
    "   - Armazena automaticamente cada par de pergunta/resposta para recupera√ß√£o eficiente\n",
    "   - Fornece respostas coerentes e contextuais com base no hist√≥rico da conversa\n",
    "\n",
    "### 3. **Mem√≥ria de Longo Prazo**\n",
    "   - Persiste conversas importantes numa mem√≥ria de longo prazo\n",
    "   - Recupera mem√≥rias relevantes da base de conhecimento e de sess√µes passadas para informar novas intera√ß√µes\n",
    "   - Constr√≥i uma base de conhecimento crescente que melhora ao longo do tempo\n",
    "\n",
    "### 4. **Recupera√ß√£o Inteligente de Mem√≥ria**\n",
    "   - Utiliza pesquisa sem√¢ntica baseada em grafos para encontrar informa√ß√µes relevantes em todo o conhecimento armazenado\n",
    "   - Filtra pesquisas por subgrupos de dados (informa√ß√µes do programador vs. princ√≠pios)\n",
    "   - Combina m√∫ltiplas fontes de dados para fornecer respostas abrangentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Pr√©-requisitos e Configura√ß√£o\n",
    "\n",
    "### Requisitos do Sistema\n",
    "\n",
    "Antes de come√ßar, certifique-se de ter:\n",
    "\n",
    "1. **Ambiente Python**\n",
    "   - Python 3.9 ou superior\n",
    "   - Ambiente virtual (recomendado)\n",
    "   \n",
    "2. **Cache Redis** (Necess√°rio para Gest√£o de Sess√µes)\n",
    "   - Redis local: `docker run -d -p 6379:6379 redis`\n",
    "   - Ou utilize um servi√ßo Redis gerido\n",
    "   \n",
    "3. **Acesso √† API LLM**\n",
    "   - Chave de API OpenAI ou outros fornecedores (consulte [documenta√ß√£o](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Configura√ß√£o de Base de Dados**\n",
    "   - Nenhuma configura√ß√£o necess√°ria por padr√£o. O Cognee utiliza bases de dados baseadas em ficheiros (LanceDB e Kuzu)\n",
    "   - Opcionalmente, pode configurar o Azure AI Search como um reposit√≥rio vetorial (consulte [documenta√ß√£o](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Configura√ß√£o do Ambiente\n",
    "\n",
    "Crie um ficheiro `.env` no diret√≥rio do seu projeto com as seguintes vari√°veis:\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Compreendendo a Arquitetura de Mem√≥ria do Cognee\n",
    "\n",
    "### Como o Cognee Funciona\n",
    "\n",
    "O Cognee oferece um sistema de mem√≥ria sofisticado que vai al√©m do armazenamento simples de chave-valor:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Componentes Principais:\n",
    "\n",
    "1. **Knowledge Graph**: Armazena entidades, rela√ß√µes e conex√µes sem√¢nticas\n",
    "2. **Vector Embeddings**: Permite pesquisa sem√¢ntica em todas as informa√ß√µes armazenadas\n",
    "3. **Session Cache**: Mant√©m o contexto da conversa dentro e entre sess√µes\n",
    "4. **NodeSets**: Organizam os dados em categorias l√≥gicas para recupera√ß√£o direcionada\n",
    "\n",
    "### Tipos de Mem√≥ria Neste Tutorial:\n",
    "\n",
    "- **Mem√≥ria Persistente**: Armazenamento de longo prazo no knowledge graph\n",
    "- **Mem√≥ria de Sess√£o**: Contexto tempor√°rio de conversa√ß√£o no cache Redis\n",
    "- **Mem√≥ria Sem√¢ntica**: Pesquisa baseada em similaridade vetorial em todos os dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Instalar Pacotes Necess√°rios\n",
    "\n",
    "Instale o Cognee com suporte ao Redis para gest√£o de sess√µes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß Inicializar Ambiente e Carregar Bibliotecas\n",
    "\n",
    "Certifique-se de que:\n",
    "1. O Redis est√° em execu√ß√£o (por exemplo, via Docker: `docker run -d -p 6379:6379 redis`)\n",
    "2. As vari√°veis de ambiente est√£o definidas antes de importar os m√≥dulos de cache\n",
    "3. Se necess√°rio, reinicie o kernel e execute as c√©lulas na ordem correta\n",
    "\n",
    "A c√©lula seguinte ir√°:\n",
    "1. Carregar vari√°veis de ambiente a partir do ficheiro `.env`\n",
    "2. Configurar o Cognee com as suas defini√ß√µes de LLM\n",
    "3. Ativar o cache para gest√£o de sess√µes\n",
    "4. Validar que todos os componentes est√£o devidamente conectados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ Configurar Diret√≥rios de Armazenamento\n",
    "\n",
    "O Cognee utiliza dois diret√≥rios separados para as suas opera√ß√µes:\n",
    "- **Data Root**: Armazena documentos ingeridos e dados processados\n",
    "- **System Root**: Cont√©m a base de dados do grafo de conhecimento e metadados do sistema\n",
    "\n",
    "Vamos criar diret√≥rios isolados para este tutorial da seguinte forma:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ Repor o Estado da Mem√≥ria\n",
    "\n",
    "Antes de come√ßarmos a construir o nosso sistema de mem√≥ria, vamos garantir que estamos a come√ßar do zero.\n",
    "\n",
    "> üí° **Dica**: Pode ignorar este passo se quiser preservar mem√≥rias existentes das suas execu√ß√µes anteriores ao usar este notebook mais tarde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Parte 1: Construir a Base de Conhecimento\n",
    "\n",
    "### Fontes de Dados para o Nosso Assistente de Desenvolvedor\n",
    "\n",
    "Vamos integrar tr√™s tipos de dados para criar uma base de conhecimento abrangente:\n",
    "\n",
    "1. **Perfil do Desenvolvedor**: Experi√™ncia pessoal e forma√ß√£o t√©cnica  \n",
    "2. **Melhores Pr√°ticas em Python**: O Zen do Python com diretrizes pr√°ticas  \n",
    "3. **Conversas Hist√≥ricas**: Sess√µes de perguntas e respostas anteriores entre desenvolvedores e assistentes de IA  \n",
    "\n",
    "Estes dados diversificados permitem que o nosso agente:  \n",
    "- Compreenda o contexto t√©cnico do utilizador  \n",
    "- Aplique as melhores pr√°ticas nas recomenda√ß√µes  \n",
    "- Aprenda com intera√ß√µes bem-sucedidas anteriores  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Processar Dados em um Grafo de Conhecimento\n",
    "\n",
    "Agora vamos transformar o nosso texto bruto em uma mem√≥ria estruturada. Este processo:\n",
    "\n",
    "1. **Adiciona dados aos NodeSets**: Organiza informa√ß√µes em categorias l√≥gicas\n",
    "   - `developer_data`: Perfil do desenvolvedor e conversas\n",
    "   - `principles_data`: Melhores pr√°ticas e diretrizes de Python\n",
    "\n",
    "2. **Executa o Cognify Pipeline**: Extrai entidades, relacionamentos e cria embeddings\n",
    "   - Identifica conceitos-chave\n",
    "   - Cria conex√µes sem√¢nticas entre informa√ß√µes relacionadas\n",
    "   - Gera embeddings vetoriais\n",
    "\n",
    "Isto pode levar alguns momentos enquanto o LLM processa o texto e constr√≥i a estrutura do grafo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä Visualizar o Grafo de Conhecimento\n",
    "\n",
    "Vamos explorar a estrutura do nosso grafo de conhecimento. A visualiza√ß√£o mostra:\n",
    "- **N√≥s**: Entidades extra√≠das do texto (conceitos, tecnologias, pessoas)\n",
    "- **Arestas**: Rela√ß√µes e conex√µes entre as entidades\n",
    "- **Clusters**: Conceitos relacionados agrupados por similaridade sem√¢ntica\n",
    "\n",
    "Abra o ficheiro HTML gerado no seu navegador para explorar o grafo de forma interativa:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Enriquecer a Mem√≥ria com Memify\n",
    "\n",
    "A fun√ß√£o `memify()` analisa o grafo de conhecimento e gera regras inteligentes sobre os dados. Este processo:\n",
    "- Identifica padr√µes e melhores pr√°ticas\n",
    "- Cria diretrizes acion√°veis com base no conte√∫do\n",
    "- Estabelece rela√ß√µes entre diferentes √°reas de conhecimento\n",
    "\n",
    "Estas regras ajudam o agente a tomar decis√µes mais informadas ao responder a perguntas. Capturar uma segunda visualiza√ß√£o ajuda a comparar como o grafo se densifica ap√≥s ser enriquecido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Parte 2: Recupera√ß√£o Inteligente de Mem√≥ria\n",
    "\n",
    "### Demonstra√ß√£o 1: Integra√ß√£o de Conhecimento entre Documentos\n",
    "\n",
    "Agora que o nosso grafo de conhecimento est√° constru√≠do, vamos testar como o Cognee combina informa√ß√µes de v√°rias fontes para responder a perguntas complexas.\n",
    "\n",
    "A primeira consulta demonstra:\n",
    "- **Compreens√£o sem√¢ntica**: Encontrar conceitos relevantes mesmo quando n√£o mencionados explicitamente\n",
    "- **Referenciamento cruzado**: Combinar o perfil do desenvolvedor com princ√≠pios de Python\n",
    "- **Racioc√≠nio contextual**: Aplicar as melhores pr√°ticas a implementa√ß√µes espec√≠ficas\n",
    "\n",
    "### Demonstra√ß√£o 2: Pesquisa Filtrada com NodeSets\n",
    "\n",
    "A segunda consulta mostra como direcionar subconjuntos espec√≠ficos do grafo de conhecimento:\n",
    "- Utiliza o par√¢metro `node_name` para pesquisar apenas dentro de `principles_data`\n",
    "- Fornece respostas focadas de um dom√≠nio de conhecimento espec√≠fico\n",
    "- √ötil quando precisa de informa√ß√µes espec√≠ficas de um dom√≠nio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Parte 3: Configura√ß√£o da Gest√£o de Sess√µes\n",
    "\n",
    "### Ativar Mem√≥ria de Conversa√ß√£o\n",
    "\n",
    "A gest√£o de sess√µes √© essencial para manter o contexto ao longo de v√°rias intera√ß√µes. Aqui iremos:\n",
    "\n",
    "1. **Inicializar o Contexto do Utilizador**: Criar ou recuperar um perfil de utilizador para rastreamento da sess√£o  \n",
    "2. **Configurar o Motor de Cache**: Ligar ao Redis para armazenar o hist√≥rico de conversas  \n",
    "3. **Ativar Vari√°veis de Sess√£o**: Configurar vari√°veis de contexto que persistem entre consultas  \n",
    "\n",
    "> ‚ö†Ô∏è **Importante**: Isto requer que o Redis esteja em execu√ß√£o e `CACHING=true` no seu ambiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Fun√ß√£o Auxiliar: Ver Hist√≥rico de Sess√£o\n",
    "\n",
    "Esta fun√ß√£o utilit√°ria permite-nos inspecionar o hist√≥rico de conversa√ß√£o armazenado no Redis. √â √∫til para:\n",
    "- Depurar a gest√£o de sess√µes\n",
    "- Verificar se as conversas est√£o a ser armazenadas em cache\n",
    "- Compreender que contexto est√° dispon√≠vel para o agente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Sess√£o 1: Laborat√≥rio de Suporte Ass√≠ncrono ‚Äî Primeira Pergunta\n",
    "\n",
    "Inicie a sess√£o `async-support-lab` perguntando sobre padr√µes de asyncio compat√≠veis com telemetria para um web scraper em larga escala. O gr√°fico j√° conhece asyncio, aiohttp e pr√°ticas de monitoriza√ß√£o, ent√£o a resposta deve refletir conversas anteriores enquanto adapta a resposta √† nova pergunta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Inspecionar a Mem√≥ria da Sess√£o 1 Ap√≥s a Primeira Troca\n",
    "\n",
    "Executar `show_history(session_1)` imediatamente ap√≥s a pergunta inicial confirma que o Cognee gravou tanto o prompt quanto a resposta no Redis. Deve ver uma entrada com a orienta√ß√£o de concorr√™ncia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Sess√£o 1: Acompanhamento sobre Modelos de Dados\n",
    "\n",
    "A seguir, perguntamos: \"Quando devo escolher dataclasses em vez de Pydantic?\" usando o mesmo ID de sess√£o. Cognee deve combinar os princ√≠pios do Python com conversas anteriores sobre FastAPI para fornecer conselhos detalhados‚Äîdemonstrando que o contexto √© mantido dentro de uma sess√£o nomeada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Confirmar que o Hist√≥rico da Sess√£o 1 Cont√©m Ambos os Turnos\n",
    "\n",
    "Outra chamada a `show_history(session_1)` deve revelar duas entradas de Pergunta e Resposta. Isto corresponde ao passo de \"replay de mem√≥ria\" do laborat√≥rio Mem0 e prova que turnos adicionais prolongam a mesma transcri√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Sess√£o 2: T√≥pico de Revis√£o de Design ‚Äî Nova Sess√£o\n",
    "\n",
    "Para demonstrar isolamento entre t√≥picos, iniciamos `design-review-session` e pedimos orienta√ß√µes de registo para revis√µes de incidentes. Embora a base de conhecimento subjacente seja a mesma, o novo ID de sess√£o mant√©m as transcri√ß√µes separadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## Revis√£o da Sess√£o 2 Hist√≥ria\n",
    "\n",
    "`show_history(session_2)` deve listar apenas o par de solicita√ß√£o/resposta da revis√£o de design. Compare com a Sess√£o 1 para destacar como o Cognee mant√©m transcri√ß√µes independentes enquanto reutiliza o grafo de conhecimento compartilhado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "Parab√©ns! Acabou de dar ao seu assistente de programa√ß√£o uma camada de mem√≥ria de longo prazo alimentada pelo Cognee.\n",
    "\n",
    "Neste tutorial, pegou conte√∫do bruto de desenvolvedores (c√≥digo, documentos, conversas) e transformou-o numa mem√≥ria em grafo + vetor que o seu agente pode pesquisar, raciocinar e melhorar continuamente.\n",
    "\n",
    "O que Aprendeu\n",
    "\n",
    "1. **De texto bruto a mem√≥ria de IA**: Como o Cognee processa dados n√£o estruturados e os transforma numa mem√≥ria inteligente e pesquis√°vel, utilizando uma arquitetura combinada de vetor + grafo de conhecimento.\n",
    "\n",
    "2. **Enriquecimento de grafos com memify**: Como ir al√©m da cria√ß√£o b√°sica de grafos e usar o memify para adicionar factos derivados e rela√ß√µes mais ricas ao seu grafo existente.\n",
    "\n",
    "3. **M√∫ltiplas estrat√©gias de pesquisa**: Como consultar a mem√≥ria com diferentes tipos de pesquisa (Q&A com consci√™ncia de grafo, conclus√£o ao estilo RAG, insights, fragmentos brutos, pesquisa de c√≥digo, etc.), dependendo das necessidades do seu agente.\n",
    "\n",
    "4. **Explora√ß√£o visual**: Como inspecionar e depurar o que o Cognee construiu utilizando visualiza√ß√µes de grafos e a interface do Cognee, para que possa realmente ver como o conhecimento est√° estruturado.\n",
    "\n",
    "5. **Mem√≥ria sens√≠vel √† sess√£o**: Como combinar o contexto de cada sess√£o com uma mem√≥ria sem√¢ntica persistente, permitindo que os agentes se lembrem entre execu√ß√µes sem partilhar informa√ß√µes entre utilizadores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Principais Conclus√µes\n",
    "1. Mem√≥ria como um Grafo de Conhecimento suportado por Embeddings\n",
    "\n",
    "   - **Compreens√£o estruturada**: O Cognee combina um armazenamento vetorial e um armazenamento em grafo, permitindo que os seus dados sejam pesquis√°veis tanto por significado quanto conectados por rela√ß√µes. O Cognee utiliza bases de dados baseadas em ficheiros por padr√£o (LanceDB para armazenamento vetorial, Kuzu para base de dados em grafo).\n",
    "\n",
    "   - **Recupera√ß√£o consciente de rela√ß√µes**: As respostas podem ser fundamentadas n√£o apenas em \"texto semelhante\", mas tamb√©m em como as entidades se relacionam.\n",
    "\n",
    "   - **Mem√≥ria viva**: A camada de mem√≥ria evolui, cresce e permanece consult√°vel como um grafo conectado.\n",
    "\n",
    "2. Modos de Pesquisa e Racioc√≠nio\n",
    "   - **Recupera√ß√£o h√≠brida**: A pesquisa combina similaridade vetorial, estrutura de grafo e racioc√≠nio de LLM, desde a pesquisa de fragmentos brutos at√© respostas a perguntas conscientes do grafo.\n",
    "\n",
    "   - **Ajustar o modo √† tarefa**: Utilize modos de estilo de conclus√£o quando quiser respostas em linguagem natural, e modos de fragmento/resumo/grafo quando o seu agente precisar de contexto bruto ou para conduzir o seu pr√≥prio racioc√≠nio.\n",
    "\n",
    "3. Agentes Personalizados e Conscientes da Sess√£o\n",
    "   - **Contexto da sess√£o + mem√≥ria de longo prazo**: O Cognee mant√©m o contexto de \"fio\" de curto prazo separado da mem√≥ria de longo prazo, ao n√≠vel do utilizador ou da organiza√ß√£o.\n",
    "\n",
    "## Aplica√ß√µes no Mundo Real\n",
    "\n",
    "1. **Agentes de IA Verticais**\n",
    "\n",
    "   Utilize o padr√£o deste notebook para criar copilotos inteligentes em dom√≠nios espec√≠ficos que utilizam o Cognee como n√∫cleo de recupera√ß√£o e racioc√≠nio:\n",
    "\n",
    "- **Copilotos para programadores**: Revis√£o de c√≥digo, an√°lise de incidentes e assistentes de arquitetura que percorrem c√≥digo, APIs, documentos de design e tickets como um √∫nico grafo de mem√≥ria.\n",
    "\n",
    "- **Copilotos voltados para o cliente**: Agentes de suporte ou sucesso que extraem informa√ß√µes de documentos de produto, FAQs, notas de CRM e tickets anteriores com recupera√ß√£o consciente do grafo e respostas citadas.\n",
    "\n",
    "- **Copilotos especialistas internos**: Assistentes de pol√≠tica, jur√≠dico ou seguran√ßa que raciocinam sobre regras interconectadas, diretrizes e decis√µes hist√≥ricas em vez de PDFs isolados.\n",
    "\n",
    "   O Cognee posiciona-se explicitamente como uma mem√≥ria persistente e precisa para agentes de IA, fornecendo um grafo de conhecimento vivo que se integra ao seu agente e substitui combina√ß√µes ad hoc de armazenamentos vetoriais e c√≥digo de grafo personalizado.\n",
    "\n",
    "2. **Unificar Silos de Dados numa √önica Mem√≥ria**\n",
    "\n",
    "   A mesma abordagem tamb√©m ajuda a construir uma camada de mem√≥ria unificada a partir de fontes dispersas:\n",
    "\n",
    "- **De silos para um √∫nico grafo**: Ingest√£o de dados estruturados (por exemplo, bases de dados) e n√£o estruturados (por exemplo, documentos, chats) num √∫nico grafo suportado por embeddings, em vez de √≠ndices separados para cada sistema.\n",
    "\n",
    "- **Racioc√≠nio entre fontes com cita√ß√µes**: Realize racioc√≠nios em m√∫ltiplas etapas sobre tudo‚Äî\"junte\" registos, m√©tricas e documentos atrav√©s do grafo‚Äîe ainda assim devolva respostas fundamentadas com proveni√™ncia.\n",
    "\n",
    "- **Hubs de conhecimento**: Para dom√≠nios como banca ou educa√ß√£o, o Cognee j√° √© utilizado para unificar PDFs, sistemas internos e dados de aplica√ß√µes num √∫nico grafo de conhecimento com vetores, permitindo que os agentes respondam a perguntas com contexto preciso e citado.\n",
    "\n",
    "## Pr√≥ximos Passos\n",
    "\n",
    "J√° implementou o ciclo de mem√≥ria principal. Aqui est√£o extens√µes naturais que pode experimentar por conta pr√≥pria (consulte a [documenta√ß√£o do Cognee](https://docs.cognee.ai/) para mais detalhes):\n",
    "\n",
    "1. **Experimente a consci√™ncia temporal**: Ative o \"temporal cognify\" para extrair eventos e marcas temporais do texto.\n",
    "\n",
    "2. **Introduza racioc√≠nio orientado por ontologia**: Defina uma ontologia OWL para o seu dom√≠nio. Utilize o suporte de ontologia do Cognee para que as entidades e rela√ß√µes extra√≠das sejam fundamentadas nesse esquema, melhorando a qualidade do grafo e as respostas espec√≠ficas do dom√≠nio.\n",
    "\n",
    "3. **Adicione um ciclo de feedback**: Permita que o Cognee ajuste os pesos das arestas do grafo com base no feedback real dos utilizadores, para que a recupera√ß√£o melhore ao longo do tempo em vez de permanecer est√°tica.\n",
    "\n",
    "4. **Ajuste para personaliza√ß√£o e comportamento de sess√£o**: Utilize IDs de utilizador, inquilinos e conjuntos de dados para oferecer a cada pessoa ou equipa a sua pr√≥pria vis√£o sobre o motor de mem√≥ria partilhado.\n",
    "\n",
    "5. **Expanda para agentes mais complexos**: Integre o Cognee em frameworks de agentes para construir sistemas multiagente que partilhem a mesma camada de mem√≥ria. *O plugin Microsoft Agent Framework x Cognee est√° a caminho.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:47:11+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "pt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}