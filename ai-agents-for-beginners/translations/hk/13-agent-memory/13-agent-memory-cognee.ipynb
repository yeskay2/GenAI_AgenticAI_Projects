{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# 使用 Cognee 建立具持久記憶的 AI 智能代理\n",
    "\n",
    "此筆記本展示如何使用 [**cognee**](https://www.cognee.ai/) 建立具備高級記憶功能的智能 AI 代理。Cognee 是一個開源的 AI 記憶系統，結合知識圖譜、語義搜索及會話管理，打造具上下文感知能力的 AI 系統。\n",
    "\n",
    "## 🎯 學習目標\n",
    "\n",
    "完成本教程後，您將了解如何：\n",
    "- **建立基於嵌入的知識圖譜**：將非結構化文本轉化為結構化、可查詢的知識\n",
    "- **實現會話記憶**：創建多輪對話並自動保留上下文\n",
    "- **持久化對話**：選擇性地將重要互動存儲於長期記憶中以供未來參考\n",
    "- **使用自然語言查詢**：在新對話中訪問並利用歷史上下文\n",
    "- **可視化記憶**：探索代理知識圖譜中的關係\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## 🏗️ 你將會建立什麼\n",
    "\n",
    "在這個教學中，我們會建立一個具有持久記憶的 **編程助手**，它能夠：\n",
    "\n",
    "### 1. **知識庫建構**\n",
    "   - 收集開發者的個人資料及專業資訊\n",
    "   - 處理 Python 編程原則及最佳實踐\n",
    "   - 儲存開發者與 AI 助手之間的歷史對話\n",
    "\n",
    "### 2. **會話感知功能**\n",
    "   - 在同一個會話中保持多個問題的上下文\n",
    "   - 自動緩存每個問題及答案以便高效檢索\n",
    "   - 根據對話歷史提供連貫且有上下文的回應\n",
    "\n",
    "### 3. **長期記憶**\n",
    "   - 將重要的對話保存到長期記憶中\n",
    "   - 從知識庫及過往會話中檢索相關記憶以輔助新的互動\n",
    "   - 建立一個隨時間增長的知識庫，持續改進\n",
    "\n",
    "### 4. **智能記憶檢索**\n",
    "   - 使用圖形感知語義搜索來尋找所有儲存知識中的相關資訊\n",
    "   - 按數據子組（例如開發者資訊 vs. 原則）篩選搜索結果\n",
    "   - 結合多個數據來源以提供全面的答案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## 📋 先決條件及設定\n",
    "\n",
    "### 系統需求\n",
    "\n",
    "在開始之前，請確保你已準備好以下項目：\n",
    "\n",
    "1. **Python 環境**\n",
    "   - Python 3.9 或更高版本\n",
    "   - 建議使用虛擬環境\n",
    "\n",
    "2. **Redis 快取**（用於會話管理）\n",
    "   - 本地 Redis：`docker run -d -p 6379:6379 redis`\n",
    "   - 或使用托管的 Redis 服務\n",
    "\n",
    "3. **LLM API 訪問**\n",
    "   - OpenAI API 金鑰或其他供應商（請參閱[文件](https://docs.cognee.ai/setup-configuration/llm-providers)）\n",
    "\n",
    "4. **資料庫配置**\n",
    "   - 預設情況下無需配置。Cognee 使用基於文件的資料庫（LanceDB 和 Kuzu）\n",
    "   - 可選地，你可以設置 Azure AI Search 作為向量存儲（請參閱[文件](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch)）\n",
    "\n",
    "### 環境配置\n",
    "\n",
    "在你的項目目錄中建立 `.env` 文件，並包含以下變數：\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## 🏛️ Cognee 記憶架構的理解\n",
    "\n",
    "### Cognee 的運作方式\n",
    "\n",
    "Cognee 提供了一個超越簡單鍵值存儲的高級記憶系統：\n",
    "\n",
    "```\n",
    "┌──────────────────────────┐\n",
    "│      30+ data sources    │\n",
    "└───────────┬──────────────┘\n",
    "            │\n",
    "            ▼\n",
    "┌──────────────────────────────────────────┐\n",
    "│  Dynamically evolving memory layers      │\n",
    "│                                          │\n",
    "│  ┌────────────────────────────────────┐  │\n",
    "│  │ Knowledge Graph in Graph Database  │  │\n",
    "│  └────────────────────────────────────┘  │\n",
    "│  ┌────────────────────────────────────┐  │\n",
    "│  │ Embeddings in Vector Store         │  │\n",
    "│  │   (e.g., Azure AI Search)          │  │\n",
    "│  └────────────────────────────────────┘  │\n",
    "└───────────┬──────────────────────────────┘\n",
    "            │                      ▲   \n",
    "            ▼                      │(optional)\n",
    "┌────────────────┐           ┌────────────────┐\n",
    "│     cognee     │(optional) │ Cognee Session │\n",
    "│    retrievers  │──────────▶│     Cache      │\n",
    "│                │           │    (Redis)     │\n",
    "└───────┬────────┘           └────────────────┘\n",
    "        ▲\n",
    "        │\n",
    "┌──────────────────────────┐\n",
    "│          Agents          │\n",
    "└──────────────────────────┘\n",
    "\n",
    "```\n",
    "\n",
    "### 主要組成部分：\n",
    "\n",
    "1. **知識圖譜**：存儲實體、關係及語義連結\n",
    "2. **向量嵌入**：支持對所有存儲信息進行語義搜索\n",
    "3. **會話緩存**：在會話內及跨會話維持對話上下文\n",
    "4. **節點集**：將數據組織成邏輯分類以便於目標檢索\n",
    "\n",
    "### 本教程中的記憶類型：\n",
    "\n",
    "- **持久記憶**：知識圖譜中的長期存儲\n",
    "- **會話記憶**：Redis 緩存中的臨時對話上下文\n",
    "- **語義記憶**：基於向量的相似性搜索，涵蓋所有數據\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## 📦 安裝所需套件\n",
    "\n",
    "安裝 Cognee，並支援 Redis 作為會話管理：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## 🔧 初始化環境及載入庫\n",
    "\n",
    "請確保：\n",
    "1. Redis 已啟動（例如使用 Docker：`docker run -d -p 6379:6379 redis`）\n",
    "2. 在導入快取模組之前已設定環境變數\n",
    "3. 如有需要，重新啟動內核並按順序執行所有單元格\n",
    "\n",
    "以下單元格將會：\n",
    "1. 從 `.env` 載入環境變數\n",
    "2. 使用你的 LLM 設定配置 Cognee\n",
    "3. 啟用快取以管理會話\n",
    "4. 驗證所有元件是否已正確連接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## 📁 配置存儲目錄\n",
    "\n",
    "Cognee 使用兩個獨立的目錄進行操作：\n",
    "- **數據根目錄**：存儲已導入的文件和處理後的數據\n",
    "- **系統根目錄**：包含知識圖譜數據庫和系統元數據\n",
    "\n",
    "我們將為本教程創建獨立的目錄，如下所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## 🧹 重置記憶狀態\n",
    "\n",
    "在我們開始建立記憶系統之前，先確保我們從頭開始。\n",
    "\n",
    "> 💡 **提示**：如果你想在之後使用這個筆記本時保留之前運行的記憶，可以跳過這一步。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## 📚 第 1 部分：建立知識庫\n",
    "\n",
    "### 我們的開發者助手的數據來源\n",
    "\n",
    "我們將引入三種類型的數據來建立一個全面的知識庫：\n",
    "\n",
    "1. **開發者檔案**：個人的專業知識和技術背景  \n",
    "2. **Python 最佳實踐**：Python 之禪及實用指引  \n",
    "3. **歷史對話**：開發者與 AI 助手之間的過往問答記錄  \n",
    "\n",
    "這些多樣化的數據能讓我們的代理做到以下幾點：  \n",
    "- 理解用戶的技術背景  \n",
    "- 在建議中應用最佳實踐  \n",
    "- 從以往成功的互動中學習  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## 🔄 將數據轉化為知識圖譜\n",
    "\n",
    "現在我們將把原始文本轉化為結構化的記憶。這個過程包括：\n",
    "\n",
    "1. **將數據添加到 NodeSets**：將信息組織到邏輯分類中\n",
    "   - `developer_data`：開發者檔案和對話\n",
    "   - `principles_data`：Python 的最佳實踐和指引\n",
    "\n",
    "2. **運行 Cognify Pipeline**：提取實體、關係並創建嵌入\n",
    "   - 識別關鍵概念\n",
    "   - 在相關信息之間創建語義連接\n",
    "   - 生成向量嵌入\n",
    "\n",
    "這可能需要一些時間，因為 LLM 正在處理文本並構建圖譜結構：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## 📊 視覺化知識圖譜\n",
    "\n",
    "讓我們來探索知識圖譜的結構。視覺化內容顯示：\n",
    "- **節點**：從文本中提取的實體（概念、技術、人員）\n",
    "- **邊**：實體之間的關係和連接\n",
    "- **群集**：按語義相似性分組的相關概念\n",
    "\n",
    "在瀏覽器中打開生成的 HTML 文件，互動式地探索圖譜：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## 🧠 用 Memify 豐富記憶\n",
    "\n",
    "`memify()` 函數會分析知識圖譜，並針對數據生成智能規則。這個過程：\n",
    "- 識別模式和最佳實踐\n",
    "- 根據內容創建可行的指引\n",
    "- 建立不同知識領域之間的關係\n",
    "\n",
    "這些規則幫助代理在回答問題時作出更明智的決定。捕捉第二次的可視化圖表，能幫助你比較圖譜在豐富後如何變得更密集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## 🔍 第 2 部分：智能記憶檢索\n",
    "\n",
    "### 示範 1：跨文件知識整合\n",
    "\n",
    "現在我們已經建立了知識圖譜，讓我們測試 Cognee 如何結合多個來源的資訊來回答複雜問題。\n",
    "\n",
    "第一個查詢展示了：\n",
    "- **語義理解**：即使未明確提及，也能找到相關概念\n",
    "- **交叉參照**：結合開發者檔案與 Python 原則\n",
    "- **情境推理**：將最佳實踐應用於特定實現\n",
    "\n",
    "### 示範 2：使用 NodeSets 的篩選搜尋\n",
    "\n",
    "第二個查詢展示如何針對知識圖譜的特定子集進行搜尋：\n",
    "- 使用 `node_name` 參數僅在 `principles_data` 中搜尋\n",
    "- 提供來自特定知識領域的聚焦答案\n",
    "- 適用於需要領域專屬資訊的情況\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## 🔐 第三部分：會話管理設置\n",
    "\n",
    "### 啟用對話記憶\n",
    "\n",
    "會話管理對於在多次互動中保持上下文非常重要。在這裡我們會：\n",
    "\n",
    "1. **初始化用戶上下文**：創建或檢索用戶檔案以進行會話追蹤  \n",
    "2. **配置緩存引擎**：連接到 Redis 以存儲對話歷史記錄  \n",
    "3. **啟用會話變數**：設置在查詢間持續存在的上下文變數  \n",
    "\n",
    "> ⚠️ **重要**：這需要 Redis 正在運行，並且環境中設置了 `CACHING=true`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## 🛠️ 輔助函數：查看會話歷史記錄\n",
    "\n",
    "此實用函數讓我們可以檢視儲存在 Redis 中的會話歷史記錄。這對以下情況非常有用：\n",
    "- 偵錯會話管理\n",
    "- 驗證會話是否已被緩存\n",
    "- 瞭解代理可用的上下文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## 第一節：非同步支援實驗室 — 第一個問題\n",
    "\n",
    "開始 `async-support-lab` 的環節，詢問適合大量網頁爬取的具備遙測友好的 asyncio 模式。圖表已經了解 asyncio、aiohttp 和監控方法，因此回應應該反映之前的對話，同時針對新問題進行調整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## 檢查第一節記憶體在首次交流後的狀況\n",
    "\n",
    "在首次提問後立即執行 `show_history(session_1)`，可以確認 Cognee 已將提示和完成內容寫入 Redis。你應該會看到一個包含並行指導的記錄。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## 第 1 節：跟進數據模型\n",
    "\n",
    "接下來我們問：「什麼時候應該選擇 dataclasses 而不是 Pydantic？」使用相同的會話 ID。Cognee 應該結合 Python 的原則以及之前有關 FastAPI 的對話，提供細緻的建議——展示出在命名會話中，內容是可以延續的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## 確認 Session 1 歷史記錄包含兩個回合\n",
    "\n",
    "再次執行 `show_history(session_1)` 應該會顯示兩個問答條目。這與 Mem0 實驗室的「記憶重播」步驟相符，並證明額外的回合會延續相同的對話記錄。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## 第2節：設計檢討討論串 — 新會話\n",
    "\n",
    "為了展示討論串之間的隔離，我們啟動了 `design-review-session`，並請求有關事件檢討的記錄指引。即使底層的知識庫相同，新的會話 ID 會將記錄分開。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## 檢討會議 2 歷史記錄\n",
    "\n",
    "`show_history(session_2)` 應該只列出設計檢討的提示/回應對比。將其與會議 1 比較，以突顯 Cognee 如何在重用共享知識圖譜的同時，保持獨立的會議記錄。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## 摘要\n",
    "\n",
    "恭喜你！你剛剛為你的編程助手添加了一個由 Cognee 驅動的真正長期記憶層。\n",
    "\n",
    "在這個教程中，你將原始的開發者內容（代碼、文檔、聊天）轉化為一個圖形 + 向量記憶，讓你的代理可以進行搜索、推理，並持續改進。\n",
    "\n",
    "你學到了什麼\n",
    "\n",
    "1. **從原始文本到 AI 記憶**：了解 Cognee 如何吸收非結構化數據，並通過結合向量 + 知識圖譜架構，將其轉化為智能、可搜索的記憶。\n",
    "\n",
    "2. **使用 memify 豐富圖譜**：學習如何超越基本的圖譜創建，使用 memify 在現有圖譜上添加衍生事實和更豐富的關係。\n",
    "\n",
    "3. **多種搜索策略**：了解如何根據代理的需求，使用不同的搜索類型（圖譜感知問答、RAG 風格補全、洞察、原始片段、代碼搜索等）來查詢記憶。\n",
    "\n",
    "4. **視覺化探索**：學習如何使用圖譜可視化和 Cognee UI 檢查和調試 Cognee 建立的內容，讓你能夠真正看到知識的結構。\n",
    "\n",
    "5. **會話感知記憶**：了解如何結合每次會話的上下文與持久的語義記憶，讓代理能夠在多次運行中記住內容，而不會在用戶之間洩漏信息。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## 關鍵重點\n",
    "1. 以嵌入支持的知識圖譜作為記憶\n",
    "\n",
    "    - **結構化理解**：Cognee 結合了向量存儲和圖譜存儲，讓您的數據既可以按意義搜索，也可以按關係連接。Cognee 預設使用基於文件的數據庫（LanceDB 用於向量存儲，Kuzu 用於圖譜數據庫）。\n",
    "\n",
    "    - **關係感知檢索**：答案不僅可以基於「相似文本」，還可以基於實體之間的關係。\n",
    "\n",
    "    - **活記憶**：記憶層會隨著時間演變、增長，並保持作為一個連接的圖譜可供查詢。\n",
    "\n",
    "2. 搜索與推理模式\n",
    "    - **混合檢索**：搜索結合了向量相似性、圖譜結構和 LLM 推理，從原始片段查詢到基於圖譜的問題回答。\n",
    "\n",
    "    - **根據需求選擇模式**：當需要自然語言答案時使用完成式模式，當代理需要原始上下文或進行自主推理時使用片段/摘要/圖譜模式。\n",
    "\n",
    "3. 個性化、會話感知的代理\n",
    "    - **會話上下文 + 長期記憶**：Cognee 將短期「線索」上下文與長期的用戶或組織層級記憶分開。\n",
    "\n",
    "## 真實世界應用\n",
    "\n",
    "1. **垂直 AI 代理**\n",
    "\n",
    "    使用此筆記本中的模式，為基於 Cognee 的檢索和推理核心的領域智能助手提供支持：\n",
    "\n",
    "- **開發者助手**：代碼審查、事件分析和架構助手，能夠遍歷代碼、API、設計文檔和票據，作為一個單一的記憶圖譜。\n",
    "\n",
    "- **面向客戶的助手**：支持或成功代理，能從產品文檔、常見問題解答、CRM 記錄和過去的票據中提取信息，並提供基於圖譜檢索的引用答案。\n",
    "\n",
    "- **內部專家助手**：政策、法律或安全助手，能夠基於互相關聯的規則、指南和歷史決策進行推理，而不是孤立的 PDF。\n",
    "\n",
    "    Cognee 明確定位為 AI 代理的持久、準確記憶，提供一個活的知識圖譜，作為代理的後端，取代臨時組合的向量存儲和自定義圖譜代碼。\n",
    "\n",
    "2. **將數據孤島統一為一個記憶**\n",
    "\n",
    "    同樣的方法也能幫助您在分散的來源之間建立統一的記憶層：\n",
    "\n",
    "- **從孤島到一個圖譜**：將結構化（例如數據庫）和非結構化數據（例如文檔、聊天）導入一個由嵌入支持的單一圖譜，而不是為每個系統建立單獨的索引。\n",
    "\n",
    "- **跨來源推理並提供引用**：在所有數據上運行多步推理——通過圖譜「連接」日誌、指標和文檔——並仍然返回有根據的答案和來源。\n",
    "\n",
    "- **知識中心**：在銀行或教育等領域，Cognee 已被用於統一 PDF、內部系統和應用數據，形成一個帶有向量的知識圖譜，讓代理能夠以精確且有引用的上下文回答問題。\n",
    "\n",
    "## 下一步\n",
    "\n",
    "您已經實現了核心記憶循環。以下是您可以自行嘗試的自然擴展（詳情請參閱 [Cognee 文檔](https://docs.cognee.ai/)）：\n",
    "\n",
    "1. **嘗試時間感知**：啟用時間認知功能，從文本中提取事件和時間戳。\n",
    "\n",
    "2. **引入基於本體的推理**：為您的領域定義 OWL 本體。使用 Cognee 的本體支持，讓提取的實體和關係基於該架構，提升圖譜質量和領域特定答案。\n",
    "\n",
    "3. **添加反饋循環**：讓 Cognee 根據真實用戶反饋調整圖譜邊緣權重，使檢索隨時間改進而非保持靜態。\n",
    "\n",
    "4. **調整個性化與會話行為**：使用用戶 ID、租戶和數據集，為每個人或團隊提供他們自己的共享記憶引擎視圖。\n",
    "\n",
    "5. **擴展到更複雜的代理**：將 Cognee 插入代理框架，構建共享同一記憶層的多代理系統。*Microsoft Agent Framework x Cognee 插件即將推出。*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**免責聲明**：  \n此文件已使用人工智能翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始語言的文件應被視為權威來源。對於重要資訊，建議使用專業的人手翻譯。我們對因使用此翻譯而引起的任何誤解或誤釋不承擔責任。\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:29:36+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "hk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}