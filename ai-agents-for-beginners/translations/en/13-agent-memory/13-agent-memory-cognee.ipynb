{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Building AI Agents with Persistent Memory using Cognee\n",
    "\n",
    "This notebook demonstrates how to create intelligent AI agents with advanced memory capabilities using [**cognee**](https://www.cognee.ai/) - an open-source AI memory system that integrates knowledge graphs, semantic search, and session management to develop context-aware AI systems.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will learn how to:\n",
    "- **Build Knowledge Graphs Backed by Embeddings**: Convert unstructured text into structured, queryable knowledge\n",
    "- **Implement Session Memory**: Enable multi-turn conversations with automatic context retention\n",
    "- **Persist Conversations**: Optionally save significant interactions in long-term memory for future use\n",
    "- **Query Using Natural Language**: Retrieve and utilize historical context in new conversations\n",
    "- **Visualize Memory**: Examine the connections within your agent's knowledge graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è What You'll Build\n",
    "\n",
    "In this tutorial, we will create a **Coding Assistant** with persistent memory that:\n",
    "\n",
    "### 1. **Knowledge Base Construction**\n",
    "   - Gathers information about developer profiles and expertise\n",
    "   - Processes principles and best practices of Python programming\n",
    "   - Stores historical conversations between developers and AI assistants\n",
    "\n",
    "### 2. **Session-Aware Conversations**\n",
    "   - Maintains context across multiple questions within the same session\n",
    "   - Automatically saves each question/answer pair for efficient retrieval\n",
    "   - Delivers coherent, context-aware responses based on conversation history\n",
    "\n",
    "### 3. **Long-term Memory**\n",
    "   - Saves important conversations into a long-term memory\n",
    "   - Retrieves relevant memories from the knowledge base and past sessions to enhance new interactions\n",
    "   - Builds an expanding knowledge base that improves over time\n",
    "\n",
    "### 4. **Intelligent Memory Retrieval**\n",
    "   - Utilizes graph-aware semantic search to locate relevant information across all stored knowledge\n",
    "   - Filters searches by data categories (developer information vs. principles)\n",
    "   - Combines multiple data sources to provide comprehensive answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Prerequisites & Setup\n",
    "\n",
    "### System Requirements\n",
    "\n",
    "Before you begin, make sure you have:\n",
    "\n",
    "1. **Python Environment**\n",
    "   - Python 3.9 or higher\n",
    "   - Virtual environment (recommended)\n",
    "   \n",
    "2. **Redis Cache** (Required for Session Management)\n",
    "   - Local Redis: `docker run -d -p 6379:6379 redis`\n",
    "   - Or use a managed Redis service\n",
    "   \n",
    "3. **LLM API Access**\n",
    "   - OpenAI API key or other providers (see [documentation](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Database Configuration**\n",
    "   - No configuration required by default. Cognee uses file-based databases (LanceDB and Kuzu)\n",
    "   - Optionally, you can set up Azure AI Search as a vector store (see [documentation](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Environment Configuration\n",
    "\n",
    "Create a `.env` file in your project directory with the following variables:\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Understanding Cognee's Memory Architecture\n",
    "\n",
    "### How Cognee Works\n",
    "\n",
    "Cognee offers an advanced memory system that surpasses basic key-value storage:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1. **Knowledge Graph**: Stores entities, relationships, and semantic connections\n",
    "2. **Vector Embeddings**: Enables semantic search across all stored information\n",
    "3. **Session Cache**: Keeps track of conversation context within and across sessions\n",
    "4. **NodeSets**: Organize data into logical categories for focused retrieval\n",
    "\n",
    "### Memory Types in This Tutorial:\n",
    "\n",
    "- **Persistent Memory**: Long-term storage in the knowledge graph\n",
    "- **Session Memory**: Temporary conversation context stored in Redis cache\n",
    "- **Semantic Memory**: Vector-based similarity search across all data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Install Required Packages\n",
    "\n",
    "Install Cognee with Redis support for session management:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß Initialize Environment and Load Libraries\n",
    "\n",
    "Make sure:\n",
    "1. Redis is running (e.g., via Docker: `docker run -d -p 6379:6379 redis`)\n",
    "2. Environment variables are set before importing cache modules\n",
    "3. If needed, restart the kernel and run cells in order\n",
    "\n",
    "The following cell will:\n",
    "1. Load environment variables from `.env`\n",
    "2. Configure Cognee with your LLM settings\n",
    "3. Enable caching for session management\n",
    "4. Validate all components are properly connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ Configure Storage Directories\n",
    "\n",
    "Cognee uses two separate directories for its operations:\n",
    "- **Data Root**: Stores ingested documents and processed data\n",
    "- **System Root**: Contains the knowledge graph database and system metadata\n",
    "\n",
    "We'll create isolated directories for this tutorial as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ Reset Memory State\n",
    "\n",
    "Before we start building our memory system, let's make sure we're starting with a clean slate.\n",
    "\n",
    "> üí° **Tip**: You can skip this step if you want to keep existing memories from your previous runs when using this notebook later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Part 1: Building the Knowledge Base\n",
    "\n",
    "### Data Sources for Our Developer Assistant\n",
    "\n",
    "We'll incorporate three types of data to build a comprehensive knowledge base:\n",
    "\n",
    "1. **Developer Profile**: Personal expertise and technical background\n",
    "2. **Python Best Practices**: The Zen of Python along with practical guidelines\n",
    "3. **Historical Conversations**: Past Q&A sessions between developers and AI assistants\n",
    "\n",
    "This diverse data enables our agent to:\n",
    "- Understand the user's technical context\n",
    "- Provide recommendations based on best practices\n",
    "- Learn from previous successful interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Process Data into Knowledge Graph\n",
    "\n",
    "Now we'll transform our raw text into a structured memory. This process:\n",
    "\n",
    "1. **Adds data to NodeSets**: Organizes information into logical categories\n",
    "   - `developer_data`: Developer profile and conversations\n",
    "   - `principles_data`: Python best practices and guidelines\n",
    "\n",
    "2. **Runs Cognify Pipeline**: Extracts entities, relationships, and creates embeddings\n",
    "   - Identifies key concepts\n",
    "   - Creates semantic connections between related information\n",
    "   - Generates vector embeddings\n",
    "\n",
    "This may take a few moments as the LLM processes the text and builds the graph structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä Visualize the Knowledge Graph\n",
    "\n",
    "Let's examine the structure of our knowledge graph. The visualization includes:\n",
    "- **Nodes**: Entities extracted from the text (concepts, technologies, individuals)\n",
    "- **Edges**: Relationships and connections between entities\n",
    "- **Clusters**: Related concepts grouped by semantic similarity\n",
    "\n",
    "Open the generated HTML file in your browser to interactively explore the graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Enhance Memory with Memify\n",
    "\n",
    "The `memify()` function examines the knowledge graph and formulates smart rules about the data. This process:\n",
    "- Detects patterns and optimal practices\n",
    "- Develops practical guidelines derived from the content\n",
    "- Builds connections between various knowledge domains\n",
    "\n",
    "These rules enable the agent to provide more insightful answers to questions. Capturing a second visualization allows you to observe how the graph becomes more interconnected after enrichment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Part 2: Intelligent Memory Retrieval\n",
    "\n",
    "### Demonstration 1: Cross-Document Knowledge Integration\n",
    "\n",
    "Now that our knowledge graph is built, let's test how Cognee combines information from multiple sources to answer complex questions.\n",
    "\n",
    "The first query demonstrates:\n",
    "- **Semantic understanding**: Identifying relevant concepts even if they are not explicitly mentioned\n",
    "- **Cross-referencing**: Merging developer profiles with Python principles\n",
    "- **Contextual reasoning**: Applying best practices to specific implementations\n",
    "\n",
    "### Demonstration 2: Filtered Search with NodeSets\n",
    "\n",
    "The second query illustrates how to focus on specific subsets of the knowledge graph:\n",
    "- Utilizes the `node_name` parameter to search exclusively within `principles_data`\n",
    "- Delivers targeted answers from a particular knowledge domain\n",
    "- Ideal for situations requiring domain-specific insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Part 3: Session Management Setup\n",
    "\n",
    "### Enabling Conversation Memory\n",
    "\n",
    "Session management is essential for preserving context throughout multiple interactions. Here we will:\n",
    "\n",
    "1. **Initialize User Context**: Create or retrieve a user profile for session tracking\n",
    "2. **Configure Cache Engine**: Connect to Redis to store conversation history\n",
    "3. **Enable Session Variables**: Set up context variables that remain consistent across queries\n",
    "\n",
    "> ‚ö†Ô∏è **Important**: This requires Redis to be running and `CACHING=true` in your environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Helper Function: View Session History\n",
    "\n",
    "This utility function allows us to check the conversation history stored in Redis. It's useful for:\n",
    "- Debugging session management\n",
    "- Ensuring that conversations are being cached\n",
    "- Understanding what context is available to the agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Session 1: Async Support Lab ‚Äî First Question\n",
    "\n",
    "Start the `async-support-lab` session by asking for asyncio patterns that are telemetry-friendly for a large-scale web scraper. The graph is already familiar with asyncio, aiohttp, and monitoring practices, so the response should reflect previous discussions while adapting the answer to this new question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Inspect Session 1 Memory After the First Exchange\n",
    "\n",
    "Running `show_history(session_1)` immediately after the initial question confirms that Cognee saved both the prompt and the completion into Redis. You should see one entry with the concurrency guidance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Session 1: Follow-up on Data Models\n",
    "\n",
    "Next, we ask, \"When should I choose dataclasses versus Pydantic?\" using the same session ID. Cognee should combine Python principles with previous FastAPI discussions to offer detailed advice‚Äîshowing that context is maintained within a named session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Confirm Session 1 History Contains Both Turns\n",
    "\n",
    "Another `show_history(session_1)` call should reveal two Q&A entries. This corresponds to the \"memory replay\" step in the Mem0 lab and demonstrates that additional turns are added to the same transcript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Session 2: Design Review Thread ‚Äî Fresh Session\n",
    "\n",
    "To demonstrate isolation between threads, we initiate `design-review-session` and request logging guidance for incident reviews. Although the underlying knowledge base remains the same, the new session ID ensures that transcripts are kept separate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## Review Session 2 History\n",
    "\n",
    "`show_history(session_2)` should only display the design-review prompt/response pair. Compare it with Session 1 to emphasize how Cognee maintains separate transcripts while leveraging the shared knowledge graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You‚Äôve just equipped your coding assistant with a robust long-term memory layer powered by Cognee.\n",
    "\n",
    "In this tutorial, you transformed raw developer content (code, documentation, chats) into a graph + vector memory that your agent can search, reason about, and continuously enhance.\n",
    "\n",
    "What You‚Äôve Learned:\n",
    "\n",
    "1. **From raw text to AI memory**: How Cognee processes unstructured data and converts it into intelligent, searchable memory using a combined vector + knowledge graph architecture.\n",
    "\n",
    "2. **Graph enrichment with memify**: How to go beyond basic graph creation by using memify to add derived facts and richer relationships to your existing graph.\n",
    "\n",
    "3. **Multiple search strategies**: How to query memory using various search methods (graph-aware Q&A, RAG-style completion, insights, raw chunks, code search, etc.) based on your agent‚Äôs needs.\n",
    "\n",
    "4. **Visual exploration**: How to inspect and debug what Cognee has built using graph visualizations and the Cognee UI, allowing you to see how knowledge is structured.\n",
    "\n",
    "5. **Session-aware memory**: How to integrate per-session context with persistent semantic memory, enabling agents to retain information across sessions without leaking data between users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "1. Memory as a Knowledge Graph backed by Embeddings\n",
    "\n",
    "    - **Structured understanding**: Cognee combines a vector store and a graph store, making your data both searchable by meaning and connected through relationships. By default, Cognee uses file-based databases (LanceDB for vector storage, Kuzu for graph database).\n",
    "\n",
    "    - **Relationship-aware retrieval**: Answers are grounded not just in ‚Äúsimilar text‚Äù but also in how entities are interconnected.\n",
    "\n",
    "    - **Living memory**: The memory layer evolves, grows, and remains queryable as a unified graph.\n",
    "\n",
    "2. Search & Reasoning Modes\n",
    "    - **Hybrid retrieval**: Combines vector similarity, graph structure, and LLM reasoning, ranging from raw chunk lookups to graph-aware question answering.\n",
    "\n",
    "    - **Adapt the mode to the task**: Use completion-style modes for natural language answers, and chunk/summary/graph modes when your agent needs raw context or to drive its own reasoning.\n",
    "\n",
    "3. Personalized, Session-Aware Agents\n",
    "    - **Session context + long-term memory**: Cognee separates short-term ‚Äúthread‚Äù context from long-term, user- or organization-level memory.\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "1. **Vertical AI Agents**\n",
    "\n",
    "    Use the approach outlined in this notebook to create domain-specific copilots powered by Cognee as their retrieval and reasoning backbone:\n",
    "\n",
    "- **Developer copilots**: Assist with code reviews, incident analysis, and architecture by navigating code, APIs, design documents, and tickets as a unified memory graph.\n",
    "\n",
    "- **Customer-facing copilots**: Support or success agents that retrieve information from product documentation, FAQs, CRM notes, and past tickets using graph-aware retrieval and cited answers.\n",
    "\n",
    "- **Internal expert copilots**: Policy, legal, or security assistants that reason over interconnected rules, guidelines, and historical decisions instead of isolated PDFs.\n",
    "\n",
    "    Cognee is designed to serve as a persistent, accurate memory for AI agents, providing a living knowledge graph that integrates seamlessly with your agent, replacing ad-hoc combinations of vector stores and custom graph code.\n",
    "\n",
    "2. **Unifying Data Silos into One Memory**\n",
    "\n",
    "    This approach also enables the creation of a unified memory layer across disparate data sources:\n",
    "\n",
    "- **From silos to one graph**: Combine structured (e.g., databases) and unstructured data (e.g., documents, chats) into a single graph backed by embeddings, rather than maintaining separate indices for each system.\n",
    "\n",
    "- **Cross-source reasoning with citations**: Perform multi-step reasoning across all data‚Äî‚Äújoin‚Äù logs, metrics, and documents via the graph‚Äîand still provide grounded answers with proper citations.\n",
    "\n",
    "- **Knowledge hubs**: In domains like banking or education, Cognee is already being used to unify PDFs, internal systems, and app data into a single knowledge graph with vectors, enabling agents to answer questions with precise, cited context.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You‚Äôve implemented the core memory loop. Here are some natural extensions you can explore on your own (refer to [Cognee documentation](https://docs.cognee.ai/) for more details):\n",
    "\n",
    "1. **Experiment with temporal awareness**: Enable temporal cognify to extract events and timestamps from text.\n",
    "\n",
    "2. **Introduce ontology-driven reasoning**: Define an OWL ontology for your domain. Use Cognee‚Äôs ontology support to ground extracted entities and relationships in that schema, enhancing graph quality and domain-specific answers.\n",
    "\n",
    "3. **Add a feedback loop**: Allow Cognee to adjust graph edge weights based on real user feedback, so retrieval improves over time instead of remaining static.\n",
    "\n",
    "4. **Tune for personalization & session behavior**: Use user IDs, tenants, and datasets to provide each individual or team with their own view of the shared memory engine.\n",
    "\n",
    "5. **Scale out to more complex agents**: Integrate Cognee into agent frameworks to build multi-agent systems that share the same memory layer. *Microsoft Agent Framework x Cognee plugin is coming soon.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Disclaimer**:  \nThis document has been translated using the AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator). While we aim for accuracy, please note that automated translations may include errors or inaccuracies. The original document in its native language should be regarded as the authoritative source. For critical information, professional human translation is advised. We are not responsible for any misunderstandings or misinterpretations resulting from the use of this translation.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:12:18+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "en"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}