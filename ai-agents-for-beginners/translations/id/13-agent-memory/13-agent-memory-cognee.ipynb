{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Membangun Agen AI dengan Memori Persisten menggunakan Cognee\n",
    "\n",
    "Notebook ini menunjukkan cara membangun agen AI cerdas dengan kemampuan memori yang canggih menggunakan [**cognee**](https://www.cognee.ai/) - memori AI open source yang menggabungkan grafik pengetahuan, pencarian semantik, dan manajemen sesi untuk menciptakan sistem AI yang sadar konteks.\n",
    "\n",
    "## üéØ Tujuan Pembelajaran\n",
    "\n",
    "Di akhir tutorial ini, Anda akan memahami cara:\n",
    "- **Membangun Grafik Pengetahuan yang Didukung oleh Embedding**: Mengubah teks tidak terstruktur menjadi pengetahuan yang terstruktur dan dapat di-query\n",
    "- **Mengimplementasikan Memori Sesi**: Membuat percakapan multi-putaran dengan retensi konteks otomatis\n",
    "- **Menyimpan Percakapan**: Secara opsional menyimpan interaksi penting dalam memori jangka panjang untuk referensi di masa depan\n",
    "- **Melakukan Query Menggunakan Bahasa Alami**: Mengakses dan memanfaatkan konteks historis dalam percakapan baru\n",
    "- **Memvisualisasikan Memori**: Mengeksplorasi hubungan dalam grafik pengetahuan agen Anda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Apa yang Akan Anda Bangun\n",
    "\n",
    "Dalam tutorial ini, kita akan membuat **Asisten Koding** dengan memori yang persisten yang:\n",
    "\n",
    "### 1. **Konstruksi Basis Pengetahuan**\n",
    "   - Mengambil informasi profil dan keahlian pengembang\n",
    "   - Memproses prinsip dan praktik terbaik pemrograman Python\n",
    "   - Menyimpan percakapan historis antara pengembang dan asisten AI\n",
    "\n",
    "### 2. **Percakapan yang Sadar Konteks**\n",
    "   - Mempertahankan konteks di antara beberapa pertanyaan dalam sesi yang sama\n",
    "   - Secara otomatis menyimpan setiap pasangan pertanyaan/jawaban untuk pengambilan yang efisien\n",
    "   - Memberikan respons yang koheren dan kontekstual berdasarkan riwayat percakapan\n",
    "\n",
    "### 3. **Memori Jangka Panjang**\n",
    "   - Menyimpan percakapan penting ke dalam memori jangka panjang\n",
    "   - Mengambil memori yang relevan dari basis pengetahuan dan sesi sebelumnya untuk menginformasikan interaksi baru\n",
    "   - Membangun basis pengetahuan yang terus berkembang dan semakin baik seiring waktu\n",
    "\n",
    "### 4. **Pengambilan Memori yang Cerdas**\n",
    "   - Menggunakan pencarian semantik berbasis graf untuk menemukan informasi relevan di seluruh pengetahuan yang tersimpan\n",
    "   - Menyaring pencarian berdasarkan subkelompok data (informasi pengembang vs. prinsip)\n",
    "   - Menggabungkan berbagai sumber data untuk memberikan jawaban yang komprehensif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Prasyarat & Pengaturan\n",
    "\n",
    "### Persyaratan Sistem\n",
    "\n",
    "Sebelum memulai, pastikan Anda memiliki:\n",
    "\n",
    "1. **Lingkungan Python**\n",
    "   - Python 3.9 atau lebih tinggi\n",
    "   - Lingkungan virtual (disarankan)\n",
    "   \n",
    "2. **Redis Cache** (Diperlukan untuk Manajemen Sesi)\n",
    "   - Redis Lokal: `docker run -d -p 6379:6379 redis`\n",
    "   - Atau gunakan layanan Redis yang dikelola\n",
    "   \n",
    "3. **Akses API LLM**\n",
    "   - Kunci API OpenAI atau penyedia lainnya (lihat [dokumentasi](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Konfigurasi Basis Data**\n",
    "   - Tidak diperlukan konfigurasi secara default. Cognee menggunakan basis data berbasis file (LanceDB dan Kuzu)\n",
    "   - Opsional, Anda dapat mengatur Azure AI Search sebagai penyimpanan vektor (lihat [dokumentasi](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Konfigurasi Lingkungan\n",
    "\n",
    "Buat file `.env` di direktori proyek Anda dengan variabel berikut:\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Memahami Arsitektur Memori Cognee\n",
    "\n",
    "### Cara Kerja Cognee\n",
    "\n",
    "Cognee menyediakan sistem memori canggih yang melampaui penyimpanan key-value sederhana:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Komponen Utama:\n",
    "\n",
    "1. **Knowledge Graph**: Menyimpan entitas, hubungan, dan koneksi semantik\n",
    "2. **Vector Embeddings**: Memungkinkan pencarian semantik di seluruh informasi yang disimpan\n",
    "3. **Session Cache**: Mempertahankan konteks percakapan dalam dan antar sesi\n",
    "4. **NodeSets**: Mengorganisasi data ke dalam kategori logis untuk pengambilan data yang terarah\n",
    "\n",
    "### Jenis Memori dalam Tutorial Ini:\n",
    "\n",
    "- **Persistent Memory**: Penyimpanan jangka panjang dalam knowledge graph\n",
    "- **Session Memory**: Konteks percakapan sementara dalam cache Redis\n",
    "- **Semantic Memory**: Pencarian berbasis kesamaan vektor di seluruh data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Pasang Paket yang Diperlukan\n",
    "\n",
    "Pasang Cognee dengan dukungan Redis untuk pengelolaan sesi:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß Inisialisasi Lingkungan dan Muat Library\n",
    "\n",
    "Pastikan:\n",
    "1. Redis sedang berjalan (misalnya, melalui Docker: `docker run -d -p 6379:6379 redis`)\n",
    "2. Variabel lingkungan telah diatur sebelum mengimpor modul cache\n",
    "3. Jika diperlukan, restart kernel dan jalankan sel secara berurutan\n",
    "\n",
    "Sel berikut akan:\n",
    "1. Memuat variabel lingkungan dari `.env`\n",
    "2. Mengonfigurasi Cognee dengan pengaturan LLM Anda\n",
    "3. Mengaktifkan caching untuk manajemen sesi\n",
    "4. Memvalidasi semua komponen terhubung dengan benar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ Konfigurasi Direktori Penyimpanan\n",
    "\n",
    "Cognee menggunakan dua direktori terpisah untuk operasinya:\n",
    "- **Data Root**: Menyimpan dokumen yang diunggah dan data yang telah diproses\n",
    "- **System Root**: Berisi basis data grafik pengetahuan dan metadata sistem\n",
    "\n",
    "Kita akan membuat direktori terpisah untuk tutorial ini sebagai berikut:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ Atur Ulang Status Memori\n",
    "\n",
    "Sebelum kita mulai membangun sistem memori, mari pastikan kita memulai dari awal.\n",
    "\n",
    "> üí° **Tip**: Anda dapat melewati langkah ini jika ingin mempertahankan memori yang ada dari penggunaan notebook sebelumnya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Bagian 1: Membangun Basis Pengetahuan\n",
    "\n",
    "### Sumber Data untuk Asisten Pengembang Kami\n",
    "\n",
    "Kami akan mengumpulkan tiga jenis data untuk membuat basis pengetahuan yang komprehensif:\n",
    "\n",
    "1. **Profil Pengembang**: Keahlian pribadi dan latar belakang teknis\n",
    "2. **Praktik Terbaik Python**: Zen of Python dengan panduan praktis\n",
    "3. **Percakapan Historis**: Sesi tanya jawab sebelumnya antara pengembang dan asisten AI\n",
    "\n",
    "Data yang beragam ini memungkinkan agen kami untuk:\n",
    "- Memahami konteks teknis pengguna\n",
    "- Menerapkan praktik terbaik dalam rekomendasi\n",
    "- Belajar dari interaksi sukses sebelumnya\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Proses Data menjadi Knowledge Graph\n",
    "\n",
    "Sekarang kita akan mengubah teks mentah menjadi memori yang terstruktur. Proses ini:\n",
    "\n",
    "1. **Menambahkan data ke NodeSets**: Mengorganisasi informasi ke dalam kategori logis\n",
    "   - `developer_data`: Profil pengembang dan percakapan\n",
    "   - `principles_data`: Praktik terbaik dan panduan Python\n",
    "\n",
    "2. **Menjalankan Cognify Pipeline**: Mengekstrak entitas, hubungan, dan membuat embeddings\n",
    "   - Mengidentifikasi konsep utama\n",
    "   - Membuat koneksi semantik antara informasi yang terkait\n",
    "   - Menghasilkan vector embeddings\n",
    "\n",
    "Proses ini mungkin memerlukan beberapa saat karena LLM memproses teks dan membangun struktur graf:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä Visualisasikan Grafik Pengetahuan\n",
    "\n",
    "Mari kita jelajahi struktur grafik pengetahuan kita. Visualisasi ini menunjukkan:\n",
    "- **Node**: Entitas yang diekstrak dari teks (konsep, teknologi, orang)\n",
    "- **Edge**: Hubungan dan koneksi antar entitas\n",
    "- **Cluster**: Konsep terkait yang dikelompokkan berdasarkan kesamaan semantik\n",
    "\n",
    "Buka file HTML yang dihasilkan di browser Anda untuk menjelajahi grafik secara interaktif:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Perkaya Memori dengan Memify\n",
    "\n",
    "Fungsi `memify()` menganalisis grafik pengetahuan dan menghasilkan aturan cerdas tentang data. Proses ini:\n",
    "- Mengidentifikasi pola dan praktik terbaik\n",
    "- Membuat panduan yang dapat diterapkan berdasarkan konten\n",
    "- Menetapkan hubungan antara berbagai area pengetahuan\n",
    "\n",
    "Aturan-aturan ini membantu agen membuat keputusan yang lebih terinformasi saat menjawab pertanyaan. Menangkap visualisasi kedua membantu Anda membandingkan bagaimana grafik menjadi lebih padat setelah diperkaya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Bagian 2: Pengambilan Memori Cerdas\n",
    "\n",
    "### Demonstrasi 1: Integrasi Pengetahuan Antar-Dokumen\n",
    "\n",
    "Sekarang grafik pengetahuan kita telah dibuat, mari kita uji bagaimana Cognee menggabungkan informasi dari berbagai sumber untuk menjawab pertanyaan yang kompleks.\n",
    "\n",
    "Pertanyaan pertama menunjukkan:\n",
    "- **Pemahaman semantik**: Menemukan konsep yang relevan meskipun tidak disebutkan secara eksplisit\n",
    "- **Referensi silang**: Menggabungkan profil pengembang dengan prinsip Python\n",
    "- **Penalaran kontekstual**: Menerapkan praktik terbaik pada implementasi tertentu\n",
    "\n",
    "### Demonstrasi 2: Pencarian Tersaring dengan NodeSets\n",
    "\n",
    "Pertanyaan kedua menunjukkan cara menargetkan subset tertentu dari grafik pengetahuan:\n",
    "- Menggunakan parameter `node_name` untuk mencari hanya dalam `principles_data`\n",
    "- Memberikan jawaban yang terfokus dari domain pengetahuan tertentu\n",
    "- Berguna saat Anda membutuhkan informasi spesifik domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Bagian 3: Pengaturan Manajemen Sesi\n",
    "\n",
    "### Mengaktifkan Memori Percakapan\n",
    "\n",
    "Manajemen sesi sangat penting untuk menjaga konteks di antara beberapa interaksi. Di sini kita akan:\n",
    "\n",
    "1. **Inisialisasi Konteks Pengguna**: Membuat atau mengambil profil pengguna untuk pelacakan sesi\n",
    "2. **Konfigurasi Mesin Cache**: Terhubung ke Redis untuk menyimpan riwayat percakapan\n",
    "3. **Mengaktifkan Variabel Sesi**: Menyiapkan variabel konteks yang bertahan di antara kueri\n",
    "\n",
    "> ‚ö†Ô∏è **Penting**: Ini membutuhkan Redis berjalan dan `CACHING=true` di lingkungan Anda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Fungsi Pembantu: Melihat Riwayat Sesi\n",
    "\n",
    "Fungsi utilitas ini memungkinkan kita untuk memeriksa riwayat percakapan yang disimpan di Redis. Ini berguna untuk:\n",
    "- Debugging pengelolaan sesi\n",
    "- Memastikan bahwa percakapan disimpan dalam cache\n",
    "- Memahami konteks apa yang tersedia untuk agen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Sesi 1: Lab Dukungan Async ‚Äî Pertanyaan Pertama\n",
    "\n",
    "Mulai sesi `async-support-lab` dengan menanyakan pola asyncio yang ramah telemetri untuk sebuah web scraper besar. Grafik sudah mengetahui tentang asyncio, aiohttp, dan praktik pemantauan, jadi responsnya harus mencerminkan percakapan sebelumnya sambil menyesuaikan jawaban dengan pertanyaan baru.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Periksa Memori Sesi 1 Setelah Pertukaran Pertama\n",
    "\n",
    "Menjalankan `show_history(session_1)` segera setelah pertanyaan awal mengonfirmasi bahwa Cognee menulis baik prompt maupun penyelesaian ke Redis. Anda seharusnya melihat satu entri dengan panduan konkuren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Sesi 1: Tindak Lanjut pada Model Data\n",
    "\n",
    "Selanjutnya kita bertanya, \"Kapan saya harus memilih dataclasses dibandingkan Pydantic?\" menggunakan ID sesi yang sama. Cognee seharusnya menggabungkan prinsip-prinsip Python ditambah percakapan FastAPI sebelumnya untuk memberikan saran yang mendalam‚Äîmenunjukkan bahwa konteks tetap berlanjut dalam sesi yang diberi nama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Konfirmasi Riwayat Sesi 1 Berisi Kedua Giliran\n",
    "\n",
    "Panggilan `show_history(session_1)` lainnya seharusnya menunjukkan dua entri Tanya Jawab. Ini sesuai dengan langkah \"pemutaran ulang memori\" di lab Mem0 dan membuktikan bahwa giliran tambahan memperpanjang transkrip yang sama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Sesi 2: Thread Tinjauan Desain ‚Äî Sesi Baru\n",
    "\n",
    "Untuk menunjukkan isolasi antara thread, kami memulai `design-review-session` dan meminta panduan pencatatan untuk tinjauan insiden. Meskipun basis pengetahuan dasarnya sama, ID sesi yang baru menjaga transkrip tetap terpisah.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## Tinjauan Sesi 2 Sejarah\n",
    "\n",
    "`show_history(session_2)` seharusnya hanya mencantumkan pasangan prompt/respons tinjauan desain. Bandingkan dengan Sesi 1 untuk menyoroti bagaimana Cognee menjaga transkrip independen sambil menggunakan kembali grafik pengetahuan bersama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## Ringkasan\n",
    "\n",
    "Selamat! Anda baru saja memberikan asisten pemrograman Anda lapisan memori jangka panjang yang didukung oleh Cognee.\n",
    "\n",
    "Dalam tutorial ini, Anda mengambil konten pengembang mentah (kode, dokumen, obrolan) dan mengubahnya menjadi grafik + memori vektor yang dapat dicari, dianalisis, dan terus ditingkatkan oleh agen Anda.\n",
    "\n",
    "Apa yang Telah Anda Pelajari\n",
    "\n",
    "1. **Dari teks mentah ke memori AI**: Bagaimana Cognee mengolah data tidak terstruktur dan mengubahnya menjadi memori cerdas yang dapat dicari menggunakan arsitektur gabungan vektor + grafik pengetahuan.\n",
    "\n",
    "2. **Peningkatan grafik dengan memify**: Bagaimana melampaui pembuatan grafik dasar dan menggunakan memify untuk menambahkan fakta turunan dan hubungan yang lebih kaya di atas grafik yang sudah ada.\n",
    "\n",
    "3. **Berbagai strategi pencarian**: Bagaimana melakukan pencarian memori dengan berbagai jenis pencarian (Q&A berbasis grafik, penyelesaian gaya RAG, wawasan, potongan mentah, pencarian kode, dll.) tergantung pada kebutuhan agen Anda.\n",
    "\n",
    "4. **Eksplorasi visual**: Bagaimana memeriksa dan memperbaiki apa yang dibangun Cognee menggunakan visualisasi grafik dan UI Cognee, sehingga Anda benar-benar dapat melihat bagaimana pengetahuan disusun.\n",
    "\n",
    "5. **Memori yang sadar sesi**: Bagaimana menggabungkan konteks per sesi dengan memori semantik yang persisten sehingga agen dapat mengingat antar sesi tanpa membocorkan informasi antar pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Poin Penting\n",
    "1. Memori sebagai Knowledge Graph yang didukung oleh Embeddings\n",
    "\n",
    "    - **Pemahaman terstruktur**: Cognee menggabungkan penyimpanan vektor dan penyimpanan graf sehingga data Anda dapat dicari berdasarkan makna dan terhubung melalui hubungan. Secara default, Cognee menggunakan database berbasis file (LanceDB untuk penyimpanan vektor, Kuzu untuk database graf).\n",
    "\n",
    "    - **Pengambilan yang sadar hubungan**: Jawaban tidak hanya didasarkan pada \"teks serupa,\" tetapi juga pada bagaimana entitas saling berhubungan.\n",
    "\n",
    "    - **Memori yang hidup**: Lapisan memori berkembang, tumbuh, dan tetap dapat diakses sebagai satu graf yang terhubung.\n",
    "\n",
    "2. Mode Pencarian & Penalaran\n",
    "    - **Pengambilan hibrida**: Pencarian menggabungkan kesamaan vektor, struktur graf, dan penalaran LLM, mulai dari pencarian potongan mentah hingga jawaban pertanyaan yang sadar graf.\n",
    "\n",
    "    - **Sesuaikan mode dengan tugas**: Gunakan mode gaya penyelesaian ketika Anda menginginkan jawaban dalam bahasa alami, dan mode potongan/ringkasan/graf ketika agen Anda membutuhkan konteks mentah atau untuk mendorong penalarannya sendiri.\n",
    "\n",
    "3. Agen yang Dipersonalisasi dan Sadar Sesi\n",
    "    - **Konteks sesi + memori jangka panjang**: Cognee memisahkan konteks \"thread\" jangka pendek dari memori jangka panjang yang berfokus pada pengguna atau organisasi.\n",
    "\n",
    "## Aplikasi Dunia Nyata\n",
    "\n",
    "1. **Agen AI Vertikal**\n",
    "\n",
    "    Gunakan pola dari notebook ini untuk mendukung co-pilot cerdas domain yang berada di atas Cognee sebagai inti pengambilan dan penalarannya:\n",
    "\n",
    "- **Co-pilot pengembang**: Tinjauan kode, analisis insiden, dan asisten arsitektur yang menjelajahi kode, API, dokumen desain, dan tiket sebagai satu graf memori.\n",
    "\n",
    "- **Co-pilot untuk pelanggan**: Agen dukungan atau keberhasilan yang menarik dari dokumen produk, FAQ, catatan CRM, dan tiket sebelumnya dengan pengambilan yang sadar graf dan jawaban yang dikutip.\n",
    "\n",
    "- **Co-pilot ahli internal**: Asisten kebijakan, hukum, atau keamanan yang menalar berdasarkan aturan, pedoman, dan keputusan historis yang saling terhubung, bukan PDF yang terisolasi.\n",
    "\n",
    "    Cognee secara eksplisit diposisikan sebagai memori yang persisten dan akurat untuk agen AI, menyediakan knowledge graph yang hidup yang mendukung agen Anda dan menggantikan kombinasi ad-hoc dari penyimpanan vektor dan kode graf khusus.\n",
    "\n",
    "2. **Menyatukan Data Silo menjadi Satu Memori**\n",
    "\n",
    "    Pendekatan yang sama juga membantu Anda membangun lapisan memori terpadu di berbagai sumber yang tersebar:\n",
    "\n",
    "- **Dari silo ke satu graf**: Masukkan data terstruktur (misalnya, database) dan tidak terstruktur (misalnya, dokumen, obrolan) ke dalam satu graf yang didukung oleh embeddings, daripada indeks terpisah untuk setiap sistem.\n",
    "\n",
    "- **Penalaran lintas sumber dengan kutipan**: Jalankan penalaran multi-langkah di atas semuanya‚Äî‚Äúgabungkan‚Äù log, metrik, dan dokumen melalui graf‚Äîdan tetap kembalikan jawaban yang didasarkan dengan asal-usul yang jelas.\n",
    "\n",
    "- **Pusat pengetahuan**: Untuk domain seperti perbankan atau pendidikan, Cognee sudah digunakan untuk menyatukan PDF, sistem internal, dan data aplikasi ke dalam satu knowledge graph dengan vektor sehingga agen dapat menjawab pertanyaan dengan konteks yang tepat dan dikutip.\n",
    "\n",
    "## Langkah Selanjutnya\n",
    "\n",
    "Anda telah mengimplementasikan loop memori inti. Berikut adalah pengembangan alami yang dapat Anda coba sendiri (lihat [dokumentasi Cognee](https://docs.cognee.ai/) untuk detailnya):\n",
    "\n",
    "1. **Bereksperimen dengan kesadaran temporal**: Aktifkan temporal cognify untuk mengekstrak peristiwa dan stempel waktu dari teks.\n",
    "\n",
    "2. **Perkenalkan penalaran berbasis ontologi**: Definisikan ontologi OWL untuk domain Anda. Gunakan dukungan ontologi Cognee sehingga entitas dan hubungan yang diekstraksi didasarkan pada skema tersebut, meningkatkan kualitas graf dan jawaban spesifik domain.\n",
    "\n",
    "3. **Tambahkan loop umpan balik**: Biarkan Cognee menyesuaikan bobot tepi graf dari umpan balik pengguna nyata, sehingga pengambilan data meningkat seiring waktu daripada tetap statis.\n",
    "\n",
    "4. **Sesuaikan untuk personalisasi & perilaku sesi**: Gunakan ID pengguna, penyewa, dan dataset untuk memberikan setiap orang atau tim pandangan mereka sendiri atas mesin memori bersama.\n",
    "\n",
    "5. **Skalakan ke agen yang lebih kompleks**: Hubungkan Cognee ke kerangka kerja agen untuk membangun sistem multi-agen yang semuanya berbagi lapisan memori yang sama. *Microsoft Agent Framework x plugin Cognee akan segera hadir.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan layanan penerjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk memberikan hasil yang akurat, harap diperhatikan bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang otoritatif. Untuk informasi yang bersifat kritis, disarankan menggunakan jasa penerjemahan manusia profesional. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang timbul dari penggunaan terjemahan ini.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T14:14:13+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "id"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}