{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# 使用 Cognee 建立具有持久記憶的 AI 代理\n",
    "\n",
    "此筆記本展示如何使用 [**cognee**](https://www.cognee.ai/) 建立具有高級記憶功能的智能 AI 代理。Cognee 是一個開源的 AI 記憶系統，結合了知識圖譜、語義搜尋和會話管理，能夠創建具備上下文感知能力的 AI 系統。\n",
    "\n",
    "## 🎯 學習目標\n",
    "\n",
    "完成本教程後，您將能夠了解如何：\n",
    "- **建立基於嵌入的知識圖譜**：將非結構化文本轉換為結構化、可查詢的知識\n",
    "- **實現會話記憶**：創建多輪對話，並自動保留上下文\n",
    "- **持久化對話**：選擇性地將重要的互動存儲於長期記憶中以供未來參考\n",
    "- **使用自然語言查詢**：在新對話中訪問並利用歷史上下文\n",
    "- **可視化記憶**：探索代理知識圖譜中的關係\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## 🏗️ 您將建立的內容\n",
    "\n",
    "在本教程中，我們將建立一個具有持久記憶的**程式助理**，其功能包括：\n",
    "\n",
    "### 1. **知識庫建構**\n",
    "   - 收集開發者的個人資料及專業資訊\n",
    "   - 處理 Python 程式設計原則及最佳實踐\n",
    "   - 儲存開發者與 AI 助理之間的歷史對話\n",
    "\n",
    "### 2. **會話感知對話**\n",
    "   - 在同一會話中保持多個問題的上下文\n",
    "   - 自動快取每個問題/答案對以提高檢索效率\n",
    "   - 根據對話歷史提供連貫且具上下文的回應\n",
    "\n",
    "### 3. **長期記憶**\n",
    "   - 將重要的對話保存到長期記憶中\n",
    "   - 從知識庫及過去的會話中檢索相關記憶以輔助新的互動\n",
    "   - 建立一個隨時間增長的知識庫以持續改進\n",
    "\n",
    "### 4. **智能記憶檢索**\n",
    "   - 使用圖形感知語義搜索來查找所有儲存知識中的相關資訊\n",
    "   - 根據數據子群組（開發者資訊 vs. 原則）篩選搜索結果\n",
    "   - 結合多個數據來源以提供全面的答案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## 📋 先決條件與設定\n",
    "\n",
    "### 系統需求\n",
    "\n",
    "在開始之前，請確保您已具備以下條件：\n",
    "\n",
    "1. **Python 環境**\n",
    "   - Python 3.9 或更高版本\n",
    "   - 建議使用虛擬環境\n",
    "\n",
    "2. **Redis 快取**（用於會話管理）\n",
    "   - 本地 Redis：`docker run -d -p 6379:6379 redis`\n",
    "   - 或使用托管的 Redis 服務\n",
    "\n",
    "3. **LLM API 存取**\n",
    "   - OpenAI API 金鑰或其他提供者（請參閱[文件](https://docs.cognee.ai/setup-configuration/llm-providers)）\n",
    "\n",
    "4. **資料庫設定**\n",
    "   - 預設情況下不需要任何設定。Cognee 使用基於檔案的資料庫（LanceDB 和 Kuzu）\n",
    "   - 可選擇性地設定 Azure AI Search 作為向量存儲（請參閱[文件](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch)）\n",
    "\n",
    "### 環境設定\n",
    "\n",
    "在您的專案目錄中建立 `.env` 檔案，並加入以下變數：\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## 🏛️ 理解 Cognee 的記憶體架構\n",
    "\n",
    "### Cognee 的運作方式\n",
    "\n",
    "Cognee 提供了一個超越簡單鍵值存儲的精密記憶體系統：\n",
    "\n",
    "```\n",
    "┌──────────────────────────┐\n",
    "│      30+ data sources    │\n",
    "└───────────┬──────────────┘\n",
    "            │\n",
    "            ▼\n",
    "┌──────────────────────────────────────────┐\n",
    "│  Dynamically evolving memory layers      │\n",
    "│                                          │\n",
    "│  ┌────────────────────────────────────┐  │\n",
    "│  │ Knowledge Graph in Graph Database  │  │\n",
    "│  └────────────────────────────────────┘  │\n",
    "│  ┌────────────────────────────────────┐  │\n",
    "│  │ Embeddings in Vector Store         │  │\n",
    "│  │   (e.g., Azure AI Search)          │  │\n",
    "│  └────────────────────────────────────┘  │\n",
    "└───────────┬──────────────────────────────┘\n",
    "            │                      ▲   \n",
    "            ▼                      │(optional)\n",
    "┌────────────────┐           ┌────────────────┐\n",
    "│     cognee     │(optional) │ Cognee Session │\n",
    "│    retrievers  │──────────▶│     Cache      │\n",
    "│                │           │    (Redis)     │\n",
    "└───────┬────────┘           └────────────────┘\n",
    "        ▲\n",
    "        │\n",
    "┌──────────────────────────┐\n",
    "│          Agents          │\n",
    "└──────────────────────────┘\n",
    "\n",
    "```\n",
    "\n",
    "### 核心組成部分：\n",
    "\n",
    "1. **知識圖譜**：存儲實體、關係和語義連結\n",
    "2. **向量嵌入**：實現對所有存儲資訊的語義搜索\n",
    "3. **會話快取**：在會話內部及跨會話之間維持對話上下文\n",
    "4. **節點集 (NodeSets)**：將數據組織成邏輯分類以便於目標檢索\n",
    "\n",
    "### 本教程中的記憶體類型：\n",
    "\n",
    "- **持久記憶體**：知識圖譜中的長期存儲\n",
    "- **會話記憶體**：Redis 快取中的臨時對話上下文\n",
    "- **語義記憶體**：基於向量的相似性搜索，涵蓋所有數據\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## 📦 安裝所需套件\n",
    "\n",
    "安裝 Cognee，並支援 Redis 用於會話管理：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## 🔧 初始化環境並載入函式庫\n",
    "\n",
    "請確保：\n",
    "1. Redis 已啟動（例如，透過 Docker：`docker run -d -p 6379:6379 redis`）\n",
    "2. 在匯入快取模組之前已設定環境變數\n",
    "3. 如有需要，重新啟動內核並按順序執行程式碼區塊\n",
    "\n",
    "以下的程式碼區塊將會：\n",
    "1. 從 `.env` 載入環境變數\n",
    "2. 使用您的 LLM 設定來配置 Cognee\n",
    "3. 啟用快取以進行會話管理\n",
    "4. 驗證所有元件是否正確連接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## 📁 設定存儲目錄\n",
    "\n",
    "Cognee 使用兩個獨立的目錄進行操作：\n",
    "- **資料根目錄**：存放已匯入的文件和處理後的數據\n",
    "- **系統根目錄**：包含知識圖譜數據庫和系統元數據\n",
    "\n",
    "在本教程中，我們將建立獨立的目錄，如下所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## 🧹 重置記憶狀態\n",
    "\n",
    "在我們開始建立記憶系統之前，先確保我們從頭開始。\n",
    "\n",
    "> 💡 **提示**：如果您希望在之後使用此筆記本時保留之前執行的現有記憶，可以跳過此步驟。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## 📚 第 1 部分：建立知識庫\n",
    "\n",
    "### 我們的開發者助手的數據來源\n",
    "\n",
    "我們將匯入三種類型的數據來建立一個全面的知識庫：\n",
    "\n",
    "1. **開發者檔案**：個人的專業知識與技術背景  \n",
    "2. **Python 最佳實踐**：Python 之禪及實用指導方針  \n",
    "3. **歷史對話**：開發者與 AI 助手之間的過去問答記錄  \n",
    "\n",
    "這些多樣化的數據能讓我們的代理：  \n",
    "- 理解使用者的技術背景  \n",
    "- 在建議中應用最佳實踐  \n",
    "- 從過去成功的互動中學習  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## 🔄 將資料轉換為知識圖譜\n",
    "\n",
    "現在我們將把原始文本轉換為結構化的記憶。此過程：\n",
    "\n",
    "1. **將資料添加到 NodeSets**：將資訊組織到邏輯分類中\n",
    "   - `developer_data`：開發者檔案和對話\n",
    "   - `principles_data`：Python 的最佳實踐和指導方針\n",
    "\n",
    "2. **執行 Cognify Pipeline**：提取實體、關係並建立嵌入\n",
    "   - 識別關鍵概念\n",
    "   - 在相關資訊之間建立語義連結\n",
    "   - 生成向量嵌入\n",
    "\n",
    "這可能需要一些時間，因為 LLM 正在處理文本並構建圖譜結構：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## 📊 視覺化知識圖譜\n",
    "\n",
    "讓我們來探索知識圖譜的結構。該視覺化圖表顯示：\n",
    "- **節點**：從文本中提取的實體（概念、技術、人員）\n",
    "- **邊**：實體之間的關係和連結\n",
    "- **群集**：根據語義相似性分組的相關概念\n",
    "\n",
    "在瀏覽器中打開生成的 HTML 文件，以互動方式探索圖譜：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## 🧠 使用 Memify 豐富記憶\n",
    "\n",
    "`memify()` 函數會分析知識圖譜並生成有關數據的智能規則。此過程：\n",
    "- 識別模式和最佳實踐\n",
    "- 根據內容創建可操作的指導方針\n",
    "- 建立不同知識領域之間的關係\n",
    "\n",
    "這些規則幫助代理在回答問題時做出更明智的決策。捕捉第二次視覺化可以幫助您比較圖譜在豐富後如何變得更加密集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## 🔍 第二部分：智能記憶檢索\n",
    "\n",
    "### 示範 1：跨文件知識整合\n",
    "\n",
    "現在我們的知識圖譜已經建立完成，讓我們測試 Cognee 如何結合多個來源的信息來回答複雜問題。\n",
    "\n",
    "第一個查詢展示了：\n",
    "- **語義理解**：即使未明確提及，也能找到相關概念\n",
    "- **交叉引用**：結合開發者檔案與 Python 原則\n",
    "- **情境推理**：將最佳實踐應用於特定實現\n",
    "\n",
    "### 示範 2：使用 NodeSets 的篩選搜尋\n",
    "\n",
    "第二個查詢展示如何針對知識圖譜的特定子集進行搜尋：\n",
    "- 使用 `node_name` 參數僅在 `principles_data` 中搜尋\n",
    "- 從特定知識領域提供專注的答案\n",
    "- 當需要領域特定的信息時非常有用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## 🔐 第三部分：會話管理設置\n",
    "\n",
    "### 啟用對話記憶\n",
    "\n",
    "會話管理對於在多次互動中保持上下文至關重要。在這裡我們將：\n",
    "\n",
    "1. **初始化用戶上下文**：創建或檢索用戶檔案以進行會話追蹤  \n",
    "2. **配置快取引擎**：連接到 Redis 以存儲對話歷史記錄  \n",
    "3. **啟用會話變數**：設置在查詢間持續存在的上下文變數  \n",
    "\n",
    "> ⚠️ **重要**：這需要 Redis 正在運行，並且環境中設置了 `CACHING=true`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## 🛠️ 輔助函式：查看會話歷史記錄\n",
    "\n",
    "此工具函式可讓我們檢視儲存在 Redis 中的會話歷史記錄。它的用途包括：\n",
    "- 偵錯會話管理\n",
    "- 驗證會話是否已被快取\n",
    "- 瞭解代理可用的上下文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## 第一節：非同步支援實驗室 — 第一個問題\n",
    "\n",
    "開始 `async-support-lab` 會話，詢問適合大量網頁爬取的具備遙測友好的 asyncio 模式。系統已經了解 asyncio、aiohttp 和監控實踐，因此回覆應反映之前的對話內容，同時針對新問題進行調整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## 檢查第一次互動後的 Session 1 記憶體\n",
    "\n",
    "在初始問題之後立即執行 `show_history(session_1)`，可以確認 Cognee 已將提示和完成內容寫入 Redis。您應該會看到一個包含並發指導的條目。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## 第 1 節：資料模型的後續討論\n",
    "\n",
    "接下來我們問：「什麼時候應該選擇 dataclasses 而不是 Pydantic？」使用相同的會話 ID。Cognee 應該結合 Python 的原則以及之前關於 FastAPI 的討論，提供細緻的建議——展示出在命名會話中，背景資訊是可以延續的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## 確認 Session 1 的歷史包含兩次對話\n",
    "\n",
    "再次呼叫 `show_history(session_1)` 應顯示兩個問答項目。這符合 Mem0 實驗室的「記憶重播」步驟，並證明額外的對話會延續相同的記錄。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## 第 2 節：設計審查討論串 — 新的會話\n",
    "\n",
    "為了展示討論串之間的隔離，我們啟動了 `design-review-session`，並請求針對事件審查提供記錄指導。即使底層的知識庫相同，新的會話 ID 仍能保持記錄分開。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## 檢視會議 2 歷史記錄\n",
    "\n",
    "`show_history(session_2)` 應該只列出設計檢視的提示/回應對。將其與會議 1 進行比較，以突顯 Cognee 如何在重複使用共享知識圖的同時，保持獨立的會議記錄。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## 摘要\n",
    "\n",
    "恭喜你！你剛剛為你的程式助理添加了一個由 Cognee 驅動的真正長期記憶層。\n",
    "\n",
    "在這個教學中，你將原始的開發者內容（程式碼、文件、聊天）轉化為一個圖形 + 向量記憶，讓你的代理可以進行搜尋、推理，並持續改進。\n",
    "\n",
    "你學到了什麼\n",
    "\n",
    "1. **從原始文本到 AI 記憶**：了解 Cognee 如何處理非結構化數據，並使用結合向量 + 知識圖譜的架構將其轉化為智能、可搜尋的記憶。\n",
    "\n",
    "2. **使用 memify 豐富圖譜**：學會如何超越基本的圖譜建立，利用 memify 在現有圖譜上添加衍生事實和更豐富的關係。\n",
    "\n",
    "3. **多種搜尋策略**：學習如何根據代理的需求，使用不同的搜尋類型（圖譜感知的問答、RAG 風格的補全、洞察、原始片段、程式碼搜尋等）來查詢記憶。\n",
    "\n",
    "4. **視覺化探索**：學會如何使用圖形視覺化和 Cognee UI 檢查和調試 Cognee 所建立的內容，讓你能夠實際看到知識的結構。\n",
    "\n",
    "5. **會話感知記憶**：了解如何結合每次會話的上下文與持久的語義記憶，讓代理能夠在多次運行中記住內容，同時避免用戶之間的信息洩漏。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## 關鍵重點\n",
    "1. 作為嵌入支持的知識圖譜的記憶\n",
    "\n",
    "    - **結構化理解**：Cognee 結合了向量存儲和圖形存儲，因此您的數據既可以通過語意進行搜索，也可以通過關係進行連接。Cognee 預設使用基於文件的數據庫（LanceDB 用於向量存儲，Kuzu 用於圖形數據庫）。\n",
    "\n",
    "    - **關係感知檢索**：答案不僅可以基於「相似文本」，還可以基於實體之間的關係。\n",
    "\n",
    "    - **活的記憶**：記憶層會隨著時間演變、成長，並作為一個連接的圖譜保持可查詢。\n",
    "\n",
    "2. 搜索與推理模式\n",
    "    - **混合檢索**：搜索結合了向量相似性、圖形結構和 LLM 推理，從原始片段查詢到圖形感知的問題回答。\n",
    "\n",
    "    - **根據需求選擇模式**：當您需要自然語言答案時，使用補全模式；當您的代理需要原始上下文或進行自身推理時，使用片段/摘要/圖形模式。\n",
    "\n",
    "3. 個性化、會話感知的代理\n",
    "    - **會話上下文 + 長期記憶**：Cognee 將短期「線索」上下文與長期的用戶或組織層級記憶分開。\n",
    "\n",
    "## 真實世界應用\n",
    "\n",
    "1. **垂直 AI 代理**\n",
    "\n",
    "    使用此筆記本中的模式，為基於 Cognee 的檢索和推理核心的領域智能助手提供支持：\n",
    "\n",
    "- **開發者助手**：代碼審查、事件分析和架構助手，將代碼、API、設計文檔和工單作為單一記憶圖譜進行遍歷。\n",
    "\n",
    "- **面向客戶的助手**：支持或成功代理，通過圖形感知檢索和引用答案，從產品文檔、常見問題解答、CRM 記錄和過去的工單中提取信息。\n",
    "\n",
    "- **內部專家助手**：政策、法律或安全助手，基於相互關聯的規則、指南和歷史決策進行推理，而不是孤立的 PDF。\n",
    "\n",
    "    Cognee 明確定位為 AI 代理的持久、準確記憶，提供一個活的知識圖譜，作為代理的後端，取代臨時組合的向量存儲和自定義圖形代碼。\n",
    "\n",
    "2. **將數據孤島統一為一個記憶體系**\n",
    "\n",
    "    同樣的方法也可以幫助您在分散的來源之間構建統一的記憶層：\n",
    "\n",
    "- **從孤島到一個圖譜**：將結構化（例如數據庫）和非結構化數據（例如文檔、聊天記錄）導入到一個由嵌入支持的單一圖譜中，而不是為每個系統建立單獨的索引。\n",
    "\n",
    "- **帶有引用的跨來源推理**：在所有數據上運行多步推理——通過圖譜「連接」日誌、指標和文檔——並仍然返回具有來源依據的答案。\n",
    "\n",
    "- **知識中心**：對於像銀行或教育這樣的領域，Cognee 已經被用來將 PDF、內部系統和應用數據統一到一個帶有向量的知識圖譜中，讓代理能夠以精確且有引用的上下文回答問題。\n",
    "\n",
    "## 下一步\n",
    "\n",
    "您已經實現了核心記憶循環。以下是您可以自行嘗試的自然擴展（詳情請參閱 [Cognee 文件](https://docs.cognee.ai/)）：\n",
    "\n",
    "1. **嘗試時間感知功能**：啟用時間感知功能，從文本中提取事件和時間戳。\n",
    "\n",
    "2. **引入本體驅動的推理**：為您的領域定義一個 OWL 本體。使用 Cognee 的本體支持，讓提取的實體和關係基於該架構，提升圖譜質量和領域特定的答案。\n",
    "\n",
    "3. **添加反饋循環**：讓 Cognee 根據真實用戶反饋調整圖譜邊權重，使檢索隨時間改進，而不是保持靜態。\n",
    "\n",
    "4. **針對個性化和會話行為進行調整**：使用用戶 ID、租戶和數據集，為每個人或團隊提供他們自己的共享記憶引擎視圖。\n",
    "\n",
    "5. **擴展到更複雜的代理**：將 Cognee 插入代理框架，構建共享相同記憶層的多代理系統。*Microsoft Agent Framework x Cognee 插件即將推出。*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**免責聲明**：  \n本文件已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。儘管我們致力於提供準確的翻譯，請注意自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於重要資訊，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或誤釋不承擔責任。\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:31:24+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "tw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}