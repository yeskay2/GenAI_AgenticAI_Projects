{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# How to Build AI Agents wey get Persistent Memory wit Cognee\n",
    "\n",
    "Dis notebook go show how to take build smart AI agents wey sabi memory well well using [**cognee**](https://www.cognee.ai/) - na open source AI memory wey join knowledge graphs, semantic search, and session management to create AI systems wey sabi context.\n",
    "\n",
    "## üéØ Wetin You Go Learn\n",
    "\n",
    "By the time you finish dis tutorial, you go sabi how to:\n",
    "- **Build Knowledge Graphs wey dey Backed by Embeddings**: Change text wey no get structure into structured knowledge wey you fit query\n",
    "- **Implement Session Memory**: Create multi-turn conversations wey go dey keep context automatically\n",
    "- **Keep Conversations for Future**: Store important interactions for long-term memory if you want am\n",
    "- **Query wit Natural Language**: Use historical context for new conversations\n",
    "- **See Memory Visuals**: Check how your agent's knowledge graph dey connect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Wetin You Go Build\n",
    "\n",
    "For dis tutorial, we go create one **Coding Assistant** wey get memory wey no dey loss, wey fit do di following:\n",
    "\n",
    "### 1. **Build Knowledge Base**\n",
    "   - Go fit collect developer profile and di kain expertise wey dem get\n",
    "   - Go sabi process Python programming principles and di best ways to take use am\n",
    "   - Go dey store old conversations wey don happen between developers and AI assistants\n",
    "\n",
    "### 2. **Session-Aware Conversations**\n",
    "   - Go fit remember context for di same session even if na multiple questions\n",
    "   - Go dey automatically save each question/answer pair so e go dey easy to find later\n",
    "   - Go dey give correct and meaningful response based on di conversation wey don happen before\n",
    "\n",
    "### 3. **Long-term Memory**\n",
    "   - Go dey keep important conversations for long-term memory\n",
    "   - Go fit bring out relevant memories from di knowledge base and past sessions to help for new interactions\n",
    "   - Go dey build di knowledge base small small so e go dey better as time dey go\n",
    "\n",
    "### 4. **Intelligent Memory Retrieval**\n",
    "   - Go use graph-aware semantic search to find di correct information from all di knowledge wey e don store\n",
    "   - Go fit filter di search by di kain data group (like developer info or principles)\n",
    "   - Go dey combine different data sources to give complete and correct answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Wetin You Need & How to Set Up\n",
    "\n",
    "### System Requirements\n",
    "\n",
    "Before you start, make sure say you get:\n",
    "\n",
    "1. **Python Environment**\n",
    "   - Python 3.9 or higher\n",
    "   - Virtual environment (e good make you use am)\n",
    "\n",
    "2. **Redis Cache** (You go need am for Session Management)\n",
    "   - Local Redis: `docker run -d -p 6379:6379 redis`\n",
    "   - Or make you use managed Redis service\n",
    "\n",
    "3. **LLM API Access**\n",
    "   - OpenAI API key or other providers (check [documentation](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Database Configuration**\n",
    "   - By default, you no need configure anything. Cognee dey use file-based databases (LanceDB and Kuzu)\n",
    "   - If you wan, you fit set up Azure AI Search as vector store (check [documentation](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Environment Configuration\n",
    "\n",
    "Create `.env` file for your project directory wey go get these variables:\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Understanding Cognee Memory Architecture\n",
    "\n",
    "### How Cognee Dey Work\n",
    "\n",
    "Cognee get one kind beta memory system wey pass just ordinary key-value storage:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Di Main Parts:\n",
    "\n",
    "1. **Knowledge Graph**: E dey store entities, relationships, and semantic connections\n",
    "2. **Vector Embeddings**: E dey make semantic search possible for all di information wey dem store\n",
    "3. **Session Cache**: E dey keep conversation context for inside and between sessions\n",
    "4. **NodeSets**: E dey arrange data into logical categories so retrieval go dey easy\n",
    "\n",
    "### Di Kain Memory We Go Talk About for Dis Tutorial:\n",
    "\n",
    "- **Persistent Memory**: Na long-term storage for di knowledge graph\n",
    "- **Session Memory**: Na temporary conversation context wey dey for Redis cache\n",
    "- **Semantic Memory**: Na vector-based similarity search wey dey work for all di data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Install Di Package Wey You Need\n",
    "\n",
    "Install Cognee wey get Redis support for session management:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß Set Up Environment and Load Libraries\n",
    "\n",
    "Make sure say:\n",
    "1. Redis dey run (e.g., if you wan use Docker: `docker run -d -p 6379:6379 redis`)\n",
    "2. You don set environment variables before you import cache modules\n",
    "3. If e need, restart di kernel and run di cells one by one for correct order\n",
    "\n",
    "Di cell wey dey follow go do di following:\n",
    "1. Load environment variables from `.env`\n",
    "2. Configure Cognee wit your LLM settings\n",
    "3. Enable caching for session management\n",
    "4. Check say all di components connect well well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ Configure Storage Directories\n",
    "\n",
    "Cognee dey use two diffren directories for di work wey e dey do:  \n",
    "- **Data Root**: Na here e dey store di documents wey e don collect and di data wey e don process.  \n",
    "- **System Root**: Na here e dey keep di knowledge graph database and di system metadata.  \n",
    "\n",
    "We go create separate directories for dis tutorial like dis:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ Reset Memory State\n",
    "\n",
    "Before we go start to build our memory system, make we make sure say we dey start afresh.\n",
    "\n",
    "> üí° **Tip**: You fit skip dis step if you wan keep di memories wey dey already from di runs wey you don do before when you go use dis notebook later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Part 1: How to Build Di Knowledge Base\n",
    "\n",
    "### Data We Go Use for Our Developer Assistant\n",
    "\n",
    "We go collect three kain data to build beta knowledge base:\n",
    "\n",
    "1. **Developer Profile**: Di person skill and wetin dem sabi for tech\n",
    "2. **Python Best Practices**: Di Zen of Python wit practical guidelines\n",
    "3. **Historical Conversations**: Old Q&A wey don happen between developers and AI assistants\n",
    "\n",
    "Dis kain data go help our agent to:\n",
    "- Sabi di user technical level\n",
    "- Use best practices for di advice wey e go give\n",
    "- Learn from di past interactions wey don work well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Process Data into Knowledge Graph\n",
    "\n",
    "Now we go change our raw text into structured memory. Dis process:\n",
    "\n",
    "1. **Add data to NodeSets**: E go arrange information into correct categories\n",
    "   - `developer_data`: Developer profile and wetin dem talk\n",
    "   - `principles_data`: Python best practices and guidelines\n",
    "\n",
    "2. **Run Cognify Pipeline**: E go extract entities, relationships, and create embeddings\n",
    "   - E go find key concepts\n",
    "   - E go connect related information semantically\n",
    "   - E go generate vector embeddings\n",
    "\n",
    "Dis one fit take small time as LLM dey process di text and dey build di graph structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä See Di Knowledge Graph\n",
    "\n",
    "Make we check how di knowledge graph be. Di visualization go show:\n",
    "- **Nodes**: Entities wey dem comot from di text (concepts, technologies, people)\n",
    "- **Edges**: Di relationships and connections wey dey between di entities\n",
    "- **Clusters**: Related concepts wey dem group based on semantic similarity\n",
    "\n",
    "Open di HTML file wey dem generate for your browser to fit explore di graph well well:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Add Memory wit Memify\n",
    "\n",
    "Di `memify()` function dey check di knowledge graph and e dey create smart rules about di data. Dis process:\n",
    "- E dey find patterns and di best way to do things\n",
    "- E dey make guidelines wey you fit use based on di content\n",
    "- E dey connect different knowledge areas together\n",
    "\n",
    "Dis rules go help di agent sabi better how to answer questions. If you capture second visualization, e go help you see how di graph don get more connections after e don enrich am.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Part 2: Intelligent Memory Retrieval\n",
    "\n",
    "### Demonstration 1: Cross-Document Knowledge Integration\n",
    "\n",
    "Now wey we don build di knowledge graph, make we test how Cognee dey join information from different sources to fit answer complex questions.\n",
    "\n",
    "Di first query go show:\n",
    "- **Semantic understanding**: How e dey find di correct concepts even if dem no talk am directly\n",
    "- **Cross-referencing**: How e dey join developer profile with Python principles\n",
    "- **Contextual reasoning**: How e dey use best practices for specific implementations\n",
    "\n",
    "### Demonstration 2: Filtered Search with NodeSets\n",
    "\n",
    "Di second query go show how you fit target specific parts of di knowledge graph:\n",
    "- E dey use `node_name` parameter to search only inside `principles_data`\n",
    "- E dey give focused answers from one particular knowledge area\n",
    "- E dey useful when you need information wey dey specific to one domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Part 3: Session Management Setup\n",
    "\n",
    "### How to Make Conversation Memory Work\n",
    "\n",
    "Session management dey very important to keep context for plenty interactions. For here we go:\n",
    "\n",
    "1. **Start User Context**: Create or find user profile wey go help track session\n",
    "2. **Set Cache Engine**: Connect am to Redis to store conversation history\n",
    "3. **Turn On Session Variables**: Arrange context variables wey go dey stay for all queries\n",
    "\n",
    "> ‚ö†Ô∏è **Important**: This one need make Redis dey run and `CACHING=true` for your environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Helper Function: View Session History\n",
    "\n",
    "Dis function go help us check di tok wey don dey store for Redis. E dey useful for:\n",
    "- Debug di way session dey work\n",
    "- Make sure say di tok dem dey save well\n",
    "- Understand di kind context wey di agent fit use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Session 1: Async Support Lab ‚Äî First Question\n",
    "\n",
    "Start the `async-support-lab` session by ask how person fit use telemetry-friendly asyncio patterns for one big web scraper. Di graph don already sabi asyncio, aiohttp, and monitoring practices, so di answer suppose match wetin dem don talk before but e go still fit di new question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Check Session 1 Memory After Di Fes Tok\n",
    "\n",
    "If you run `show_history(session_1)` just afta di first question, e go show say Cognee don put di prompt and di answer inside Redis. You go see one entry wey get di concurrency guidance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Session 1: Follow-up on Data Models\n",
    "\n",
    "Next we go ask, \"Wen I go fit choose dataclasses or Pydantic?\" we go use di same session id. Cognee go join di Python principles plus di FastAPI talk wey we don do before to give better advice‚Äîshow say context dey continue inside one session wey get name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Confirm Session 1 History Get Both Turns\n",
    "\n",
    "Another `show_history(session_1)` call go show two Q&A entries. Dis one match di Mem0 lab \"memory replay\" step and e show say extra turns dey add to di same transcript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Session 2: Design Review Thread ‚Äî Fresh Session\n",
    "\n",
    "To show say threads dey separate, we go start `design-review-session` and ask for logging guidance for incident reviews. Even though di knowledge base wey dey under dey di same, di new session id go keep transcripts separate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## Review Session 2 History\n",
    "\n",
    "`show_history(session_2)` suppose show only di design-review prompt/response pair. Compare am wit Session 1 to show how Cognee dey keep separate transcripts but still dey use di shared knowledge graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congrats! You don give your coding assistant real long-term memory layer wey dey powered by Cognee.\n",
    "\n",
    "For dis tutorial, you carry raw developer content (code, docs, chats) turn am into graph + vector memory wey your agent fit search, reason on top, and dey improve steady.\n",
    "\n",
    "Wetin You Don Learn\n",
    "\n",
    "1. **From raw text to AI memory**: How Cognee dey take unstructured data turn am into smart, searchable memory using combined vector + knowledge graph architecture.\n",
    "\n",
    "2. **Graph enrichment with memify**: How you fit go beyond just creating graph and use memify take add extra facts and better relationships on top your graph wey don already dey.\n",
    "\n",
    "3. **Multiple search strategies**: How to query memory with different search types (graph-aware Q&A, RAG-style completion, insights, raw chunks, code search, etc.) based on wetin your agent need.\n",
    "\n",
    "4. **Visual exploration**: How to check and debug wetin Cognee don build using graph visualizations and the Cognee UI, so you fit see how knowledge take dey structured.\n",
    "\n",
    "5. **Session-aware memory**: How to join per-session context with persistent semantic memory so agents fit remember across runs without leaking information between users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "1. Memory as Knowledge Graph wey dey use Embeddings\n",
    "\n",
    "   - **Beta understanding**: Cognee dey join vector store and graph store so your data go dey searchable by meaning and e go still connect by relationships. Cognee dey use file-based databases by default (LanceDB for vector-, Kuzu for graph database).\n",
    "\n",
    "   - **Relationship-aware retrieval**: Answers no go just base on ‚Äúsimilar text,‚Äù but e go also consider how entities take relate.\n",
    "\n",
    "   - **Living memory**: The memory layer dey evolve, grow, and e go still dey queryable as one connected graph.\n",
    "\n",
    "2. Search & Reasoning Modes\n",
    "   - **Hybrid retrieval**: Search dey mix vector similarity, graph structure, and LLM reasoning, from raw chunk lookup to graph-aware question answering.\n",
    "\n",
    "   - **Fit the mode to the job**: Use completion-style modes if you want natural language answers, and chunk/summary/graph modes if your agent need raw context or wan drive im own reasoning.\n",
    "\n",
    "3. Personalized, Session-Aware Agents\n",
    "   - **Session context + long-term memory**: Cognee dey keep short-term ‚Äúthread‚Äù context separate from long-lived, user- or org-level memory.\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "1. **Vertical AI Agents**\n",
    "\n",
    "   Use the pattern wey dey this notebook to power domain-smart copilots wey go dey on top of Cognee as their retrieval and reasoning core:\n",
    "\n",
    "- **Developer copilots**: Code review, incident analysis, and architecture assistants wey fit waka through code, APIs, design docs, and tickets as one memory graph.\n",
    "\n",
    "- **Customer-facing copilots**: Support or success agents wey dey pull from product docs, FAQs, CRM notes, and past tickets with graph-aware retrieval and cited answers.\n",
    "\n",
    "- **Internal expert copilots**: Policy, legal, or security assistants wey dey reason over interconnected rules, guidelines, and historical decisions instead of isolated PDFs.\n",
    "\n",
    "   Cognee dey positioned as persistent, accurate memory for AI agents, wey dey provide living knowledge graph wey fit dey behind your agent and replace ad-hoc combinations of vector stores and custom graph code.\n",
    "\n",
    "2. **Unifying Data Silos into One Memory**\n",
    "\n",
    "   This same approach go help you build one unified memory layer across scattered sources:\n",
    "\n",
    "- **From silos to one graph**: Ingest structured (e.g., databases) and unstructured data (e.g., docs, chats) into one single graph wey dey backed by embeddings, instead of separate indices for each system.\n",
    "\n",
    "- **Cross-source reasoning with citations**: Run multi-step reasoning over everything‚Äî‚Äújoin‚Äù logs, metrics, and docs via the graph‚Äîand still return grounded answers with provenance.\n",
    "\n",
    "- **Knowledge hubs**: For domains like banking or education, Cognee don already dey used to unify PDFs, internal systems, and app data into one knowledge graph with vectors so agents fit answer questions with precise, cited context.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You don implement the core memory loop. These na natural extensions wey you fit try on your own (see [Cognee documentation](https://docs.cognee.ai/) for details):\n",
    "\n",
    "1. **Experiment with temporal awareness**: Turn on temporal cognify to extract events and timestamps from text.\n",
    "\n",
    "2. **Introduce ontology-driven reasoning**: Define an OWL ontology for your domain. Use Cognee‚Äôs ontology support so extracted entities and relations go dey grounded in that schema, wey go improve graph quality and domain-specific answers.\n",
    "\n",
    "3. **Add a feedback loop**: Make Cognee dey adjust graph edge weights from real user feedback, so retrieval go dey improve over time instead of staying static.\n",
    "\n",
    "4. **Tune for personalization & session behavior**: Use user IDs, tenants, and datasets to give each person or team their own view over the shared memory engine.\n",
    "\n",
    "5. **Scale out to more complex agents**: Plug Cognee into agent frameworks to build multi-agent systems wey all go dey share the same memory layer. *Microsoft Agent Framework x Cognee plugin dey come soon.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Disclaimer**:  \nDis dokyument don use AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator) do di translation. Even as we dey try make am correct, abeg make you sabi say machine translation fit get mistake or no dey accurate well. Di original dokyument wey dey for im native language na di main source wey you go trust. For important information, e better make professional human translation dey use. We no go fit take blame for any misunderstanding or wrong interpretation wey fit happen because you use dis translation.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T14:54:43+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "pcm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}