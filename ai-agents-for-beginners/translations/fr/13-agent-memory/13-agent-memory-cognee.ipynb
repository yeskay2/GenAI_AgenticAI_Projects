{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Construire des agents IA avec une m√©moire persistante en utilisant Cognee\n",
    "\n",
    "Ce notebook montre comment cr√©er des agents IA intelligents avec des capacit√©s de m√©moire sophistiqu√©es en utilisant [**cognee**](https://www.cognee.ai/) - une m√©moire IA open source qui combine des graphes de connaissances, une recherche s√©mantique et une gestion de session pour cr√©er des syst√®mes IA sensibles au contexte.\n",
    "\n",
    "## üéØ Objectifs d'apprentissage\n",
    "\n",
    "√Ä la fin de ce tutoriel, vous serez capable de :\n",
    "- **Construire des graphes de connaissances bas√©s sur des embeddings** : Transformer du texte non structur√© en connaissances structur√©es et interrogeables\n",
    "- **Mettre en ≈ìuvre une m√©moire de session** : Cr√©er des conversations multi-tours avec une r√©tention automatique du contexte\n",
    "- **Conserver les conversations** : Stocker √©ventuellement des interactions importantes dans une m√©moire √† long terme pour une utilisation future\n",
    "- **Interroger en langage naturel** : Acc√©der et exploiter le contexte historique dans de nouvelles conversations\n",
    "- **Visualiser la m√©moire** : Explorer les relations dans le graphe de connaissances de votre agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Ce que vous allez construire\n",
    "\n",
    "Dans ce tutoriel, nous allons cr√©er un **Assistant de Codage** avec une m√©moire persistante qui :\n",
    "\n",
    "### 1. **Construction d'une base de connaissances**\n",
    "   - Int√®gre les informations sur le profil et l'expertise des d√©veloppeurs\n",
    "   - Traite les principes et les bonnes pratiques de programmation en Python\n",
    "   - Stocke les conversations historiques entre les d√©veloppeurs et les assistants IA\n",
    "\n",
    "### 2. **Conversations conscientes du contexte**\n",
    "   - Maintient le contexte √† travers plusieurs questions dans une m√™me session\n",
    "   - Met automatiquement en cache chaque paire question/r√©ponse pour une r√©cup√©ration efficace\n",
    "   - Fournit des r√©ponses coh√©rentes et contextuelles bas√©es sur l'historique de la conversation\n",
    "\n",
    "### 3. **M√©moire √† long terme**\n",
    "   - Conserve les conversations importantes dans une m√©moire √† long terme\n",
    "   - R√©cup√®re des souvenirs pertinents de la base de connaissances et des sessions pass√©es pour informer de nouvelles interactions\n",
    "   - Construit une base de connaissances √©volutive qui s'am√©liore avec le temps\n",
    "\n",
    "### 4. **R√©cup√©ration intelligente de la m√©moire**\n",
    "   - Utilise une recherche s√©mantique bas√©e sur les graphes pour trouver des informations pertinentes dans toutes les connaissances stock√©es\n",
    "   - Filtre les recherches par sous-groupes de donn√©es (informations sur les d√©veloppeurs vs principes)\n",
    "   - Combine plusieurs sources de donn√©es pour fournir des r√©ponses compl√®tes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Pr√©requis et Configuration\n",
    "\n",
    "### Configuration syst√®me\n",
    "\n",
    "Avant de commencer, assurez-vous d'avoir :\n",
    "\n",
    "1. **Environnement Python**\n",
    "   - Python 3.9 ou sup√©rieur\n",
    "   - Environnement virtuel (recommand√©)\n",
    "   \n",
    "2. **Cache Redis** (Requis pour la gestion des sessions)\n",
    "   - Redis local : `docker run -d -p 6379:6379 redis`\n",
    "   - Ou utilisez un service Redis g√©r√©\n",
    "   \n",
    "3. **Acc√®s √† l'API LLM**\n",
    "   - Cl√© API OpenAI ou autres fournisseurs (voir [documentation](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Configuration de la base de donn√©es**\n",
    "   - Aucune configuration requise par d√©faut. Cognee utilise des bases de donn√©es bas√©es sur des fichiers (LanceDB et Kuzu)\n",
    "   - Optionnellement, vous pouvez configurer Azure AI Search comme magasin de vecteurs (voir [documentation](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Configuration de l'environnement\n",
    "\n",
    "Cr√©ez un fichier `.env` dans le r√©pertoire de votre projet avec les variables suivantes :\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Comprendre l'Architecture M√©moire de Cognee\n",
    "\n",
    "### Comment fonctionne Cognee\n",
    "\n",
    "Cognee offre un syst√®me de m√©moire sophistiqu√© qui va au-del√† d'un simple stockage cl√©-valeur :\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Composants cl√©s :\n",
    "\n",
    "1. **Graph de Connaissances** : Stocke les entit√©s, les relations et les connexions s√©mantiques\n",
    "2. **Embeddings Vectoriels** : Permet la recherche s√©mantique √† travers toutes les informations stock√©es\n",
    "3. **Cache de Session** : Conserve le contexte des conversations au sein et entre les sessions\n",
    "4. **NodeSets** : Organise les donn√©es en cat√©gories logiques pour une r√©cup√©ration cibl√©e\n",
    "\n",
    "### Types de m√©moire dans ce tutoriel :\n",
    "\n",
    "- **M√©moire Persistante** : Stockage √† long terme dans le graph de connaissances\n",
    "- **M√©moire de Session** : Contexte temporaire des conversations dans le cache Redis\n",
    "- **M√©moire S√©mantique** : Recherche de similarit√© bas√©e sur des vecteurs √† travers toutes les donn√©es\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Installer les paquets requis\n",
    "\n",
    "Installez Cognee avec le support de Redis pour la gestion des sessions :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß Initialiser l'environnement et charger les biblioth√®ques\n",
    "\n",
    "Assurez-vous que :\n",
    "1. Redis est en cours d'ex√©cution (par exemple, via Docker : `docker run -d -p 6379:6379 redis`)\n",
    "2. Les variables d'environnement sont d√©finies avant d'importer les modules de cache\n",
    "3. Si n√©cessaire, red√©marrez le noyau et ex√©cutez les cellules dans l'ordre\n",
    "\n",
    "La cellule suivante va :\n",
    "1. Charger les variables d'environnement depuis `.env`\n",
    "2. Configurer Cognee avec vos param√®tres LLM\n",
    "3. Activer la mise en cache pour la gestion des sessions\n",
    "4. Valider que tous les composants sont correctement connect√©s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ Configurer les r√©pertoires de stockage\n",
    "\n",
    "Cognee utilise deux r√©pertoires distincts pour ses op√©rations :\n",
    "- **Racine des donn√©es** : Stocke les documents ing√©r√©s et les donn√©es trait√©es\n",
    "- **Racine syst√®me** : Contient la base de donn√©es du graphe de connaissances et les m√©tadonn√©es du syst√®me\n",
    "\n",
    "Nous allons cr√©er des r√©pertoires isol√©s pour ce tutoriel comme suit :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ R√©initialiser l'√©tat de la m√©moire\n",
    "\n",
    "Avant de commencer √† construire notre syst√®me de m√©moire, assurons-nous de partir sur une base saine.\n",
    "\n",
    "> üí° **Astuce** : Vous pouvez passer cette √©tape si vous souhaitez conserver les souvenirs existants de vos pr√©c√©dentes ex√©cutions lorsque vous utiliserez ce notebook ult√©rieurement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Partie 1 : Construire la base de connaissances\n",
    "\n",
    "### Sources de donn√©es pour notre assistant d√©veloppeur\n",
    "\n",
    "Nous allons int√©grer trois types de donn√©es pour cr√©er une base de connaissances compl√®te :\n",
    "\n",
    "1. **Profil du d√©veloppeur** : Expertise personnelle et parcours technique  \n",
    "2. **Bonnes pratiques Python** : Le Zen de Python avec des directives pratiques  \n",
    "3. **Conversations historiques** : Sessions de questions-r√©ponses pass√©es entre d√©veloppeurs et assistants IA  \n",
    "\n",
    "Ces donn√©es vari√©es permettent √† notre agent de :  \n",
    "- Comprendre le contexte technique de l'utilisateur  \n",
    "- Appliquer les meilleures pratiques dans ses recommandations  \n",
    "- Apprendre des interactions r√©ussies pr√©c√©dentes  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Transformer les donn√©es en graphe de connaissances\n",
    "\n",
    "Nous allons maintenant transformer notre texte brut en une m√©moire structur√©e. Ce processus :\n",
    "\n",
    "1. **Ajoute des donn√©es aux NodeSets** : Organise les informations en cat√©gories logiques\n",
    "   - `developer_data` : Profil du d√©veloppeur et conversations\n",
    "   - `principles_data` : Bonnes pratiques et directives Python\n",
    "\n",
    "2. **Ex√©cute le pipeline Cognify** : Extrait les entit√©s, les relations et cr√©e des embeddings\n",
    "   - Identifie les concepts cl√©s\n",
    "   - Cr√©e des connexions s√©mantiques entre les informations li√©es\n",
    "   - G√©n√®re des embeddings vectoriels\n",
    "\n",
    "Cela peut prendre quelques instants pendant que le LLM traite le texte et construit la structure du graphe :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä Visualiser le graphe de connaissances\n",
    "\n",
    "Explorons la structure de notre graphe de connaissances. La visualisation montre :\n",
    "- **N≈ìuds** : Entit√©s extraites du texte (concepts, technologies, personnes)\n",
    "- **Ar√™tes** : Relations et connexions entre les entit√©s\n",
    "- **Clusters** : Concepts li√©s regroup√©s par similarit√© s√©mantique\n",
    "\n",
    "Ouvrez le fichier HTML g√©n√©r√© dans votre navigateur pour explorer le graphe de mani√®re interactive :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Enrichir la m√©moire avec Memify\n",
    "\n",
    "La fonction `memify()` analyse le graphe de connaissances et g√©n√®re des r√®gles intelligentes sur les donn√©es. Ce processus :\n",
    "- Identifie des mod√®les et des bonnes pratiques\n",
    "- Cr√©e des directives exploitables bas√©es sur le contenu\n",
    "- √âtablit des relations entre diff√©rentes zones de connaissances\n",
    "\n",
    "Ces r√®gles aident l'agent √† prendre des d√©cisions plus √©clair√©es lorsqu'il r√©pond aux questions. Capturer une deuxi√®me visualisation vous permet de comparer comment le graphe se densifie une fois enrichi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Partie 2 : R√©cup√©ration intelligente de la m√©moire\n",
    "\n",
    "### D√©monstration 1 : Int√©gration des connaissances entre documents\n",
    "\n",
    "Maintenant que notre graphe de connaissances est construit, testons comment Cognee combine des informations provenant de plusieurs sources pour r√©pondre √† des questions complexes.\n",
    "\n",
    "La premi√®re requ√™te d√©montre :\n",
    "- **Compr√©hension s√©mantique** : Trouver des concepts pertinents m√™me s'ils ne sont pas mentionn√©s explicitement\n",
    "- **R√©f√©rencement crois√©** : Combiner le profil du d√©veloppeur avec les principes de Python\n",
    "- **Raisonnement contextuel** : Appliquer les meilleures pratiques √† des impl√©mentations sp√©cifiques\n",
    "\n",
    "### D√©monstration 2 : Recherche filtr√©e avec NodeSets\n",
    "\n",
    "La deuxi√®me requ√™te montre comment cibler des sous-ensembles sp√©cifiques du graphe de connaissances :\n",
    "- Utilise le param√®tre `node_name` pour rechercher uniquement dans `principles_data`\n",
    "- Fournit des r√©ponses cibl√©es provenant d'un domaine de connaissances sp√©cifique\n",
    "- Utile lorsque vous avez besoin d'informations sp√©cifiques √† un domaine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Partie 3 : Configuration de la gestion des sessions\n",
    "\n",
    "### Activer la m√©moire des conversations\n",
    "\n",
    "La gestion des sessions est essentielle pour conserver le contexte au fil de plusieurs interactions. Ici, nous allons :\n",
    "\n",
    "1. **Initialiser le contexte utilisateur** : Cr√©er ou r√©cup√©rer un profil utilisateur pour le suivi des sessions\n",
    "2. **Configurer le moteur de cache** : Se connecter √† Redis pour stocker l'historique des conversations\n",
    "3. **Activer les variables de session** : Configurer des variables de contexte qui persistent entre les requ√™tes\n",
    "\n",
    "> ‚ö†Ô∏è **Important** : Cela n√©cessite que Redis soit en cours d'ex√©cution et que `CACHING=true` soit activ√© dans votre environnement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Fonction d'aide : Voir l'historique de session\n",
    "\n",
    "Cette fonction utilitaire nous permet d'inspecter l'historique des conversations stock√© dans Redis. Elle est utile pour :\n",
    "- D√©boguer la gestion des sessions\n",
    "- V√©rifier que les conversations sont mises en cache\n",
    "- Comprendre quel contexte est disponible pour l'agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Session 1 : Laboratoire de support asynchrone ‚Äî Premi√®re question\n",
    "\n",
    "Lancez la session `async-support-lab` en demandant des mod√®les asyncio adapt√©s √† la t√©l√©m√©trie pour un √©norme outil de scraping web. Le graphe conna√Æt d√©j√† asyncio, aiohttp et les pratiques de surveillance, donc la r√©ponse devrait refl√©ter les conversations pr√©c√©dentes tout en adaptant la r√©ponse √† cette nouvelle requ√™te.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Inspecter la m√©moire de la session 1 apr√®s le premier √©change\n",
    "\n",
    "Ex√©cuter `show_history(session_1)` imm√©diatement apr√®s la question initiale confirme que Cognee a enregistr√© √† la fois l'invite et la r√©ponse dans Redis. Vous devriez voir une entr√©e avec les indications de concurrence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Session 1 : Suivi sur les mod√®les de donn√©es\n",
    "\n",
    "Ensuite, nous nous demandons : \"Quand devrais-je choisir dataclasses plut√¥t que Pydantic ?\" en utilisant le m√™me identifiant de session. Cognee devrait rassembler les principes Python ainsi que les conversations pr√©c√©dentes sur FastAPI pour fournir des conseils nuanc√©s‚Äîd√©montrant que le contexte se poursuit au sein d'une session nomm√©e.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Confirmer que l'historique de la session 1 contient les deux √©changes\n",
    "\n",
    "Un autre appel √† `show_history(session_1)` devrait r√©v√©ler deux entr√©es de questions-r√©ponses. Cela correspond √† l'√©tape de \"relecture de m√©moire\" du laboratoire Mem0 et prouve que des √©changes suppl√©mentaires prolongent le m√™me transcript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Session 2 : Fil de discussion sur la revue de conception ‚Äî Nouvelle session\n",
    "\n",
    "Pour montrer l'isolation entre les fils de discussion, nous lan√ßons `design-review-session` et demandons des conseils de journalisation pour les revues d'incidents. Bien que la base de connaissances sous-jacente soit la m√™me, le nouvel identifiant de session permet de garder les transcriptions s√©par√©es.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## R√©vision de la session 2 : Histoire\n",
    "\n",
    "`show_history(session_2)` doit uniquement afficher le couple de question/r√©ponse de la revue de conception. Comparez cela avec la Session 1 pour mettre en √©vidence comment Cognee conserve des transcriptions ind√©pendantes tout en r√©utilisant le graphe de connaissances partag√©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## R√©sum√©\n",
    "\n",
    "F√©licitations ! Vous venez d'offrir √† votre assistant de codage une v√©ritable couche de m√©moire √† long terme gr√¢ce √† Cognee.\n",
    "\n",
    "Dans ce tutoriel, vous avez pris du contenu brut de d√©veloppeur (code, documents, discussions) et l'avez transform√© en une m√©moire graphique + vectorielle que votre agent peut rechercher, analyser et am√©liorer en continu.\n",
    "\n",
    "Ce que vous avez appris :\n",
    "\n",
    "1. **Du texte brut √† la m√©moire IA** : Comment Cognee ing√®re des donn√©es non structur√©es et les transforme en une m√©moire intelligente et consultable gr√¢ce √† une architecture combin√©e de vecteurs + graphe de connaissances.\n",
    "\n",
    "2. **Enrichissement du graphe avec memify** : Comment aller au-del√† de la cr√©ation de graphe de base et utiliser memify pour ajouter des faits d√©riv√©s et des relations plus riches √† votre graphe existant.\n",
    "\n",
    "3. **Strat√©gies de recherche multiples** : Comment interroger la m√©moire avec diff√©rents types de recherche (Q&R avec conscience du graphe, compl√©tion de style RAG, insights, fragments bruts, recherche de code, etc.) en fonction des besoins de votre agent.\n",
    "\n",
    "4. **Exploration visuelle** : Comment inspecter et d√©boguer ce que Cognee a construit en utilisant des visualisations de graphe et l'interface utilisateur de Cognee, afin de voir concr√®tement comment les connaissances sont structur√©es.\n",
    "\n",
    "5. **M√©moire sensible aux sessions** : Comment combiner le contexte par session avec une m√©moire s√©mantique persistante pour que les agents puissent se souvenir d'une session √† l'autre sans divulguer d'informations entre les utilisateurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Points Cl√©s\n",
    "1. M√©moire sous forme de Graphique de Connaissances soutenue par des Embeddings\n",
    "\n",
    "   - **Compr√©hension structur√©e** : Cognee combine un magasin de vecteurs et un magasin de graphes pour que vos donn√©es soient √† la fois recherchables par signification et connect√©es par des relations. Par d√©faut, Cognee utilise des bases de donn√©es bas√©es sur des fichiers (LanceDB pour les vecteurs, Kuzu pour les bases de donn√©es graphiques).\n",
    "\n",
    "   - **R√©cup√©ration sensible aux relations** : Les r√©ponses peuvent √™tre bas√©es non seulement sur du \"texte similaire\", mais aussi sur la mani√®re dont les entit√©s sont reli√©es.\n",
    "\n",
    "   - **M√©moire vivante** : La couche m√©moire √©volue, grandit et reste interrogeable comme un graphique connect√© unique.\n",
    "\n",
    "2. Modes de Recherche et de Raisonnement\n",
    "   - **R√©cup√©ration hybride** : La recherche combine la similarit√© vectorielle, la structure du graphe et le raisonnement LLM, allant de la recherche brute de fragments √† des r√©ponses aux questions tenant compte du graphe.\n",
    "\n",
    "   - **Adapter le mode √† la t√¢che** : Utilisez les modes de type compl√©tion lorsque vous souhaitez des r√©ponses en langage naturel, et les modes fragment/r√©sum√©/graphe lorsque votre agent a besoin de contexte brut ou pour alimenter son propre raisonnement.\n",
    "\n",
    "3. Agents Personnalis√©s et Sensibles aux Sessions\n",
    "   - **Contexte de session + m√©moire √† long terme** : Cognee s√©pare le contexte √† court terme des \"fils de discussion\" de la m√©moire durable au niveau de l'utilisateur ou de l'organisation.\n",
    "\n",
    "## Applications R√©elles\n",
    "\n",
    "1. **Agents IA Verticaux**\n",
    "\n",
    "   Utilisez le mod√®le de ce notebook pour alimenter des copilotes intelligents dans leur domaine, reposant sur Cognee comme c≈ìur de r√©cup√©ration et de raisonnement :\n",
    "\n",
    "- **Copilotes pour d√©veloppeurs** : Assistance pour la revue de code, l'analyse d'incidents et l'architecture, traversant le code, les API, les documents de conception et les tickets comme un seul graphique m√©moire.\n",
    "\n",
    "- **Copilotes orient√©s client** : Agents de support ou de succ√®s qui puisent dans les documents produits, FAQ, notes CRM et tickets pass√©s avec une r√©cup√©ration tenant compte des graphes et des r√©ponses cit√©es.\n",
    "\n",
    "- **Copilotes experts internes** : Assistants en politique, juridique ou s√©curit√© qui raisonnent sur des r√®gles, directives et d√©cisions historiques interconnect√©es au lieu de PDF isol√©s.\n",
    "\n",
    "   Cognee se positionne explicitement comme une m√©moire persistante et pr√©cise pour les agents IA, fournissant un graphique de connaissances vivant qui s'int√®gre derri√®re votre agent et remplace les combinaisons ad hoc de magasins de vecteurs et de code graphique personnalis√©.\n",
    "\n",
    "2. **Unifier les Silos de Donn√©es en une M√©moire Unique**\n",
    "\n",
    "   La m√™me approche vous aide √©galement √† construire une couche m√©moire unifi√©e √† partir de sources dispers√©es :\n",
    "\n",
    "- **Des silos √† un seul graphe** : Int√©grez des donn√©es structur√©es (par ex., bases de donn√©es) et non structur√©es (par ex., documents, discussions) dans un seul graphe soutenu par des embeddings, plut√¥t que des index s√©par√©s pour chaque syst√®me.\n",
    "\n",
    "- **Raisonnement inter-sources avec citations** : Effectuez un raisonnement en plusieurs √©tapes sur tout‚Äî\"joignez\" journaux, m√©triques et documents via le graphe‚Äîet retournez toujours des r√©ponses fond√©es avec provenance.\n",
    "\n",
    "- **Hubs de connaissances** : Pour des domaines comme la banque ou l'√©ducation, Cognee est d√©j√† utilis√© pour unifier des PDF, des syst√®mes internes et des donn√©es d'applications en un seul graphique de connaissances avec des vecteurs, permettant aux agents de r√©pondre √† des questions avec un contexte pr√©cis et cit√©.\n",
    "\n",
    "## Prochaines √âtapes\n",
    "\n",
    "Vous avez mis en ≈ìuvre la boucle m√©moire principale. Voici des extensions naturelles que vous pouvez essayer par vous-m√™me (voir la [documentation Cognee](https://docs.cognee.ai/) pour plus de d√©tails) :\n",
    "\n",
    "1. **Exp√©rimentez avec la conscience temporelle** : Activez la fonction de cognition temporelle pour extraire des √©v√©nements et des horodatages √† partir de texte.\n",
    "\n",
    "2. **Introduisez un raisonnement bas√© sur une ontologie** : D√©finissez une ontologie OWL pour votre domaine. Utilisez le support d'ontologie de Cognee pour que les entit√©s et relations extraites soient ancr√©es dans ce sch√©ma, am√©liorant la qualit√© du graphe et les r√©ponses sp√©cifiques au domaine.\n",
    "\n",
    "3. **Ajoutez une boucle de r√©troaction** : Permettez √† Cognee d'ajuster les poids des ar√™tes du graphe √† partir des retours r√©els des utilisateurs, afin que la r√©cup√©ration s'am√©liore avec le temps au lieu de rester statique.\n",
    "\n",
    "4. **Optimisez pour la personnalisation et le comportement en session** : Utilisez des identifiants d'utilisateur, des locataires et des ensembles de donn√©es pour offrir √† chaque personne ou √©quipe sa propre vue sur le moteur de m√©moire partag√©.\n",
    "\n",
    "5. **√âtendez √† des agents plus complexes** : Connectez Cognee √† des frameworks d'agents pour construire des syst√®mes multi-agents partageant tous la m√™me couche m√©moire. *Le plugin Microsoft Agent Framework x Cognee arrive bient√¥t.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Avertissement** :  \nCe document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:14:02+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "fr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}