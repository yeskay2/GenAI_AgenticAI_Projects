{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# സെമാന്റിക് കർണൽ\n",
    "\n",
    "ഈ കോഡ് സാമ്പിളിൽ, [സെമാന്റിക് കർണൽ](https://aka.ms/ai-agents-beginners/semantic-kernel) AI ഫ്രെയിംവർക്കിനെ ഉപയോഗിച്ച് ഒരു അടിസ്ഥാന ഏജന്റ് സൃഷ്ടിക്കും.\n",
    "\n",
    "വിവിധ ഏജന്റിക് പാറ്റേണുകൾ നടപ്പിലാക്കുമ്പോൾ, പിന്നീട് ഉപയോഗിക്കുന്ന അധിക കോഡ് സാമ്പിളുകളിൽ ഞങ്ങൾ സ്വീകരിക്കുന്ന ഘട്ടങ്ങൾ നിങ്ങൾക്ക് കാണിക്കാൻ ഈ സാമ്പിളിന്റെ ലക്ഷ്യമാണ്.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ആവശ്യമായ പൈത്തൺ പാക്കേജുകൾ ഇറക്കുമതി ചെയ്യുക\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import Annotated\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ക്ലയന്റ് സൃഷ്ടിക്കൽ\n",
    "\n",
    "ഈ ഉദാഹരണത്തിൽ, LLM-ലേക്ക് പ്രവേശനത്തിനായി [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) ഉപയോഗിക്കും.\n",
    "\n",
    "`ai_model_id` എന്നത് `gpt-4o-mini` ആയി നിർവചിച്ചിരിക്കുന്നു. GitHub Models മാർക്കറ്റ്പ്ലേസിൽ ലഭ്യമായ മറ്റൊരു മോഡലിലേക്ക് മോഡൽ മാറ്റി വ്യത്യസ്ത ഫലങ്ങൾ കാണാൻ ശ്രമിക്കുക.\n",
    "\n",
    "GitHub Models-ക്കുള്ള `base_url` ഉപയോഗിക്കുന്ന `Azure Inference SDK` ഉപയോഗിക്കാൻ, Semantic Kernel-ൽ `OpenAIChatCompletion` കണക്റ്റർ ഉപയോഗിക്കും. Semantic Kernel ഉപയോഗിച്ച് മറ്റ് മോഡൽ പ്രൊവൈഡർമാർക്കുള്ള [ലഭ്യമായ മറ്റ് കണക്റ്ററുകൾ](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) ഉണ്ട്.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "\n",
    "class DestinationsPlugin:\n",
    "    \"\"\"A List of Random Destinations for a vacation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # List of vacation destinations\n",
    "        self.destinations = [\n",
    "            \"Barcelona, Spain\",\n",
    "            \"Paris, France\",\n",
    "            \"Berlin, Germany\",\n",
    "            \"Tokyo, Japan\",\n",
    "            \"Sydney, Australia\",\n",
    "            \"New York, USA\",\n",
    "            \"Cairo, Egypt\",\n",
    "            \"Cape Town, South Africa\",\n",
    "            \"Rio de Janeiro, Brazil\",\n",
    "            \"Bali, Indonesia\"\n",
    "        ]\n",
    "        # Track last destination to avoid repeats\n",
    "        self.last_destination = None\n",
    "\n",
    "    @kernel_function(description=\"Provides a random vacation destination.\")\n",
    "    def get_random_destination(self) -> Annotated[str, \"Returns a random vacation destination.\"]:\n",
    "        # Get available destinations (excluding last one if possible)\n",
    "        available_destinations = self.destinations.copy()\n",
    "        if self.last_destination and len(available_destinations) > 1:\n",
    "            available_destinations.remove(self.last_destination)\n",
    "\n",
    "        # Select a random destination\n",
    "        destination = random.choice(available_destinations)\n",
    "\n",
    "        # Update the last destination\n",
    "        self.last_destination = destination\n",
    "\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ഏജന്റ് സൃഷ്ടിക്കുന്നത്\n",
    "\n",
    "താഴെ `TravelAgent` എന്ന ഏജന്റ് സൃഷ്ടിക്കുന്നു.\n",
    "\n",
    "ഈ ഉദാഹരണത്തിൽ, വളരെ ലളിതമായ നിർദ്ദേശങ്ങൾ ഉപയോഗിക്കുന്നു. ഏജന്റിന്റെ പ്രതികരണം എങ്ങനെ വ്യത്യസ്തമാകുന്നുവെന്ന് കാണാൻ നിങ്ങൾക്ക് ഈ നിർദ്ദേശങ്ങൾ മാറ്റാം.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service, \n",
    "    plugins=[DestinationsPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"You are a helpful AI Agent that can help plan vacations for customers at random destinations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ഏജന്റ് പ്രവർത്തിപ്പിക്കൽ\n",
    "\n",
    "ഇപ്പോൾ, `ChatHistoryAgentThread` എന്ന തരം ഒരു ത്രെഡ് നിർവചിച്ച് ഏജന്റ് പ്രവർത്തിപ്പിക്കാം. ഏജന്റിന്റെ invoke_stream `messages` കീവേഡ് ആർഗുമെന്റിലേക്ക് ആവശ്യമായ സിസ്റ്റം സന്ദേശങ്ങൾ നൽകാം.\n",
    "\n",
    "ഇവ നിർവചിച്ചതിന് ശേഷം, ഉപയോക്താവ് ഏജന്റിലേക്ക് അയക്കുന്ന സന്ദേശമായ `user_inputs` സൃഷ്ടിക്കുന്നു. ഈ സന്ദേശം `Plan me a sunny vacation` ആയി സജ്ജമാക്കിയിരിക്കുന്നു.\n",
    "\n",
    "ഏജന്റ് വ്യത്യസ്തമായി പ്രതികരിക്കുന്നതിനെ കാണാൻ ഈ സന്ദേശം മാറ്റാൻ മടിക്കേണ്ടതില്ല.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create a new thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Plan me a day trip.\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            # 5. Print the response\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(f\"{response}\", end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    # Clean up the thread\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**അസത്യവാദം**:  \nഈ രേഖ AI വിവർത്തന സേവനമായ [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് വിവർത്തനം ചെയ്തതാണ്. കൃത്യതയ്ക്കായി ഞങ്ങൾ ശ്രമിക്കുന്നുവെങ്കിലും, ഓട്ടോമേറ്റഡ് വിവർത്തനങ്ങളിൽ പിശകുകൾ അല്ലെങ്കിൽ തെറ്റായ വിവരങ്ങൾ ഉണ്ടാകാൻ സാധ്യതയുണ്ട്. അതിന്റെ സ്വാഭാവിക ഭാഷയിലുള്ള മൗലിക രേഖ പ്രാമാണികമായ ഉറവിടമായി പരിഗണിക്കണം. നിർണായകമായ വിവരങ്ങൾക്ക്, പ്രൊഫഷണൽ മനുഷ്യ വിവർത്തനം ശുപാർശ ചെയ്യുന്നു. ഈ വിവർത്തനം ഉപയോഗിച്ച് ഉണ്ടാകുന്ന തെറ്റിദ്ധാരണകൾക്കോ തെറ്റായ വ്യാഖ്യാനങ്ങൾക്കോ ഞങ്ങൾ ഉത്തരവാദികളല്ല.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9faeec13969c8dff8a53f0933771d228",
   "translation_date": "2025-12-03T18:26:26+00:00",
   "source_file": "01-intro-to-ai-agents/code_samples/01-semantic-kernel.ipynb",
   "language_code": "ml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}