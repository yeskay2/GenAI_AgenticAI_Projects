{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# 使用 Cognee 构建具有持久记忆的 AI 代理\n",
    "\n",
    "本笔记本演示了如何使用 [**cognee**](https://www.cognee.ai/) 构建具有复杂记忆功能的智能 AI 代理。Cognee 是一种开源的 AI 记忆系统，它结合了知识图谱、语义搜索和会话管理，能够创建具有上下文感知能力的 AI 系统。\n",
    "\n",
    "## 🎯 学习目标\n",
    "\n",
    "通过本教程，你将学会：\n",
    "- **构建基于嵌入的知识图谱**：将非结构化文本转化为结构化、可查询的知识\n",
    "- **实现会话记忆**：创建多轮对话并自动保留上下文\n",
    "- **持久化对话**：可选择将重要的交互存储在长期记忆中以供将来参考\n",
    "- **使用自然语言查询**：在新对话中访问并利用历史上下文\n",
    "- **可视化记忆**：探索代理知识图谱中的关系\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## 🏗️ 您将构建的内容\n",
    "\n",
    "在本教程中，我们将创建一个具有持久记忆的**编码助手**，其功能包括：\n",
    "\n",
    "### 1. **知识库构建**\n",
    "   - 获取开发者的个人资料和专业信息\n",
    "   - 处理 Python 编程原则和最佳实践\n",
    "   - 存储开发者与 AI 助手之间的历史对话\n",
    "\n",
    "### 2. **会话感知对话**\n",
    "   - 在同一会话中保持上下文关联\n",
    "   - 自动缓存每个问题/答案对以提高检索效率\n",
    "   - 基于对话历史提供连贯且有上下文的回复\n",
    "\n",
    "### 3. **长期记忆**\n",
    "   - 将重要对话存储到长期记忆中\n",
    "   - 从知识库和过去的会话中检索相关记忆以辅助新交互\n",
    "   - 构建一个不断增长的知识库，随着时间推移不断改进\n",
    "\n",
    "### 4. **智能记忆检索**\n",
    "   - 使用图感知语义搜索在所有存储的知识中查找相关信息\n",
    "   - 按数据子组（开发者信息 vs. 编程原则）过滤搜索\n",
    "   - 结合多个数据源提供全面的答案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## 📋 前置条件与设置\n",
    "\n",
    "### 系统要求\n",
    "\n",
    "在开始之前，请确保您具备以下条件：\n",
    "\n",
    "1. **Python 环境**\n",
    "   - Python 3.9 或更高版本\n",
    "   - 推荐使用虚拟环境\n",
    "\n",
    "2. **Redis 缓存**（用于会话管理，必需）\n",
    "   - 本地 Redis: `docker run -d -p 6379:6379 redis`\n",
    "   - 或使用托管的 Redis 服务\n",
    "\n",
    "3. **LLM API 访问**\n",
    "   - OpenAI API 密钥或其他提供商（参见[文档](https://docs.cognee.ai/setup-configuration/llm-providers)）\n",
    "\n",
    "4. **数据库配置**\n",
    "   - 默认无需配置。Cognee 使用基于文件的数据库（LanceDB 和 Kuzu）\n",
    "   - 可选：您可以设置 Azure AI Search 作为向量存储（参见[文档](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch)）\n",
    "\n",
    "### 环境配置\n",
    "\n",
    "在您的项目目录中创建一个 `.env` 文件，并包含以下变量：\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## 🏛️ 理解Cognee的记忆架构\n",
    "\n",
    "### Cognee的工作原理\n",
    "\n",
    "Cognee提供了一个复杂的记忆系统，超越了简单的键值存储：\n",
    "\n",
    "```\n",
    "┌──────────────────────────┐\n",
    "│      30+ data sources    │\n",
    "└───────────┬──────────────┘\n",
    "            │\n",
    "            ▼\n",
    "┌──────────────────────────────────────────┐\n",
    "│  Dynamically evolving memory layers      │\n",
    "│                                          │\n",
    "│  ┌────────────────────────────────────┐  │\n",
    "│  │ Knowledge Graph in Graph Database  │  │\n",
    "│  └────────────────────────────────────┘  │\n",
    "│  ┌────────────────────────────────────┐  │\n",
    "│  │ Embeddings in Vector Store         │  │\n",
    "│  │   (e.g., Azure AI Search)          │  │\n",
    "│  └────────────────────────────────────┘  │\n",
    "└───────────┬──────────────────────────────┘\n",
    "            │                      ▲   \n",
    "            ▼                      │(optional)\n",
    "┌────────────────┐           ┌────────────────┐\n",
    "│     cognee     │(optional) │ Cognee Session │\n",
    "│    retrievers  │──────────▶│     Cache      │\n",
    "│                │           │    (Redis)     │\n",
    "└───────┬────────┘           └────────────────┘\n",
    "        ▲\n",
    "        │\n",
    "┌──────────────────────────┐\n",
    "│          Agents          │\n",
    "└──────────────────────────┘\n",
    "\n",
    "```\n",
    "\n",
    "### 关键组件：\n",
    "\n",
    "1. **知识图谱**：存储实体、关系和语义连接\n",
    "2. **向量嵌入**：支持对所有存储信息的语义搜索\n",
    "3. **会话缓存**：在会话内及跨会话维持对话上下文\n",
    "4. **节点集**：将数据组织成逻辑类别以便于目标检索\n",
    "\n",
    "### 本教程中的记忆类型：\n",
    "\n",
    "- **持久记忆**：知识图谱中的长期存储\n",
    "- **会话记忆**：Redis缓存中的临时对话上下文\n",
    "- **语义记忆**：基于向量的相似性搜索覆盖所有数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## 📦 安装所需软件包\n",
    "\n",
    "安装带有 Redis 支持的 Cognee 以进行会话管理：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## 🔧 初始化环境并加载库\n",
    "\n",
    "确保：\n",
    "1. Redis 正在运行（例如，通过 Docker：`docker run -d -p 6379:6379 redis`）\n",
    "2. 在导入缓存模块之前设置环境变量\n",
    "3. 如果需要，重新启动内核并按顺序运行单元格\n",
    "\n",
    "以下单元格将会：\n",
    "1. 从 `.env` 文件加载环境变量\n",
    "2. 使用您的 LLM 设置配置 Cognee\n",
    "3. 启用会话管理的缓存功能\n",
    "4. 验证所有组件是否正确连接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## 📁 配置存储目录\n",
    "\n",
    "Cognee 使用两个独立的目录进行操作：\n",
    "- **数据根目录**：存储已导入的文档和处理后的数据\n",
    "- **系统根目录**：包含知识图谱数据库和系统元数据\n",
    "\n",
    "在本教程中，我们将创建独立的目录，如下所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## 🧹 重置记忆状态\n",
    "\n",
    "在我们开始构建记忆系统之前，先确保我们从头开始。\n",
    "\n",
    "> 💡 **提示**：如果您希望在以后使用此笔记本时保留之前运行的现有记忆，可以跳过此步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## 📚 第1部分：构建知识库\n",
    "\n",
    "### 我们开发者助手的数据来源\n",
    "\n",
    "我们将引入三种类型的数据来创建一个全面的知识库：\n",
    "\n",
    "1. **开发者档案**：个人专业知识和技术背景  \n",
    "2. **Python最佳实践**：Python之禅及其实用指南  \n",
    "3. **历史对话**：开发者与AI助手之间的过去问答记录  \n",
    "\n",
    "这些多样化的数据使我们的代理能够：  \n",
    "- 理解用户的技术背景  \n",
    "- 在推荐中应用最佳实践  \n",
    "- 从以往成功的互动中学习  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## 🔄 将数据转化为知识图谱\n",
    "\n",
    "现在我们将把原始文本转化为结构化的记忆。这个过程包括：\n",
    "\n",
    "1. **将数据添加到 NodeSets**：将信息组织到逻辑分类中\n",
    "   - `developer_data`：开发者资料和对话\n",
    "   - `principles_data`：Python最佳实践和指导原则\n",
    "\n",
    "2. **运行 Cognify Pipeline**：提取实体、关系并创建嵌入\n",
    "   - 识别关键概念\n",
    "   - 在相关信息之间创建语义连接\n",
    "   - 生成向量嵌入\n",
    "\n",
    "这可能需要一些时间，因为LLM正在处理文本并构建图谱结构：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## 📊 可视化知识图谱\n",
    "\n",
    "让我们来探索知识图谱的结构。可视化内容包括：\n",
    "- **节点**：从文本中提取的实体（概念、技术、人物）\n",
    "- **边**：实体之间的关系和连接\n",
    "- **聚类**：按语义相似性分组的相关概念\n",
    "\n",
    "在浏览器中打开生成的 HTML 文件，以交互方式探索图谱：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## 🧠 用 Memify 丰富记忆\n",
    "\n",
    "`memify()` 函数会分析知识图谱并生成关于数据的智能规则。这个过程：\n",
    "- 识别模式和最佳实践\n",
    "- 根据内容创建可操作的指导方针\n",
    "- 建立不同知识领域之间的关系\n",
    "\n",
    "这些规则帮助代理在回答问题时做出更明智的决策。捕获第二个可视化可以帮助您比较图谱在丰富后如何变得更加密集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## 🔍 第2部分：智能记忆检索\n",
    "\n",
    "### 示例 1：跨文档知识整合\n",
    "\n",
    "现在我们的知识图谱已经构建完成，让我们测试一下Cognee如何结合多个来源的信息来回答复杂问题。\n",
    "\n",
    "第一个查询展示了：\n",
    "- **语义理解**：即使未明确提及，也能找到相关概念\n",
    "- **交叉引用**：结合开发者档案与Python原则\n",
    "- **上下文推理**：将最佳实践应用于具体实现\n",
    "\n",
    "### 示例 2：使用NodeSets进行筛选搜索\n",
    "\n",
    "第二个查询展示了如何针对知识图谱的特定子集进行搜索：\n",
    "- 使用`node_name`参数仅在`principles_data`中搜索\n",
    "- 从特定知识领域提供集中答案\n",
    "- 当需要领域特定信息时非常有用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## 🔐 第三部分：会话管理设置\n",
    "\n",
    "### 启用对话记忆\n",
    "\n",
    "会话管理对于在多次交互中保持上下文至关重要。在这里我们将：\n",
    "\n",
    "1. **初始化用户上下文**：创建或检索用户档案以进行会话跟踪\n",
    "2. **配置缓存引擎**：连接到 Redis 以存储对话历史记录\n",
    "3. **启用会话变量**：设置在查询之间持久化的上下文变量\n",
    "\n",
    "> ⚠️ **重要**：这需要 Redis 正在运行，并且环境中设置了 `CACHING=true`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## 🛠️ 辅助函数：查看会话历史\n",
    "\n",
    "此工具函数允许我们检查存储在 Redis 中的会话历史记录。它的用途包括：\n",
    "- 调试会话管理\n",
    "- 验证对话是否被缓存\n",
    "- 了解代理可用的上下文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## 第1节：异步支持实验室——第一个问题\n",
    "\n",
    "开始 `async-support-lab` 课程，询问适用于大规模网页抓取的支持遥测的 asyncio 模式。图谱已经了解 asyncio、aiohttp 和监控实践，因此回答应反映之前的讨论，同时针对新问题进行调整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## 检查会话 1 在第一次交互后的内存\n",
    "\n",
    "在初始问题后立即运行 `show_history(session_1)` 可以确认 Cognee 已将提示和完成内容都写入了 Redis。你应该会看到一个包含并发指导的条目。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## 第1节：数据模型的后续讨论\n",
    "\n",
    "接下来我们问：“什么时候应该选择 dataclasses 而不是 Pydantic？”使用相同的会话 ID。Cognee 应该结合 Python 原则以及之前关于 FastAPI 的讨论，提供细致的建议——展示在命名会话中上下文是可以延续的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## 确认会话 1 的历史记录包含两个回合\n",
    "\n",
    "再次调用 `show_history(session_1)` 应该会显示两个问答条目。这与 Mem0 实验室的“记忆重播”步骤相符，并证明了额外的回合会扩展相同的对话记录。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## 第2节：设计评审线程 — 新会话\n",
    "\n",
    "为了展示线程之间的隔离，我们启动了 `design-review-session`，并请求关于事件评审的日志指导。尽管底层知识库是相同的，但新的会话 ID 会将记录分开。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## 审查会话 2 历史记录\n",
    "\n",
    "`show_history(session_2)` 应仅列出设计审查的提示/响应对。将其与会话 1 进行比较，以突出显示 Cognee 如何在重用共享知识图的同时保持独立的记录。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "恭喜你！你刚刚为你的编码助手添加了一个由 Cognee 提供支持的真正的长期记忆层。\n",
    "\n",
    "在本教程中，你将原始开发者内容（代码、文档、聊天记录）转化为一个图形 + 向量记忆，使你的代理能够进行搜索、推理并不断改进。\n",
    "\n",
    "你学到了什么\n",
    "\n",
    "1. **从原始文本到 AI 记忆**：了解 Cognee 如何摄取非结构化数据，并通过结合向量 + 知识图谱架构将其转化为智能、可搜索的记忆。\n",
    "\n",
    "2. **通过 memify 丰富图谱**：学习如何超越基本的图谱创建，使用 memify 在现有图谱之上添加推导出的事实和更丰富的关系。\n",
    "\n",
    "3. **多种搜索策略**：学习如何根据代理的需求，使用不同的搜索类型（图感知问答、RAG 风格补全、洞察、原始片段、代码搜索等）查询记忆。\n",
    "\n",
    "4. **可视化探索**：学习如何使用图形可视化和 Cognee UI 检查和调试 Cognee 构建的内容，从而直观地了解知识的结构。\n",
    "\n",
    "5. **会话感知记忆**：学习如何将每次会话的上下文与持久的语义记忆结合起来，使代理能够在多次运行中记住内容，同时避免在用户之间泄露信息。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## 关键要点\n",
    "1. 基于嵌入的知识图谱记忆\n",
    "\n",
    "    - **结构化理解**：Cognee结合了向量存储和图存储，使您的数据既可以通过语义搜索，也可以通过关系连接进行检索。Cognee默认使用基于文件的数据库（LanceDB用于向量存储，Kuzu用于图数据库）。\n",
    "\n",
    "    - **关系感知检索**：答案不仅可以基于“相似文本”，还可以基于实体之间的关系。\n",
    "\n",
    "    - **动态记忆**：记忆层不断演变、增长，并作为一个连接的图谱保持可查询。\n",
    "\n",
    "2. 搜索与推理模式\n",
    "    - **混合检索**：搜索结合了向量相似性、图结构和LLM推理，从原始块查找到基于图的问答。\n",
    "\n",
    "    - **根据任务选择模式**：当需要自然语言答案时使用补全模式；当代理需要原始上下文或驱动自身推理时使用块/摘要/图模式。\n",
    "\n",
    "3. 个性化、会话感知的代理\n",
    "    - **会话上下文 + 长期记忆**：Cognee将短期“线程”上下文与长期用户或组织级记忆分开。\n",
    "\n",
    "## 实际应用\n",
    "\n",
    "1. **垂直领域AI代理**\n",
    "\n",
    "    使用此笔记本中的模式，为基于Cognee的检索和推理核心的领域智能助手提供支持：\n",
    "\n",
    "- **开发者助手**：代码审查、事件分析和架构助手，能够遍历代码、API、设计文档和工单，作为一个单一的记忆图谱。\n",
    "\n",
    "- **面向客户的助手**：支持或成功代理，从产品文档、常见问题解答、CRM笔记和过去的工单中提取信息，进行基于图的检索并提供引用答案。\n",
    "\n",
    "- **内部专家助手**：政策、法律或安全助手，能够基于互相关联的规则、指南和历史决策进行推理，而不是孤立的PDF。\n",
    "\n",
    "    Cognee明确定位为AI代理的持久、准确记忆，提供一个动态知识图谱，作为代理的后端，取代临时组合的向量存储和自定义图代码。\n",
    "\n",
    "2. **将数据孤岛统一为一个记忆层**\n",
    "\n",
    "    同样的方法也可以帮助您在分散的来源之间构建统一的记忆层：\n",
    "\n",
    "- **从孤岛到一个图谱**：将结构化数据（如数据库）和非结构化数据（如文档、聊天记录）导入一个由嵌入支持的单一图谱，而不是为每个系统创建单独的索引。\n",
    "\n",
    "- **带引用的跨来源推理**：在所有数据上运行多步推理——通过图谱“连接”日志、指标和文档——并仍然返回有出处的答案。\n",
    "\n",
    "- **知识中心**：在银行或教育等领域，Cognee已经用于将PDF、内部系统和应用数据统一为一个带向量的知识图谱，使代理能够以精确、引用的上下文回答问题。\n",
    "\n",
    "## 下一步\n",
    "\n",
    "您已经实现了核心记忆循环。以下是您可以自行尝试的自然扩展（详见 [Cognee文档](https://docs.cognee.ai/)）：\n",
    "\n",
    "1. **尝试时间感知**：开启时间认知功能，从文本中提取事件和时间戳。\n",
    "\n",
    "2. **引入基于本体的推理**：为您的领域定义一个OWL本体。使用Cognee的本体支持，使提取的实体和关系基于该架构，从而提高图谱质量和领域特定答案。\n",
    "\n",
    "3. **添加反馈循环**：让Cognee根据真实用户反馈调整图边权重，使检索随着时间的推移不断改进，而不是保持静态。\n",
    "\n",
    "4. **优化个性化和会话行为**：使用用户ID、租户和数据集，为每个人或团队提供共享记忆引擎的专属视图。\n",
    "\n",
    "5. **扩展到更复杂的代理**：将Cognee接入代理框架，构建共享同一记忆层的多代理系统。*Microsoft Agent Framework x Cognee插件即将推出。*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**免责声明**：  \n本文档使用AI翻译服务[Co-op Translator](https://github.com/Azure/co-op-translator)进行翻译。尽管我们努力确保翻译的准确性，但请注意，自动翻译可能包含错误或不准确之处。原始语言的文档应被视为权威来源。对于关键信息，建议使用专业人工翻译。我们不对因使用此翻译而产生的任何误解或误读承担责任。\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:25:47+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "zh"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}