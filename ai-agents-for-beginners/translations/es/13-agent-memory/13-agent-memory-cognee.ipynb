{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Construyendo Agentes de IA con Memoria Persistente usando Cognee\n",
    "\n",
    "Este cuaderno demuestra c√≥mo construir agentes de IA inteligentes con capacidades avanzadas de memoria utilizando [**cognee**](https://www.cognee.ai/) - una memoria de IA de c√≥digo abierto que combina gr√°ficos de conocimiento, b√∫squeda sem√°ntica y gesti√≥n de sesiones para crear sistemas de IA conscientes del contexto.\n",
    "\n",
    "## üéØ Objetivos de Aprendizaje\n",
    "\n",
    "Al final de este tutorial, comprender√°s c√≥mo:\n",
    "- **Construir Gr√°ficos de Conocimiento Respaldados por Embeddings**: Transformar texto no estructurado en conocimiento estructurado y consultable\n",
    "- **Implementar Memoria de Sesi√≥n**: Crear conversaciones de m√∫ltiples turnos con retenci√≥n autom√°tica de contexto\n",
    "- **Persistir Conversaciones**: Almacenar opcionalmente interacciones importantes en memoria a largo plazo para referencia futura\n",
    "- **Consultar Usando Lenguaje Natural**: Acceder y aprovechar el contexto hist√≥rico en nuevas conversaciones\n",
    "- **Visualizar Memoria**: Explorar las relaciones en el gr√°fico de conocimiento de tu agente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Lo que Construir√°s\n",
    "\n",
    "En este tutorial, crearemos un **Asistente de Programaci√≥n** con memoria persistente que:\n",
    "\n",
    "### 1. **Construcci√≥n de una Base de Conocimientos**\n",
    "   - Ingiera informaci√≥n del perfil y experiencia del desarrollador\n",
    "   - Procese principios y mejores pr√°cticas de programaci√≥n en Python\n",
    "   - Almacene conversaciones hist√≥ricas entre desarrolladores y asistentes de IA\n",
    "\n",
    "### 2. **Conversaciones Conscientes de la Sesi√≥n**\n",
    "   - Mantenga el contexto a lo largo de m√∫ltiples preguntas en la misma sesi√≥n\n",
    "   - Almacene autom√°ticamente cada par de pregunta/respuesta para una recuperaci√≥n eficiente\n",
    "   - Proporcione respuestas coherentes y contextuales basadas en el historial de la conversaci√≥n\n",
    "\n",
    "### 3. **Memoria a Largo Plazo**\n",
    "   - Persista conversaciones importantes en una memoria a largo plazo\n",
    "   - Recupere recuerdos relevantes de la base de conocimientos y sesiones pasadas para informar nuevas interacciones\n",
    "   - Construya una base de conocimientos en crecimiento que mejore con el tiempo\n",
    "\n",
    "### 4. **Recuperaci√≥n Inteligente de Memoria**\n",
    "   - Utilice b√∫squeda sem√°ntica basada en grafos para encontrar informaci√≥n relevante en todo el conocimiento almacenado\n",
    "   - Filtre b√∫squedas por subgrupos de datos (informaci√≥n del desarrollador vs. principios)\n",
    "   - Combine m√∫ltiples fuentes de datos para proporcionar respuestas completas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Requisitos previos y configuraci√≥n\n",
    "\n",
    "### Requisitos del sistema\n",
    "\n",
    "Antes de comenzar, aseg√∫rate de tener:\n",
    "\n",
    "1. **Entorno de Python**\n",
    "   - Python 3.9 o superior\n",
    "   - Entorno virtual (recomendado)\n",
    "   \n",
    "2. **Cache de Redis** (Requerido para la gesti√≥n de sesiones)\n",
    "   - Redis local: `docker run -d -p 6379:6379 redis`\n",
    "   - O utiliza un servicio gestionado de Redis\n",
    "   \n",
    "3. **Acceso a la API de LLM**\n",
    "   - Clave de API de OpenAI u otros proveedores (consulta la [documentaci√≥n](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Configuraci√≥n de la base de datos**\n",
    "   - No se requiere configuraci√≥n por defecto. Cognee utiliza bases de datos basadas en archivos (LanceDB y Kuzu)\n",
    "   - Opcionalmente, puedes configurar Azure AI Search como un almac√©n vectorial (consulta la [documentaci√≥n](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Configuraci√≥n del entorno\n",
    "\n",
    "Crea un archivo `.env` en el directorio de tu proyecto con las siguientes variables:\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Comprendiendo la Arquitectura de Memoria de Cognee\n",
    "\n",
    "### C√≥mo Funciona Cognee\n",
    "\n",
    "Cognee ofrece un sistema de memoria sofisticado que va m√°s all√° del simple almacenamiento de clave-valor:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Componentes Clave:\n",
    "\n",
    "1. **Grafo de Conocimiento**: Almacena entidades, relaciones y conexiones sem√°nticas\n",
    "2. **Embeddings Vectoriales**: Permite la b√∫squeda sem√°ntica en toda la informaci√≥n almacenada\n",
    "3. **Cach√© de Sesi√≥n**: Mantiene el contexto de la conversaci√≥n dentro y entre sesiones\n",
    "4. **NodeSets**: Organiza los datos en categor√≠as l√≥gicas para una recuperaci√≥n espec√≠fica\n",
    "\n",
    "### Tipos de Memoria en Este Tutorial:\n",
    "\n",
    "- **Memoria Persistente**: Almacenamiento a largo plazo en el grafo de conocimiento\n",
    "- **Memoria de Sesi√≥n**: Contexto temporal de la conversaci√≥n en la cach√© de Redis\n",
    "- **Memoria Sem√°ntica**: B√∫squeda basada en similitud vectorial en todos los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Instalar paquetes requeridos\n",
    "\n",
    "Instala Cognee con soporte de Redis para la gesti√≥n de sesiones:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß Inicializar el Entorno y Cargar Bibliotecas\n",
    "\n",
    "Aseg√∫rate de que:\n",
    "1. Redis est√© en funcionamiento (por ejemplo, usando Docker: `docker run -d -p 6379:6379 redis`)\n",
    "2. Las variables de entorno est√©n configuradas antes de importar los m√≥dulos de cach√©\n",
    "3. Si es necesario, reinicia el kernel y ejecuta las celdas en orden\n",
    "\n",
    "La siguiente celda har√° lo siguiente:\n",
    "1. Cargar las variables de entorno desde `.env`\n",
    "2. Configurar Cognee con tus ajustes de LLM\n",
    "3. Habilitar la cach√© para la gesti√≥n de sesiones\n",
    "4. Validar que todos los componentes est√©n correctamente conectados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ Configurar Directorios de Almacenamiento\n",
    "\n",
    "Cognee utiliza dos directorios separados para sus operaciones:\n",
    "- **Ra√≠z de Datos**: Almacena documentos ingeridos y datos procesados\n",
    "- **Ra√≠z del Sistema**: Contiene la base de datos del grafo de conocimiento y los metadatos del sistema\n",
    "\n",
    "Crearemos directorios aislados para este tutorial de la siguiente manera:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ Restablecer el Estado de la Memoria\n",
    "\n",
    "Antes de comenzar a construir nuestro sistema de memoria, asegur√©monos de empezar desde cero.\n",
    "\n",
    "> üí° **Consejo**: Puedes omitir este paso si deseas conservar los recuerdos existentes de ejecuciones anteriores cuando uses este cuaderno m√°s adelante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Parte 1: Construyendo la Base de Conocimiento\n",
    "\n",
    "### Fuentes de Datos para Nuestro Asistente de Desarrolladores\n",
    "\n",
    "Incorporaremos tres tipos de datos para crear una base de conocimiento integral:\n",
    "\n",
    "1. **Perfil del Desarrollador**: Experiencia personal y antecedentes t√©cnicos\n",
    "2. **Mejores Pr√°cticas de Python**: El Zen de Python con pautas pr√°cticas\n",
    "3. **Conversaciones Hist√≥ricas**: Sesiones de preguntas y respuestas pasadas entre desarrolladores y asistentes de IA\n",
    "\n",
    "Estos datos diversos permiten que nuestro agente:\n",
    "- Comprenda el contexto t√©cnico del usuario\n",
    "- Aplique mejores pr√°cticas en sus recomendaciones\n",
    "- Aprenda de interacciones exitosas anteriores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Procesar Datos en un Grafo de Conocimiento\n",
    "\n",
    "Ahora transformaremos nuestro texto sin procesar en una memoria estructurada. Este proceso:\n",
    "\n",
    "1. **Agrega datos a NodeSets**: Organiza la informaci√≥n en categor√≠as l√≥gicas\n",
    "   - `developer_data`: Perfil del desarrollador y conversaciones\n",
    "   - `principles_data`: Mejores pr√°cticas y directrices de Python\n",
    "\n",
    "2. **Ejecuta el Pipeline Cognify**: Extrae entidades, relaciones y crea embeddings\n",
    "   - Identifica conceptos clave\n",
    "   - Crea conexiones sem√°nticas entre informaci√≥n relacionada\n",
    "   - Genera embeddings vectoriales\n",
    "\n",
    "Esto puede tomar unos momentos mientras el LLM procesa el texto y construye la estructura del grafo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä Visualizar el Grafo de Conocimiento\n",
    "\n",
    "Vamos a explorar la estructura de nuestro grafo de conocimiento. La visualizaci√≥n muestra:\n",
    "- **Nodos**: Entidades extra√≠das del texto (conceptos, tecnolog√≠as, personas)\n",
    "- **Aristas**: Relaciones y conexiones entre las entidades\n",
    "- **Cl√∫steres**: Conceptos relacionados agrupados por similitud sem√°ntica\n",
    "\n",
    "Abre el archivo HTML generado en tu navegador para explorar el grafo de manera interactiva:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Enriquecer la Memoria con Memify\n",
    "\n",
    "La funci√≥n `memify()` analiza el grafo de conocimiento y genera reglas inteligentes sobre los datos. Este proceso:\n",
    "- Identifica patrones y mejores pr√°cticas\n",
    "- Crea pautas accionables basadas en el contenido\n",
    "- Establece relaciones entre diferentes √°reas de conocimiento\n",
    "\n",
    "Estas reglas ayudan al agente a tomar decisiones m√°s informadas al responder preguntas. Capturar una segunda visualizaci√≥n te permite comparar c√≥mo se densifica el grafo una vez enriquecido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Parte 2: Recuperaci√≥n Inteligente de Memoria\n",
    "\n",
    "### Demostraci√≥n 1: Integraci√≥n de Conocimientos entre Documentos\n",
    "\n",
    "Ahora que nuestro grafo de conocimiento est√° construido, probemos c√≥mo Cognee combina informaci√≥n de m√∫ltiples fuentes para responder preguntas complejas.\n",
    "\n",
    "La primera consulta demuestra:\n",
    "- **Comprensi√≥n sem√°ntica**: Encontrar conceptos relevantes incluso cuando no se mencionan expl√≠citamente\n",
    "- **Referencia cruzada**: Combinar el perfil del desarrollador con principios de Python\n",
    "- **Razonamiento contextual**: Aplicar mejores pr√°cticas a implementaciones espec√≠ficas\n",
    "\n",
    "### Demostraci√≥n 2: B√∫squeda Filtrada con NodeSets\n",
    "\n",
    "La segunda consulta muestra c√≥mo dirigirnos a subconjuntos espec√≠ficos del grafo de conocimiento:\n",
    "- Utiliza el par√°metro `node_name` para buscar solo dentro de `principles_data`\n",
    "- Proporciona respuestas enfocadas de un dominio de conocimiento espec√≠fico\n",
    "- √ötil cuando necesitas informaci√≥n espec√≠fica de un dominio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Parte 3: Configuraci√≥n de Gesti√≥n de Sesiones\n",
    "\n",
    "### Habilitar Memoria de Conversaci√≥n\n",
    "\n",
    "La gesti√≥n de sesiones es crucial para mantener el contexto a lo largo de m√∫ltiples interacciones. Aqu√≠ haremos lo siguiente:\n",
    "\n",
    "1. **Inicializar el Contexto del Usuario**: Crear o recuperar un perfil de usuario para el seguimiento de la sesi√≥n.\n",
    "2. **Configurar el Motor de Cach√©**: Conectar a Redis para almacenar el historial de conversaciones.\n",
    "3. **Habilitar Variables de Sesi√≥n**: Configurar variables de contexto que persistan entre consultas.\n",
    "\n",
    "> ‚ö†Ô∏è **Importante**: Esto requiere que Redis est√© en funcionamiento y que `CACHING=true` est√© configurado en tu entorno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Funci√≥n de Ayuda: Ver Historial de Sesi√≥n\n",
    "\n",
    "Esta funci√≥n de utilidad nos permite inspeccionar el historial de conversaciones almacenado en Redis. Es √∫til para:\n",
    "- Depurar la gesti√≥n de sesiones\n",
    "- Verificar que las conversaciones se est√°n almacenando en cach√©\n",
    "- Comprender qu√© contexto est√° disponible para el agente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Sesi√≥n 1: Laboratorio de soporte as√≠ncrono ‚Äî Primera pregunta\n",
    "\n",
    "Inicia la sesi√≥n `async-support-lab` preguntando por patrones de asyncio compatibles con telemetr√≠a para un scraper web masivo. El gr√°fico ya tiene conocimiento sobre asyncio, aiohttp y pr√°cticas de monitoreo, por lo que la respuesta deber√≠a reflejar conversaciones previas mientras adapta la respuesta a la nueva consulta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Inspeccionar la Memoria de la Sesi√≥n 1 Despu√©s del Primer Intercambio\n",
    "\n",
    "Ejecutar `show_history(session_1)` inmediatamente despu√©s de la pregunta inicial confirma que Cognee escribi√≥ tanto el mensaje inicial como la respuesta en Redis. Deber√≠as ver una entrada con la gu√≠a de concurrencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Sesi√≥n 1: Seguimiento de Modelos de Datos\n",
    "\n",
    "A continuaci√≥n, preguntamos: \"¬øCu√°ndo deber√≠a elegir dataclasses en lugar de Pydantic?\" utilizando el mismo id de sesi√≥n. Cognee deber√≠a combinar los principios de Python junto con conversaciones previas sobre FastAPI para ofrecer un consejo matizado, demostrando que el contexto se mantiene dentro de una sesi√≥n nombrada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Confirmar que el Historial de la Sesi√≥n 1 Contiene Ambos Turnos\n",
    "\n",
    "Otra llamada a `show_history(session_1)` deber√≠a mostrar dos entradas de preguntas y respuestas. Esto coincide con el paso de \"reproducci√≥n de memoria\" del laboratorio Mem0 y demuestra que los turnos adicionales ampl√≠an la misma transcripci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Sesi√≥n 2: Hilo de Revisi√≥n de Dise√±o ‚Äî Sesi√≥n Nueva\n",
    "\n",
    "Para mostrar aislamiento entre hilos, iniciamos `design-review-session` y pedimos orientaci√≥n sobre el registro para revisiones de incidentes. Aunque la base de conocimiento subyacente es la misma, el nuevo id de sesi√≥n mantiene las transcripciones separadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## Revisi√≥n de la Sesi√≥n 2 Historia\n",
    "\n",
    "`show_history(session_2)` deber√≠a listar √∫nicamente el par de solicitud/respuesta de revisi√≥n de dise√±o. Comp√°ralo con la Sesi√≥n 1 para destacar c√≥mo Cognee mantiene transcripciones independientes mientras reutiliza el gr√°fico de conocimiento compartido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "¬°Felicidades! Acabas de darle a tu asistente de codificaci√≥n una capa de memoria a largo plazo impulsada por Cognee.\n",
    "\n",
    "En este tutorial, tomaste contenido de desarrollador en bruto (c√≥digo, documentos, chats) y lo transformaste en un grafo + memoria vectorial que tu agente puede buscar, razonar y mejorar continuamente.\n",
    "\n",
    "Lo que has aprendido\n",
    "\n",
    "1. **De texto en bruto a memoria de IA**: C√≥mo Cognee ingiere datos no estructurados y los convierte en una memoria inteligente y buscable utilizando una arquitectura combinada de vector + grafo de conocimiento.\n",
    "\n",
    "2. **Enriquecimiento del grafo con memify**: C√≥mo ir m√°s all√° de la creaci√≥n b√°sica de grafos y usar memify para agregar hechos derivados y relaciones m√°s ricas sobre tu grafo existente.\n",
    "\n",
    "3. **M√∫ltiples estrategias de b√∫squeda**: C√≥mo consultar la memoria con diferentes tipos de b√∫squeda (preguntas y respuestas conscientes del grafo, completado estilo RAG, insights, fragmentos en bruto, b√∫squeda de c√≥digo, etc.) dependiendo de lo que necesite tu agente.\n",
    "\n",
    "4. **Exploraci√≥n visual**: C√≥mo inspeccionar y depurar lo que Cognee construy√≥ utilizando visualizaciones de grafos y la interfaz de usuario de Cognee, para que realmente puedas ver c√≥mo est√° estructurado el conocimiento.\n",
    "\n",
    "5. **Memoria consciente de la sesi√≥n**: C√≥mo combinar el contexto por sesi√≥n con la memoria sem√°ntica persistente para que los agentes puedan recordar entre ejecuciones sin filtrar informaci√≥n entre usuarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Puntos Clave\n",
    "1. Memoria como un Grafo de Conocimiento respaldado por Embeddings\n",
    "\n",
    "    - **Comprensi√≥n estructurada**: Cognee combina un almac√©n vectorial y un almac√©n de grafos para que tus datos sean tanto buscables por significado como conectados por relaciones. Cognee utiliza bases de datos basadas en archivos por defecto (LanceDB para vectores, Kuzu para bases de datos de grafos).\n",
    "\n",
    "    - **Recuperaci√≥n consciente de relaciones**: Las respuestas pueden estar fundamentadas no solo en \"texto similar\", sino tambi√©n en c√≥mo se relacionan las entidades.\n",
    "\n",
    "    - **Memoria viva**: La capa de memoria evoluciona, crece y permanece consultable como un grafo conectado.\n",
    "\n",
    "2. Modos de B√∫squeda y Razonamiento\n",
    "    - **Recuperaci√≥n h√≠brida**: La b√∫squeda combina similitud vectorial, estructura de grafos y razonamiento de LLM, desde la b√∫squeda de fragmentos hasta respuestas a preguntas conscientes del grafo.\n",
    "\n",
    "    - **Ajusta el modo al trabajo**: Usa modos de estilo de completado cuando necesites respuestas en lenguaje natural, y modos de fragmento/resumen/grafo cuando tu agente necesite contexto bruto o impulsar su propio razonamiento.\n",
    "\n",
    "3. Agentes Personalizados y Conscientes de la Sesi√≥n\n",
    "    - **Contexto de sesi√≥n + memoria a largo plazo**: Cognee mantiene el contexto de \"hilo\" a corto plazo separado de la memoria duradera a nivel de usuario u organizaci√≥n.\n",
    "\n",
    "## Aplicaciones en el Mundo Real\n",
    "\n",
    "1. **Agentes Verticales de IA**\n",
    "\n",
    "    Usa el patr√≥n de este cuaderno para potenciar copilotos inteligentes en dominios que se basen en Cognee como su n√∫cleo de recuperaci√≥n y razonamiento:\n",
    "\n",
    "- **Copilotos para desarrolladores**: Asistentes de revisi√≥n de c√≥digo, an√°lisis de incidentes y arquitectura que recorren c√≥digo, APIs, documentos de dise√±o y tickets como un √∫nico grafo de memoria.\n",
    "\n",
    "- **Copilotos orientados al cliente**: Agentes de soporte o √©xito que extraen informaci√≥n de documentos de productos, preguntas frecuentes, notas de CRM y tickets anteriores con recuperaci√≥n consciente del grafo y respuestas citadas.\n",
    "\n",
    "- **Copilotos expertos internos**: Asistentes de pol√≠ticas, legales o de seguridad que razonan sobre reglas interconectadas, gu√≠as y decisiones hist√≥ricas en lugar de PDFs aislados.\n",
    "\n",
    "    Cognee est√° expl√≠citamente posicionado como memoria persistente y precisa para agentes de IA, proporcionando un grafo de conocimiento vivo que se integra detr√°s de tu agente y reemplaza combinaciones ad-hoc de almacenes vectoriales y c√≥digo de grafos personalizado.\n",
    "\n",
    "2. **Unificar Silos de Datos en Una Memoria**\n",
    "\n",
    "    El mismo enfoque tambi√©n te ayuda a construir una capa de memoria unificada a partir de fuentes dispersas:\n",
    "\n",
    "- **De silos a un grafo √∫nico**: Ingresa datos estructurados (por ejemplo, bases de datos) y no estructurados (por ejemplo, documentos, chats) en un √∫nico grafo respaldado por embeddings, en lugar de √≠ndices separados para cada sistema.\n",
    "\n",
    "- **Razonamiento entre fuentes con citas**: Realiza razonamientos de m√∫ltiples pasos sobre todo‚Äî\"une\" registros, m√©tricas y documentos a trav√©s del grafo‚Äîy a√∫n devuelve respuestas fundamentadas con procedencia.\n",
    "\n",
    "- **Centros de conocimiento**: Para dominios como banca o educaci√≥n, Cognee ya se utiliza para unificar PDFs, sistemas internos y datos de aplicaciones en un grafo de conocimiento con vectores para que los agentes puedan responder preguntas con contexto preciso y citado.\n",
    "\n",
    "## Pr√≥ximos Pasos\n",
    "\n",
    "Has implementado el bucle de memoria principal. Aqu√≠ hay extensiones naturales que puedes probar por tu cuenta (consulta la [documentaci√≥n de Cognee](https://docs.cognee.ai/) para m√°s detalles):\n",
    "\n",
    "1. **Experimenta con conciencia temporal**: Activa la cognificaci√≥n temporal para extraer eventos y marcas de tiempo del texto.\n",
    "\n",
    "2. **Introduce razonamiento basado en ontolog√≠as**: Define una ontolog√≠a OWL para tu dominio. Usa el soporte de ontolog√≠as de Cognee para que las entidades y relaciones extra√≠das est√©n fundamentadas en ese esquema, mejorando la calidad del grafo y las respuestas espec√≠ficas del dominio.\n",
    "\n",
    "3. **A√±ade un bucle de retroalimentaci√≥n**: Permite que Cognee ajuste los pesos de los bordes del grafo a partir de la retroalimentaci√≥n real de los usuarios, para que la recuperaci√≥n mejore con el tiempo en lugar de permanecer est√°tica.\n",
    "\n",
    "4. **Optimiza para personalizaci√≥n y comportamiento de sesi√≥n**: Usa IDs de usuario, inquilinos y conjuntos de datos para dar a cada persona o equipo su propia vista sobre el motor de memoria compartido.\n",
    "\n",
    "5. **Escala hacia agentes m√°s complejos**: Conecta Cognee a marcos de agentes para construir sistemas multi-agente que compartan la misma capa de memoria. *El plugin Microsoft Agent Framework x Cognee estar√° disponible pronto.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Descargo de responsabilidad**:  \nEste documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que surjan del uso de esta traducci√≥n.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:15:24+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "es"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}