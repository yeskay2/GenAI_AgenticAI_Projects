{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Membina Ejen AI dengan Memori Berterusan menggunakan Cognee\n",
    "\n",
    "Notebook ini menunjukkan cara membina ejen AI pintar dengan keupayaan memori yang canggih menggunakan [**cognee**](https://www.cognee.ai/) - memori AI sumber terbuka yang menggabungkan graf pengetahuan, carian semantik, dan pengurusan sesi untuk mencipta sistem AI yang sedar konteks.\n",
    "\n",
    "## üéØ Objektif Pembelajaran\n",
    "\n",
    "Pada akhir tutorial ini, anda akan memahami cara untuk:\n",
    "- **Membina Graf Pengetahuan Disokong oleh Embedding**: Menukar teks tidak berstruktur kepada pengetahuan yang berstruktur dan boleh ditanya\n",
    "- **Melaksanakan Memori Sesi**: Mewujudkan perbualan berbilang giliran dengan pengekalan konteks secara automatik\n",
    "- **Menyimpan Perbualan**: Secara opsional menyimpan interaksi penting dalam memori jangka panjang untuk rujukan masa depan\n",
    "- **Bertanya Menggunakan Bahasa Semula Jadi**: Mengakses dan memanfaatkan konteks sejarah dalam perbualan baru\n",
    "- **Visualisasi Memori**: Meneroka hubungan dalam graf pengetahuan ejen anda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Apa Yang Akan Anda Bina\n",
    "\n",
    "Dalam tutorial ini, kita akan mencipta **Pembantu Pengaturcaraan** dengan memori berterusan yang:\n",
    "\n",
    "### 1. **Pembinaan Pangkalan Pengetahuan**\n",
    "   - Mengambil maklumat profil dan kepakaran pembangun\n",
    "   - Memproses prinsip dan amalan terbaik pengaturcaraan Python\n",
    "   - Menyimpan perbualan sejarah antara pembangun dan pembantu AI\n",
    "\n",
    "### 2. **Perbualan Sedar Sesi**\n",
    "   - Mengekalkan konteks merentasi pelbagai soalan dalam sesi yang sama\n",
    "   - Secara automatik menyimpan setiap pasangan soalan/jawapan untuk pengambilan yang cekap\n",
    "   - Memberikan respons yang koheren dan berkonteks berdasarkan sejarah perbualan\n",
    "\n",
    "### 3. **Memori Jangka Panjang**\n",
    "   - Menyimpan perbualan penting ke dalam memori jangka panjang\n",
    "   - Mengambil memori yang relevan dari pangkalan pengetahuan dan sesi lalu untuk memaklumkan interaksi baru\n",
    "   - Membina pangkalan pengetahuan yang berkembang dan bertambah baik dari masa ke masa\n",
    "\n",
    "### 4. **Pengambilan Memori Pintar**\n",
    "   - Menggunakan carian semantik yang sedar graf untuk mencari maklumat yang relevan di seluruh pengetahuan yang disimpan\n",
    "   - Menapis carian mengikut subkumpulan data (maklumat pembangun vs. prinsip)\n",
    "   - Menggabungkan pelbagai sumber data untuk memberikan jawapan yang komprehensif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Prasyarat & Persediaan\n",
    "\n",
    "### Keperluan Sistem\n",
    "\n",
    "Sebelum memulakan, pastikan anda mempunyai:\n",
    "\n",
    "1. **Persekitaran Python**\n",
    "   - Python 3.9 atau lebih tinggi\n",
    "   - Persekitaran maya (disyorkan)\n",
    "   \n",
    "2. **Redis Cache** (Diperlukan untuk Pengurusan Sesi)\n",
    "   - Redis Tempatan: `docker run -d -p 6379:6379 redis`\n",
    "   - Atau gunakan perkhidmatan Redis yang diuruskan\n",
    "   \n",
    "3. **Akses API LLM**\n",
    "   - Kunci API OpenAI atau penyedia lain (lihat [dokumentasi](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Konfigurasi Pangkalan Data**\n",
    "   - Tiada konfigurasi diperlukan secara lalai. Cognee menggunakan pangkalan data berasaskan fail (LanceDB dan Kuzu)\n",
    "   - Secara opsyenal, anda boleh menyediakan Azure AI Search sebagai stor vektor (lihat [dokumentasi](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Konfigurasi Persekitaran\n",
    "\n",
    "Cipta fail `.env` dalam direktori projek anda dengan pembolehubah berikut:\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Memahami Seni Bina Memori Cognee\n",
    "\n",
    "### Bagaimana Cognee Berfungsi\n",
    "\n",
    "Cognee menyediakan sistem memori yang canggih yang melangkaui penyimpanan kunci-nilai yang mudah:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Komponen Utama:\n",
    "\n",
    "1. **Graf Pengetahuan**: Menyimpan entiti, hubungan, dan sambungan semantik\n",
    "2. **Vector Embeddings**: Membolehkan carian semantik merentasi semua maklumat yang disimpan\n",
    "3. **Cache Sesi**: Mengekalkan konteks perbualan dalam dan antara sesi\n",
    "4. **NodeSets**: Mengatur data ke dalam kategori logik untuk pengambilan yang disasarkan\n",
    "\n",
    "### Jenis Memori dalam Tutorial Ini:\n",
    "\n",
    "- **Memori Kekal**: Penyimpanan jangka panjang dalam graf pengetahuan\n",
    "- **Memori Sesi**: Konteks perbualan sementara dalam cache Redis\n",
    "- **Memori Semantik**: Carian kesamaan berasaskan vektor merentasi semua data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Pasang Pakej Diperlukan\n",
    "\n",
    "Pasang Cognee dengan sokongan Redis untuk pengurusan sesi:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß Memulakan Persekitaran dan Memuatkan Pustaka\n",
    "\n",
    "Pastikan:\n",
    "1. Redis sedang berjalan (contohnya, melalui Docker: `docker run -d -p 6379:6379 redis`)\n",
    "2. Pembolehubah persekitaran telah ditetapkan sebelum mengimport modul cache\n",
    "3. Jika perlu, mulakan semula kernel dan jalankan sel mengikut urutan\n",
    "\n",
    "Sel berikut akan:\n",
    "1. Memuatkan pembolehubah persekitaran dari `.env`\n",
    "2. Mengkonfigurasi Cognee dengan tetapan LLM anda\n",
    "3. Mengaktifkan cache untuk pengurusan sesi\n",
    "4. Mengesahkan semua komponen disambungkan dengan betul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ Konfigurasi Direktori Penyimpanan\n",
    "\n",
    "Cognee menggunakan dua direktori berasingan untuk operasinya:\n",
    "- **Data Root**: Menyimpan dokumen yang dimasukkan dan data yang telah diproses\n",
    "- **System Root**: Mengandungi pangkalan data graf pengetahuan dan metadata sistem\n",
    "\n",
    "Kita akan mencipta direktori yang terasing untuk tutorial ini seperti berikut:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ Tetapkan Semula Keadaan Memori\n",
    "\n",
    "Sebelum kita mula membina sistem memori kita, mari pastikan kita bermula dengan keadaan yang bersih.\n",
    "\n",
    "> üí° **Tip**: Anda boleh abaikan langkah ini jika anda ingin mengekalkan memori sedia ada daripada sesi sebelumnya apabila anda menggunakan buku nota ini nanti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Bahagian 1: Membina Pangkalan Pengetahuan\n",
    "\n",
    "### Sumber Data untuk Pembantu Pembangun Kita\n",
    "\n",
    "Kita akan menggunakan tiga jenis data untuk mencipta pangkalan pengetahuan yang komprehensif:\n",
    "\n",
    "1. **Profil Pembangun**: Kepakaran peribadi dan latar belakang teknikal\n",
    "2. **Amalan Terbaik Python**: Zen of Python dengan panduan praktikal\n",
    "3. **Perbualan Sejarah**: Sesi soal jawab terdahulu antara pembangun dan pembantu AI\n",
    "\n",
    "Data yang pelbagai ini membolehkan agen kita untuk:\n",
    "- Memahami konteks teknikal pengguna\n",
    "- Menerapkan amalan terbaik dalam cadangan\n",
    "- Belajar daripada interaksi berjaya yang lepas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Proses Data ke dalam Graf Pengetahuan\n",
    "\n",
    "Sekarang kita akan menukar teks mentah kita menjadi memori yang berstruktur. Proses ini:\n",
    "\n",
    "1. **Menambah data ke NodeSets**: Menyusun maklumat ke dalam kategori logik\n",
    "   - `developer_data`: Profil pembangun dan perbualan\n",
    "   - `principles_data`: Amalan terbaik dan panduan Python\n",
    "\n",
    "2. **Menjalankan Cognify Pipeline**: Mengekstrak entiti, hubungan, dan mencipta embedding\n",
    "   - Mengenal pasti konsep utama\n",
    "   - Mewujudkan sambungan semantik antara maklumat yang berkaitan\n",
    "   - Menjana embedding vektor\n",
    "\n",
    "Ini mungkin mengambil masa beberapa saat kerana LLM memproses teks dan membina struktur graf:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä Visualisasikan Graf Pengetahuan\n",
    "\n",
    "Mari kita terokai struktur graf pengetahuan kita. Visualisasi ini menunjukkan:\n",
    "- **Nod**: Entiti yang diekstrak daripada teks (konsep, teknologi, individu)\n",
    "- **Tepi**: Hubungan dan sambungan antara entiti\n",
    "- **Kumpulan**: Konsep berkaitan yang dikelompokkan berdasarkan kesamaan semantik\n",
    "\n",
    "Buka fail HTML yang dijana dalam pelayar anda untuk meneroka graf secara interaktif:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Perkayakan Memori dengan Memify\n",
    "\n",
    "Fungsi `memify()` menganalisis graf pengetahuan dan menghasilkan peraturan pintar tentang data. Proses ini:\n",
    "- Mengenal pasti corak dan amalan terbaik\n",
    "- Mencipta panduan yang boleh diambil tindakan berdasarkan kandungan\n",
    "- Menjalin hubungan antara pelbagai bidang pengetahuan\n",
    "\n",
    "Peraturan ini membantu agen membuat keputusan yang lebih bermaklumat semasa menjawab soalan. Menangkap visualisasi kedua membantu anda membandingkan bagaimana graf menjadi lebih padat setelah diperkayakan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Bahagian 2: Pengambilan Memori Pintar\n",
    "\n",
    "### Demonstrasi 1: Integrasi Pengetahuan Merentas Dokumen\n",
    "\n",
    "Sekarang bahawa graf pengetahuan kita telah dibina, mari kita uji bagaimana Cognee menggabungkan maklumat dari pelbagai sumber untuk menjawab soalan yang kompleks.\n",
    "\n",
    "Pertanyaan pertama menunjukkan:\n",
    "- **Pemahaman semantik**: Mencari konsep yang relevan walaupun tidak disebut secara eksplisit\n",
    "- **Rujukan silang**: Menggabungkan profil pembangun dengan prinsip Python\n",
    "- **Penaakulan kontekstual**: Menerapkan amalan terbaik kepada pelaksanaan tertentu\n",
    "\n",
    "### Demonstrasi 2: Carian Tapis dengan NodeSets\n",
    "\n",
    "Pertanyaan kedua menunjukkan cara menyasarkan subset tertentu dalam graf pengetahuan:\n",
    "- Menggunakan parameter `node_name` untuk mencari hanya dalam `principles_data`\n",
    "- Memberikan jawapan yang fokus dari domain pengetahuan tertentu\n",
    "- Berguna apabila anda memerlukan maklumat khusus domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Bahagian 3: Tetapan Pengurusan Sesi\n",
    "\n",
    "### Mengaktifkan Memori Perbualan\n",
    "\n",
    "Pengurusan sesi adalah penting untuk mengekalkan konteks sepanjang pelbagai interaksi. Di sini kita akan:\n",
    "\n",
    "1. **Inisialisasi Konteks Pengguna**: Cipta atau dapatkan profil pengguna untuk penjejakan sesi\n",
    "2. **Konfigurasi Enjin Cache**: Sambungkan ke Redis untuk menyimpan sejarah perbualan\n",
    "3. **Aktifkan Pembolehubah Sesi**: Tetapkan pembolehubah konteks yang kekal merentasi pertanyaan\n",
    "\n",
    "> ‚ö†Ô∏è **Penting**: Ini memerlukan Redis sedang berjalan dan `CACHING=true` dalam persekitaran anda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Fungsi Pembantu: Lihat Sejarah Sesi\n",
    "\n",
    "Fungsi utiliti ini membolehkan kita memeriksa sejarah perbualan yang disimpan dalam Redis. Ia berguna untuk:\n",
    "- Menyelesaikan masalah pengurusan sesi\n",
    "- Memastikan perbualan disimpan dalam cache\n",
    "- Memahami konteks yang tersedia untuk ejen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Sesi 1: Makmal Sokongan Async ‚Äî Soalan Pertama\n",
    "\n",
    "Mulakan sesi `async-support-lab` dengan bertanya tentang corak asyncio yang mesra telemetri untuk pengikis web berskala besar. Graf sudah mengetahui tentang asyncio, aiohttp, dan amalan pemantauan, jadi responsnya harus mencerminkan perbualan sebelumnya sambil menyesuaikan jawapan dengan pertanyaan baru.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Periksa Memori Sesi 1 Selepas Pertukaran Pertama\n",
    "\n",
    "Menjalankan `show_history(session_1)` sejurus selepas soalan awal mengesahkan bahawa Cognee telah menulis kedua-dua prompt dan jawapan ke dalam Redis. Anda sepatutnya melihat satu entri dengan panduan keserentakan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Sesi 1: Susulan mengenai Model Data\n",
    "\n",
    "Seterusnya kita tanya, \"Bila saya patut memilih dataclasses berbanding Pydantic?\" menggunakan ID sesi yang sama. Cognee sepatutnya menggabungkan prinsip Python bersama perbincangan FastAPI sebelum ini untuk memberikan nasihat yang lebih terperinci‚Äîmenunjukkan bahawa konteks dibawa ke hadapan dalam sesi yang dinamakan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Sahkan Sejarah Sesi 1 Mengandungi Kedua-dua Giliran\n",
    "\n",
    "Panggilan `show_history(session_1)` yang lain sepatutnya menunjukkan dua entri Soal & Jawab. Ini sepadan dengan langkah \"ulang ingatan\" dalam makmal Mem0 dan membuktikan bahawa giliran tambahan melanjutkan transkrip yang sama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Sesi 2: Benang Semakan Reka Bentuk ‚Äî Sesi Baru\n",
    "\n",
    "Untuk menunjukkan pengasingan antara benang, kami memulakan `design-review-session` dan meminta panduan log untuk semakan insiden. Walaupun asas pangkalan pengetahuan adalah sama, id sesi baru memastikan transkrip kekal berasingan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## Ulasan Sesi 2 Sejarah\n",
    "\n",
    "`show_history(session_2)` hanya perlu menyenaraikan pasangan prompt/respons ulasan reka bentuk. Bandingkan dengan Sesi 1 untuk menonjolkan bagaimana Cognee mengekalkan transkrip yang berasingan sambil menggunakan semula graf pengetahuan yang dikongsi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## Ringkasan\n",
    "\n",
    "Tahniah! Anda baru sahaja memberikan pembantu pengekodan anda lapisan memori jangka panjang sebenar yang dikuasakan oleh Cognee.\n",
    "\n",
    "Dalam tutorial ini, anda telah mengambil kandungan pembangun mentah (kod, dokumen, sembang) dan mengubahnya menjadi graf + memori vektor yang boleh dicari, dianalisis, dan diperbaiki secara berterusan oleh agen anda.\n",
    "\n",
    "Apa Yang Anda Pelajari\n",
    "\n",
    "1. **Daripada teks mentah kepada memori AI**: Bagaimana Cognee memproses data tidak berstruktur dan mengubahnya menjadi memori pintar yang boleh dicari menggunakan gabungan seni bina vektor + graf pengetahuan.\n",
    "\n",
    "2. **Pengayaan graf dengan memify**: Bagaimana untuk melangkaui penciptaan graf asas dan menggunakan memify untuk menambah fakta terbitan dan hubungan yang lebih kaya di atas graf sedia ada anda.\n",
    "\n",
    "3. **Pelbagai strategi carian**: Bagaimana untuk membuat pertanyaan memori dengan pelbagai jenis carian (Q&A yang sedar graf, pelengkapan gaya RAG, wawasan, potongan mentah, carian kod, dll.) bergantung pada keperluan agen anda.\n",
    "\n",
    "4. **Penerokaan visual**: Bagaimana untuk memeriksa dan menyahpepijat apa yang dibina oleh Cognee menggunakan visualisasi graf dan UI Cognee, supaya anda benar-benar dapat melihat bagaimana pengetahuan disusun.\n",
    "\n",
    "5. **Memori sedar sesi**: Bagaimana untuk menggabungkan konteks setiap sesi dengan memori semantik berterusan supaya agen dapat mengingati merentasi sesi tanpa membocorkan maklumat antara pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Poin Penting\n",
    "1. Memori sebagai Graf Pengetahuan yang disokong oleh Embeddings\n",
    "\n",
    "    - **Pemahaman terstruktur**: Cognee menggabungkan stor vektor dan stor graf supaya data anda boleh dicari berdasarkan makna dan dihubungkan melalui hubungan. Cognee menggunakan pangkalan data berasaskan fail secara lalai (LanceDB untuk stor vektor, Kuzu untuk pangkalan data graf).\n",
    "\n",
    "    - **Pengambilan maklumat berasaskan hubungan**: Jawapan boleh diasaskan bukan sahaja pada \"teks yang serupa,\" tetapi juga pada bagaimana entiti saling berkaitan.\n",
    "\n",
    "    - **Memori yang hidup**: Lapisan memori berkembang, bertambah, dan kekal boleh dicari sebagai satu graf yang bersambung.\n",
    "\n",
    "2. Mod Carian & Penaakulan\n",
    "    - **Pengambilan hibrid**: Carian menggabungkan kesamaan vektor, struktur graf, dan penaakulan LLM, dari pencarian potongan mentah hingga soal jawab yang sedar graf.\n",
    "\n",
    "    - **Sesuaikan mod dengan tugas**: Gunakan mod gaya pelengkap apabila anda mahukan jawapan dalam bahasa semula jadi, dan mod potongan/ringkasan/graf apabila agen anda memerlukan konteks mentah atau untuk mendorong penaakulan sendiri.\n",
    "\n",
    "3. Agen yang Diperibadikan dan Sedar Sesi\n",
    "    - **Konteks sesi + memori jangka panjang**: Cognee memisahkan konteks \"benang\" jangka pendek daripada memori jangka panjang di peringkat pengguna atau organisasi.\n",
    "\n",
    "## Aplikasi Dunia Sebenar\n",
    "\n",
    "1. **Agen AI Vertikal**\n",
    "\n",
    "    Gunakan corak dari buku nota ini untuk menggerakkan pembantu pintar domain yang duduk di atas Cognee sebagai teras pengambilan dan penaakulan mereka:\n",
    "\n",
    "- **Pembantu pembangun**: Semakan kod, analisis insiden, dan pembantu seni bina yang menelusuri kod, API, dokumen reka bentuk, dan tiket sebagai satu graf memori.\n",
    "\n",
    "- **Pembantu berhadapan pelanggan**: Agen sokongan atau kejayaan yang menarik dari dokumen produk, FAQ, nota CRM, dan tiket lalu dengan pengambilan sedar graf dan jawapan yang disokong.\n",
    "\n",
    "- **Pembantu pakar dalaman**: Pembantu dasar, undang-undang, atau keselamatan yang membuat penaakulan berdasarkan peraturan, panduan, dan keputusan sejarah yang saling berkaitan, bukannya PDF yang terasing.\n",
    "\n",
    "    Cognee secara eksplisit diposisikan sebagai memori yang berterusan dan tepat untuk agen AI, menyediakan graf pengetahuan yang hidup yang menggantikan kombinasi ad-hoc stor vektor dan kod graf tersuai.\n",
    "\n",
    "2. **Menyatukan Silo Data ke dalam Satu Memori**\n",
    "\n",
    "    Pendekatan yang sama juga membantu anda membina lapisan memori bersatu merentasi sumber yang tersebar:\n",
    "\n",
    "- **Dari silo ke satu graf**: Serap data terstruktur (contohnya, pangkalan data) dan tidak terstruktur (contohnya, dokumen, sembang) ke dalam satu graf yang disokong oleh embeddings, bukannya indeks berasingan untuk setiap sistem.\n",
    "\n",
    "- **Penaakulan silang sumber dengan sitasi**: Jalankan penaakulan berbilang langkah ke atas semuanya‚Äî‚Äúgabungkan‚Äù log, metrik, dan dokumen melalui graf‚Äîdan tetap kembalikan jawapan yang diasaskan dengan bukti.\n",
    "\n",
    "- **Hab pengetahuan**: Untuk domain seperti perbankan atau pendidikan, Cognee sudah digunakan untuk menyatukan PDF, sistem dalaman, dan data aplikasi ke dalam satu graf pengetahuan dengan vektor supaya agen boleh menjawab soalan dengan konteks yang tepat dan disokong.\n",
    "\n",
    "## Langkah Seterusnya\n",
    "\n",
    "Anda telah melaksanakan gelung memori teras. Berikut adalah lanjutan semula jadi yang boleh anda cuba sendiri (lihat [dokumentasi Cognee](https://docs.cognee.ai/) untuk butiran):\n",
    "\n",
    "1. **Bereksperimen dengan kesedaran temporal**: Hidupkan temporal cognify untuk mengekstrak peristiwa dan cap waktu dari teks.\n",
    "\n",
    "2. **Perkenalkan penaakulan berasaskan ontologi**: Tentukan ontologi OWL untuk domain anda. Gunakan sokongan ontologi Cognee supaya entiti dan hubungan yang diekstrak diasaskan dalam skema tersebut, meningkatkan kualiti graf dan jawapan khusus domain.\n",
    "\n",
    "3. **Tambah gelung maklum balas**: Biarkan Cognee menyesuaikan berat tepi graf berdasarkan maklum balas pengguna sebenar, supaya pengambilan maklumat bertambah baik dari masa ke masa dan tidak statik.\n",
    "\n",
    "4. **Laraskan untuk personalisasi & tingkah laku sesi**: Gunakan ID pengguna, penyewa, dan set data untuk memberikan setiap individu atau pasukan pandangan mereka sendiri terhadap enjin memori yang dikongsi.\n",
    "\n",
    "5. **Skalakan kepada agen yang lebih kompleks**: Sambungkan Cognee ke rangka kerja agen untuk membina sistem multi-agen yang semuanya berkongsi lapisan memori yang sama. *Microsoft Agent Framework x plugin Cognee akan datang tidak lama lagi.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang berwibawa. Untuk maklumat kritikal, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T14:16:00+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "ms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}