{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Pagbuo ng AI Agents na may Persistent Memory gamit ang Cognee\n",
    "\n",
    "Ang notebook na ito ay nagpapakita kung paano bumuo ng matatalinong AI agents na may advanced na kakayahan sa memorya gamit ang [**cognee**](https://www.cognee.ai/) - isang open source na AI memory na pinagsasama ang knowledge graphs, semantic search, at session management upang makalikha ng mga context-aware na AI systems.\n",
    "\n",
    "## üéØ Mga Layunin sa Pag-aaral\n",
    "\n",
    "Sa pagtatapos ng tutorial na ito, mauunawaan mo kung paano:\n",
    "- **Bumuo ng Knowledge Graphs na May Embeddings**: I-transform ang hindi organisadong teksto sa structured, queryable na kaalaman\n",
    "- **Magpatupad ng Session Memory**: Lumikha ng multi-turn na mga pag-uusap na may awtomatikong pag-iingat ng konteksto\n",
    "- **Mag-imbak ng Mga Pag-uusap**: Opsyonal na itago ang mahahalagang interaksyon sa pangmatagalang memorya para sa hinaharap na paggamit\n",
    "- **Mag-query Gamit ang Natural na Wika**: I-access at gamitin ang historical na konteksto sa mga bagong pag-uusap\n",
    "- **I-visualize ang Memorya**: Tuklasin ang mga relasyon sa knowledge graph ng iyong agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Ano ang Iyong Itatayo\n",
    "\n",
    "Sa tutorial na ito, gagawa tayo ng isang **Coding Assistant** na may kakayahang magtago ng memorya na:\n",
    "\n",
    "### 1. **Pagbuo ng Knowledge Base**\n",
    "   - Kumukuha ng impormasyon tungkol sa profile at kakayahan ng developer\n",
    "   - Nagpoproseso ng mga prinsipyo at pinakamahusay na kasanayan sa Python programming\n",
    "   - Nagtatabi ng mga nakaraang pag-uusap sa pagitan ng mga developer at AI assistants\n",
    "\n",
    "### 2. **Session-Aware na Mga Pag-uusap**\n",
    "   - Pinapanatili ang konteksto sa maraming tanong sa parehong session\n",
    "   - Awtomatikong iniimbak ang bawat pares ng tanong/sagot para sa mas mabilis na retrieval\n",
    "   - Nagbibigay ng malinaw at may kontekstong sagot batay sa kasaysayan ng pag-uusap\n",
    "\n",
    "### 3. **Pangmatagalang Memorya**\n",
    "   - Nagtatabi ng mahahalagang pag-uusap sa pangmatagalang memorya\n",
    "   - Kinukuha ang mga kaugnay na alaala mula sa knowledge base at mga nakaraang session upang magbigay ng impormasyon sa mga bagong interaksyon\n",
    "   - Lumilikha ng lumalaking knowledge base na patuloy na bumubuti sa paglipas ng panahon\n",
    "\n",
    "### 4. **Matalinong Retrieval ng Memorya**\n",
    "   - Gumagamit ng graph-aware semantic search upang mahanap ang kaugnay na impormasyon sa lahat ng nakaimbak na kaalaman\n",
    "   - Nagfi-filter ng mga paghahanap batay sa mga subgroup ng data (impormasyon ng developer vs. mga prinsipyo)\n",
    "   - Pinagsasama ang maraming pinagmumulan ng data upang makapagbigay ng komprehensibong sagot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Mga Paunang Kailangan at Setup\n",
    "\n",
    "### Mga Kinakailangan sa Sistema\n",
    "\n",
    "Bago magsimula, tiyakin na mayroon ka ng mga sumusunod:\n",
    "\n",
    "1. **Python Environment**\n",
    "   - Python 3.9 o mas mataas\n",
    "   - Virtual environment (inirerekomenda)\n",
    "   \n",
    "2. **Redis Cache** (Kinakailangan para sa Session Management)\n",
    "   - Lokal na Redis: `docker run -d -p 6379:6379 redis`\n",
    "   - O gumamit ng isang managed Redis service\n",
    "   \n",
    "3. **LLM API Access**\n",
    "   - OpenAI API key o iba pang provider (tingnan ang [dokumentasyon](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Database Configuration**\n",
    "   - Walang kinakailangang configuration bilang default. Gumagamit ang Cognee ng file-based databases (LanceDB at Kuzu)\n",
    "   - Opsyonal, maaari kang mag-setup ng Azure AI Search bilang vector store (tingnan ang [dokumentasyon](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Configuration ng Environment\n",
    "\n",
    "Gumawa ng `.env` file sa iyong project directory na may mga sumusunod na variable:\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Pag-unawa sa Arkitektura ng Memorya ng Cognee\n",
    "\n",
    "### Paano Gumagana ang Cognee\n",
    "\n",
    "Ang Cognee ay nagbibigay ng isang sopistikadong sistema ng memorya na higit pa sa simpleng key-value storage:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Mga Pangunahing Komponent:\n",
    "\n",
    "1. **Knowledge Graph**: Nagtatago ng mga entidad, relasyon, at semantikong koneksyon\n",
    "2. **Vector Embeddings**: Nagpapahintulot ng semantikong paghahanap sa lahat ng nakaimbak na impormasyon\n",
    "3. **Session Cache**: Pinapanatili ang konteksto ng pag-uusap sa loob at labas ng mga sesyon\n",
    "4. **NodeSets**: Inaayos ang data sa mga lohikal na kategorya para sa mas tiyak na retrieval\n",
    "\n",
    "### Mga Uri ng Memorya sa Tutorial na Ito:\n",
    "\n",
    "- **Persistent Memory**: Pangmatagalang imbakan sa knowledge graph\n",
    "- **Session Memory**: Pansamantalang konteksto ng pag-uusap sa Redis cache\n",
    "- **Semantic Memory**: Batay sa vector na paghahanap ng pagkakatulad sa lahat ng data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Mag-install ng Mga Kinakailangang Package\n",
    "\n",
    "I-install ang Cognee na may suporta sa Redis para sa session management:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß I-set up ang Kapaligiran at I-load ang mga Library\n",
    "\n",
    "Siguraduhin na:\n",
    "1. Tumatakbo ang Redis (hal., gamit ang Docker: `docker run -d -p 6379:6379 redis`)\n",
    "2. Naka-set ang mga environment variable bago i-import ang mga cache module\n",
    "3. Kung kinakailangan, i-restart ang kernel at patakbuhin ang mga cell nang sunud-sunod\n",
    "\n",
    "Ang sumusunod na cell ay gagawin ang mga sumusunod:\n",
    "1. I-load ang mga environment variable mula sa `.env`\n",
    "2. I-configure ang Cognee gamit ang iyong LLM settings\n",
    "3. I-enable ang caching para sa session management\n",
    "4. Siguraduhing maayos na nakakonekta ang lahat ng mga bahagi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ I-configure ang mga Direktoryo ng Storage\n",
    "\n",
    "Gumagamit ang Cognee ng dalawang magkahiwalay na direktoryo para sa mga operasyon nito:\n",
    "- **Data Root**: Nagtatabi ng mga dokumentong na-ingest at mga naprosesong data\n",
    "- **System Root**: Naglalaman ng knowledge graph database at metadata ng sistema\n",
    "\n",
    "Gagawa tayo ng magkakahiwalay na direktoryo para sa tutorial na ito tulad ng sumusunod:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ I-reset ang Estado ng Memorya\n",
    "\n",
    "Bago tayo magsimula sa paggawa ng ating sistema ng memorya, tiyakin muna natin na nagsisimula tayo nang malinis.\n",
    "\n",
    "> üí° **Tip**: Maaari mong laktawan ang hakbang na ito kung nais mong panatilihin ang mga umiiral na alaala mula sa iyong mga nakaraang pagtakbo kapag ginamit mo ang notebook na ito sa hinaharap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Bahagi 1: Pagbuo ng Knowledge Base\n",
    "\n",
    "### Mga Pinagmulan ng Data para sa Ating Developer Assistant\n",
    "\n",
    "Tatlong uri ng data ang ating gagamitin upang makabuo ng komprehensibong knowledge base:\n",
    "\n",
    "1. **Profile ng Developer**: Personal na kadalubhasaan at teknikal na background\n",
    "2. **Mga Pinakamahusay na Praktis sa Python**: Ang Zen of Python na may praktikal na gabay\n",
    "3. **Mga Makasaysayang Usapan**: Mga nakaraang Q&A session sa pagitan ng mga developer at AI assistants\n",
    "\n",
    "Ang magkakaibang data na ito ay nagbibigay-daan sa ating agent na:\n",
    "- Maunawaan ang teknikal na konteksto ng user\n",
    "- Mag-apply ng pinakamahusay na praktis sa mga rekomendasyon\n",
    "- Matuto mula sa mga nakaraang matagumpay na interaksyon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Proseso ng Datos patungo sa Knowledge Graph\n",
    "\n",
    "Ngayon, babaguhin natin ang ating raw text sa isang nakaayos na memorya. Ang prosesong ito:\n",
    "\n",
    "1. **Nagdaragdag ng datos sa NodeSets**: Inaayos ang impormasyon sa lohikal na mga kategorya\n",
    "   - `developer_data`: Profile ng developer at mga pag-uusap\n",
    "   - `principles_data`: Mga pinakamahusay na kasanayan at gabay sa Python\n",
    "\n",
    "2. **Pinapatakbo ang Cognify Pipeline**: Kinukuha ang mga entity, relasyon, at gumagawa ng embeddings\n",
    "   - Tinutukoy ang mga pangunahing konsepto\n",
    "   - Lumilikha ng semantikong koneksyon sa pagitan ng magkakaugnay na impormasyon\n",
    "   - Gumagawa ng vector embeddings\n",
    "\n",
    "Maaaring tumagal ito ng ilang sandali habang pinoproseso ng LLM ang teksto at binubuo ang istruktura ng graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä I-visualize ang Knowledge Graph\n",
    "\n",
    "Tuklasin natin ang istruktura ng ating knowledge graph. Ang visualization ay nagpapakita ng:\n",
    "- **Nodes**: Mga entity na nakuha mula sa teksto (mga konsepto, teknolohiya, tao)\n",
    "- **Edges**: Mga relasyon at koneksyon sa pagitan ng mga entity\n",
    "- **Clusters**: Mga kaugnay na konsepto na pinagsama batay sa semantikong pagkakatulad\n",
    "\n",
    "Buksan ang nalikhang HTML file sa iyong browser upang interaktibong tuklasin ang graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Pagyamanin ang Memorya gamit ang Memify\n",
    "\n",
    "Ang `memify()` na function ay sinusuri ang knowledge graph at bumubuo ng matatalinong alituntunin tungkol sa datos. Ang prosesong ito:\n",
    "- Tinutukoy ang mga pattern at pinakamahusay na mga kasanayan\n",
    "- Lumilikha ng mga praktikal na gabay batay sa nilalaman\n",
    "- Nagpapalaganap ng ugnayan sa pagitan ng iba't ibang larangan ng kaalaman\n",
    "\n",
    "Ang mga alituntuning ito ay tumutulong sa ahente na gumawa ng mas maalam na desisyon kapag sumasagot ng mga tanong. Ang pagkuha ng pangalawang biswal na representasyon ay tumutulong sa iyo na maikumpara kung paano nagiging mas siksik ang graph kapag napagyaman.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Bahagi 2: Matalinong Pagkuha ng Impormasyon\n",
    "\n",
    "### Demonstrasyon 1: Pagsasama ng Kaalaman mula sa Iba't ibang Dokumento\n",
    "\n",
    "Ngayon na nabuo na ang ating knowledge graph, subukan natin kung paano pinagsasama ng Cognee ang impormasyon mula sa iba't ibang mapagkukunan upang sagutin ang masalimuot na mga tanong.\n",
    "\n",
    "Ang unang query ay nagpapakita ng:\n",
    "- **Semantic na pag-unawa**: Paghahanap ng mga kaugnay na konsepto kahit hindi ito tahasang binanggit\n",
    "- **Cross-referencing**: Pagsasama ng profile ng developer sa mga prinsipyo ng Python\n",
    "- **Contextual na pangangatwiran**: Paglalapat ng pinakamahusay na mga kasanayan sa mga tiyak na implementasyon\n",
    "\n",
    "### Demonstrasyon 2: Piniling Paghahanap gamit ang NodeSets\n",
    "\n",
    "Ang pangalawang query ay nagpapakita kung paano mag-target ng mga tiyak na subset ng knowledge graph:\n",
    "- Gumagamit ng `node_name` parameter upang maghanap lamang sa loob ng `principles_data`\n",
    "- Nagbibigay ng nakatuon na sagot mula sa isang tiyak na domain ng kaalaman\n",
    "- Kapaki-pakinabang kapag kailangan mo ng impormasyon na tiyak sa isang domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Bahagi 3: Pag-set up ng Pamamahala ng Session\n",
    "\n",
    "### Pag-enable ng Memorya ng Usapan\n",
    "\n",
    "Ang pamamahala ng session ay mahalaga para mapanatili ang konteksto sa maraming interaksyon. Dito natin gagawin ang sumusunod:\n",
    "\n",
    "1. **I-initialize ang Konteksto ng User**: Gumawa o kunin ang profile ng user para sa pagsubaybay ng session\n",
    "2. **I-configure ang Cache Engine**: Kumonekta sa Redis para sa pag-iimbak ng kasaysayan ng usapan\n",
    "3. **I-enable ang Mga Variable ng Session**: Mag-set up ng mga variable ng konteksto na nananatili sa bawat query\n",
    "\n",
    "> ‚ö†Ô∏è **Mahalaga**: Kinakailangan na tumatakbo ang Redis at `CACHING=true` sa iyong environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Helper Function: Tingnan ang Kasaysayan ng Session\n",
    "\n",
    "Ang utility function na ito ay nagbibigay-daan sa atin na suriin ang kasaysayan ng pag-uusap na nakaimbak sa Redis. Ito ay kapaki-pakinabang para sa:\n",
    "- Pag-debug ng pamamahala ng session\n",
    "- Pag-verify na ang mga pag-uusap ay nai-cache\n",
    "- Pag-unawa kung anong konteksto ang magagamit para sa ahente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Session 1: Async Support Lab ‚Äî Unang Tanong\n",
    "\n",
    "Simulan ang sesyon ng `async-support-lab` sa pamamagitan ng pagtatanong tungkol sa mga telemetry-friendly na asyncio patterns para sa isang napakalaking web scraper. Alam na ng graph ang tungkol sa asyncio, aiohttp, at mga monitoring practices, kaya ang sagot ay dapat sumasalamin sa mga naunang pag-uusap habang iniangkop ang sagot sa bagong tanong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Suriin ang Memorya ng Session 1 Pagkatapos ng Unang Palitan\n",
    "\n",
    "Ang pagtakbo ng `show_history(session_1)` kaagad pagkatapos ng unang tanong ay nagkukumpirma na isinulat ng Cognee ang parehong prompt at completion sa Redis. Makikita mo ang isang entry na may gabay sa concurrency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Session 1: Pagsusuri sa Data Models\n",
    "\n",
    "Susunod nating tanungin, \"Kailan ko dapat piliin ang dataclasses kumpara sa Pydantic?\" gamit ang parehong session id. Dapat pagsamahin ni Cognee ang mga prinsipyo ng Python kasama ang mga naunang pag-uusap tungkol sa FastAPI upang magbigay ng mas detalyado at masusing payo‚Äîipinapakita na ang konteksto ay naipapasa sa loob ng isang pinangalanang session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Kumpirmahin na ang Kasaysayan ng Session 1 ay Naglalaman ng Parehong Mga Palitan\n",
    "\n",
    "Ang isa pang `show_history(session_1)` na tawag ay dapat magpakita ng dalawang Q&A na entry. Ito ay tumutugma sa \"memory replay\" na hakbang ng Mem0 lab at nagpapatunay na ang mga karagdagang palitan ay nagdaragdag sa parehong transcript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Session 2: Thread ng Pagsusuri ng Disenyo ‚Äî Bagong Session\n",
    "\n",
    "Para ipakita ang paghihiwalay sa pagitan ng mga thread, pinapatakbo namin ang `design-review-session` at humihingi ng gabay sa pag-log para sa pagsusuri ng insidente. Kahit pareho ang base ng kaalaman, ang bagong session id ay nagpapanatili ng hiwalay na mga transcript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## Pagsusuri ng Session 2 Kasaysayan\n",
    "\n",
    "`show_history(session_2)` ay dapat maglista lamang ng pares ng prompt/response para sa design-review. Ihambing ito sa Session 1 upang ipakita kung paano pinapanatili ng Cognee ang mga independiyenteng transcript habang muling ginagamit ang ibinahaging knowledge graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## Buod\n",
    "\n",
    "Binabati kita! Nabigyan mo na ang iyong coding assistant ng isang tunay na pangmatagalang memory layer na pinapagana ng Cognee.\n",
    "\n",
    "Sa tutorial na ito, kinuha mo ang raw na nilalaman ng developer (code, dokumento, chat) at ginawang isang graph + vector memory na maaaring hanapin, pag-isipan, at patuloy na pagbutihin ng iyong agent.\n",
    "\n",
    "Ano ang Iyong Natutunan\n",
    "\n",
    "1. **Mula sa raw na teksto patungo sa AI memory**: Paano ini-ingest ng Cognee ang hindi istrukturang data at ginagawang matalino, mahanap na memory gamit ang pinagsamang vector + knowledge graph na arkitektura.\n",
    "\n",
    "2. **Pagpapayaman ng graph gamit ang memify**: Paano lampasan ang simpleng paggawa ng graph at gamitin ang memify upang magdagdag ng mga derived facts at mas mayamang relasyon sa ibabaw ng iyong umiiral na graph.\n",
    "\n",
    "3. **Iba't ibang estratehiya sa paghahanap**: Paano mag-query ng memory gamit ang iba't ibang uri ng paghahanap (graph-aware Q&A, RAG-style completion, insights, raw chunks, code search, atbp.) depende sa pangangailangan ng iyong agent.\n",
    "\n",
    "4. **Visual na eksplorasyon**: Paano inspeksyunin at i-debug ang ginawa ng Cognee gamit ang mga graph visualization at ang Cognee UI, upang makita mo kung paano nakaayos ang kaalaman.\n",
    "\n",
    "5. **Session-aware memory**: Paano pagsamahin ang per-session context sa persistent semantic memory upang maalala ng mga agent ang mga impormasyon sa bawat run nang hindi nagkakaroon ng pagtagas ng impormasyon sa pagitan ng mga user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Mga Pangunahing Punto\n",
    "1. Memorya bilang isang Knowledge Graph na sinusuportahan ng Embeddings\n",
    "\n",
    "    - **Naka-istrukturang pag-unawa**: Pinagsasama ng Cognee ang isang vector store at isang graph store upang ang iyong data ay parehong mahanap batay sa kahulugan at konektado sa pamamagitan ng mga relasyon. Gumagamit ang Cognee ng mga file-based na database bilang default (LanceDB para sa vector-, Kuzu para sa graph database).\n",
    "\n",
    "    - **Pagkuha na may kamalayan sa relasyon**: Ang mga sagot ay maaaring batay hindi lamang sa ‚Äúkatulad na teksto,‚Äù kundi pati na rin sa kung paano nauugnay ang mga entity.\n",
    "\n",
    "    - **Buhay na memorya**: Ang memory layer ay umuunlad, lumalago, at nananatiling mahanap bilang isang konektadong graph.\n",
    "\n",
    "2. Mga Mode ng Paghahanap at Pangangatwiran\n",
    "    - **Hybrid retrieval**: Ang paghahanap ay pinagsasama ang vector similarity, graph structure, at LLM reasoning, mula sa raw chunk lookup hanggang sa graph-aware na pagsagot sa tanong.\n",
    "\n",
    "    - **Iangkop ang mode sa trabaho**: Gumamit ng completion-style modes kapag gusto mo ng natural na sagot sa wika, at chunk/summary/graph modes kapag kailangan ng iyong agent ng raw na konteksto o upang magmaneho ng sariling pangangatwiran.\n",
    "\n",
    "3. Personalized, Session-Aware Agents\n",
    "    - **Session context + long-term memory**: Pinapanatili ng Cognee ang maikling ‚Äúthread‚Äù context na hiwalay mula sa pangmatagalang memorya sa antas ng user o organisasyon.\n",
    "\n",
    "## Mga Aplikasyon sa Tunay na Mundo\n",
    "\n",
    "1. **Vertical AI Agents**\n",
    "\n",
    "    Gamitin ang pattern mula sa notebook na ito upang paganahin ang domain-smart copilots na nakabase sa Cognee bilang retrieval at reasoning core:\n",
    "\n",
    "- **Developer copilots**: Code review, pagsusuri ng insidente, at mga assistant sa arkitektura na naglalakbay sa code, APIs, design docs, at mga ticket bilang isang memory graph.\n",
    "\n",
    "- **Customer-facing copilots**: Mga support o success agents na kumukuha mula sa product docs, FAQs, CRM notes, at mga nakaraang ticket gamit ang graph-aware retrieval at mga sagot na may citation.\n",
    "\n",
    "- **Internal expert copilots**: Mga assistant sa polisiya, legal, o seguridad na nangangatuwiran sa interconnected na mga patakaran, gabay, at mga desisyon sa kasaysayan sa halip na mga hiwalay na PDF.\n",
    "\n",
    "    Ang Cognee ay tahasang nakaposisyon bilang persistent, accurate memory para sa AI agents, na nagbibigay ng isang buhay na knowledge graph na maaaring gamitin sa likod ng iyong agent at pumalit sa ad-hoc na kombinasyon ng vector stores at custom graph code.\n",
    "\n",
    "2. **Pag-iisa ng Data Silos sa Isang Memorya**\n",
    "\n",
    "    Ang parehong approach ay tumutulong din sa pagbuo ng isang unified memory layer sa mga magkakahiwalay na sources:\n",
    "\n",
    "- **Mula sa silos patungo sa isang graph**: I-ingest ang structured (hal., databases) at unstructured data (hal., docs, chats) sa isang graph na sinusuportahan ng embeddings, sa halip na magkakahiwalay na indices para sa bawat sistema.\n",
    "\n",
    "- **Pangangatwiran sa cross-source na may citations**: Magpatakbo ng multi-step reasoning sa lahat‚Äî‚Äúi-join‚Äù ang logs, metrics, at docs sa pamamagitan ng graph‚Äîat magbalik pa rin ng grounded na sagot na may provenance.\n",
    "\n",
    "- **Knowledge hubs**: Para sa mga domain tulad ng banking o edukasyon, ginagamit na ang Cognee upang pag-isahin ang PDFs, internal systems, at app data sa isang knowledge graph na may vectors upang ang mga agents ay makasagot ng mga tanong na may eksaktong, cited na konteksto.\n",
    "\n",
    "## Mga Susunod na Hakbang\n",
    "\n",
    "Na-implement mo na ang core memory loop. Narito ang mga natural na extension na maaari mong subukan sa iyong sarili (tingnan ang [Cognee documentation](https://docs.cognee.ai/) para sa mga detalye):\n",
    "\n",
    "1. **Mag-eksperimento sa temporal awareness**: I-on ang temporal cognify upang mag-extract ng mga event at timestamps mula sa teksto.\n",
    "\n",
    "2. **Magpakilala ng ontology-driven reasoning**: Tukuyin ang isang OWL ontology para sa iyong domain. Gamitin ang suporta ng Cognee sa ontology upang ang mga na-extract na entity at relasyon ay nakabase sa schema na iyon, na nagpapabuti sa kalidad ng graph at mga sagot na partikular sa domain.\n",
    "\n",
    "3. **Magdagdag ng feedback loop**: Hayaan ang Cognee na ayusin ang graph edge weights mula sa aktwal na feedback ng user, upang ang retrieval ay patuloy na bumuti sa paglipas ng panahon sa halip na manatiling static.\n",
    "\n",
    "4. **I-tune para sa personalization at session behavior**: Gamitin ang user IDs, tenants, at datasets upang bigyan ang bawat tao o team ng kanilang sariling view sa shared memory engine.\n",
    "\n",
    "5. **Mag-scale out sa mas kumplikadong agents**: I-plug ang Cognee sa agent frameworks upang bumuo ng multi-agent systems na lahat ay nagbabahagi ng parehong memory layer. *Microsoft Agent Framework x Cognee plugin ay paparating na.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Paunawa**:  \nAng dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagama't sinisikap naming maging tumpak, mangyaring tandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na awtoritatibong pinagmulan. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na dulot ng paggamit ng pagsasaling ito.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T14:17:56+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "tl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}