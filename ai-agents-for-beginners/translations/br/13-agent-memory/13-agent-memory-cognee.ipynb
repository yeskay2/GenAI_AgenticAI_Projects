{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a807409",
   "metadata": {},
   "source": [
    "# Construindo Agentes de IA com Mem√≥ria Persistente usando Cognee\n",
    "\n",
    "Este notebook demonstra como construir agentes de IA inteligentes com capacidades sofisticadas de mem√≥ria usando [**cognee**](https://www.cognee.ai/) - uma mem√≥ria de IA de c√≥digo aberto que combina grafos de conhecimento, busca sem√¢ntica e gerenciamento de sess√µes para criar sistemas de IA conscientes de contexto.\n",
    "\n",
    "## üéØ Objetivos de Aprendizado\n",
    "\n",
    "Ao final deste tutorial, voc√™ entender√° como:\n",
    "- **Construir Grafos de Conhecimento Baseados em Embeddings**: Transformar texto n√£o estruturado em conhecimento estruturado e consult√°vel\n",
    "- **Implementar Mem√≥ria de Sess√£o**: Criar conversas de m√∫ltiplas intera√ß√µes com reten√ß√£o autom√°tica de contexto\n",
    "- **Persistir Conversas**: Opcionalmente armazenar intera√ß√µes importantes em mem√≥ria de longo prazo para refer√™ncia futura\n",
    "- **Consultar Usando Linguagem Natural**: Acessar e aproveitar o contexto hist√≥rico em novas conversas\n",
    "- **Visualizar Mem√≥ria**: Explorar os relacionamentos no grafo de conhecimento do seu agente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195e5f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è O que voc√™ vai construir\n",
    "\n",
    "Neste tutorial, vamos criar um **Assistente de Codifica√ß√£o** com mem√≥ria persistente que:\n",
    "\n",
    "### 1. **Constru√ß√£o de Base de Conhecimento**\n",
    "   - Ingere informa√ß√µes sobre o perfil e a expertise do desenvolvedor\n",
    "   - Processa princ√≠pios e boas pr√°ticas de programa√ß√£o em Python\n",
    "   - Armazena conversas hist√≥ricas entre desenvolvedores e assistentes de IA\n",
    "\n",
    "### 2. **Conversas com Contexto de Sess√£o**\n",
    "   - Mant√©m o contexto ao longo de v√°rias perguntas na mesma sess√£o\n",
    "   - Armazena automaticamente cada par de pergunta/resposta para recupera√ß√£o eficiente\n",
    "   - Fornece respostas coerentes e contextuais com base no hist√≥rico da conversa\n",
    "\n",
    "### 3. **Mem√≥ria de Longo Prazo**\n",
    "   - Persiste conversas importantes em uma mem√≥ria de longo prazo\n",
    "   - Recupera mem√≥rias relevantes da base de conhecimento e sess√µes anteriores para informar novas intera√ß√µes\n",
    "   - Constr√≥i uma base de conhecimento crescente que melhora com o tempo\n",
    "\n",
    "### 4. **Recupera√ß√£o Inteligente de Mem√≥ria**\n",
    "   - Utiliza busca sem√¢ntica baseada em grafos para encontrar informa√ß√µes relevantes em todo o conhecimento armazenado\n",
    "   - Filtra buscas por subgrupos de dados (informa√ß√µes do desenvolvedor vs. princ√≠pios)\n",
    "   - Combina m√∫ltiplas fontes de dados para fornecer respostas abrangentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fdf9d",
   "metadata": {},
   "source": [
    "## üìã Pr√©-requisitos e Configura√ß√£o\n",
    "\n",
    "### Requisitos do Sistema\n",
    "\n",
    "Antes de come√ßar, certifique-se de ter:\n",
    "\n",
    "1. **Ambiente Python**\n",
    "   - Python 3.9 ou superior\n",
    "   - Ambiente virtual (recomendado)\n",
    "   \n",
    "2. **Cache Redis** (Necess√°rio para Gerenciamento de Sess√£o)\n",
    "   - Redis local: `docker run -d -p 6379:6379 redis`\n",
    "   - Ou use um servi√ßo Redis gerenciado\n",
    "   \n",
    "3. **Acesso √† API LLM**\n",
    "   - Chave de API OpenAI ou outros provedores (veja [documenta√ß√£o](https://docs.cognee.ai/setup-configuration/llm-providers))\n",
    "\n",
    "4. **Configura√ß√£o de Banco de Dados**\n",
    "   - Nenhuma configura√ß√£o necess√°ria por padr√£o. Cognee utiliza bancos de dados baseados em arquivos (LanceDB e Kuzu)\n",
    "   - Opcionalmente, voc√™ pode configurar o Azure AI Search como um armazenamento vetorial (veja [documenta√ß√£o](https://github.com/topoteretes/cognee-community/tree/main/packages/vector/azureaisearch))\n",
    "\n",
    "### Configura√ß√£o do Ambiente\n",
    "\n",
    "Crie um arquivo `.env` no diret√≥rio do seu projeto com as seguintes vari√°veis:\n",
    "\n",
    "```ini\n",
    "# LLM Configuration (Required)\n",
    "LLM_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# Cache Configuration (Required for Sessions)\n",
    "CACHING=true  # Must be enabled for session history\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f70d",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Entendendo a Arquitetura de Mem√≥ria do Cognee\n",
    "\n",
    "### Como o Cognee Funciona\n",
    "\n",
    "O Cognee oferece um sistema de mem√≥ria sofisticado que vai al√©m do simples armazenamento de chave-valor:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      30+ data sources    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Dynamically evolving memory layers      ‚îÇ\n",
    "‚îÇ                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Knowledge Graph in Graph Database  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Embeddings in Vector Store         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   (e.g., Azure AI Search)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                      ‚ñ≤   \n",
    "            ‚ñº                      ‚îÇ(optional)\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ     cognee     ‚îÇ(optional) ‚îÇ Cognee Session ‚îÇ\n",
    "‚îÇ    retrievers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Cache      ‚îÇ\n",
    "‚îÇ                ‚îÇ           ‚îÇ    (Redis)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚ñ≤\n",
    "        ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Agents          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n",
    "\n",
    "### Componentes Principais:\n",
    "\n",
    "1. **Knowledge Graph (Grafo de Conhecimento)**: Armazena entidades, relacionamentos e conex√µes sem√¢nticas\n",
    "2. **Vector Embeddings (Vetores de Embedding)**: Permite busca sem√¢ntica em todas as informa√ß√µes armazenadas\n",
    "3. **Session Cache (Cache de Sess√£o)**: Mant√©m o contexto da conversa dentro e entre sess√µes\n",
    "4. **NodeSets**: Organiza os dados em categorias l√≥gicas para recupera√ß√£o direcionada\n",
    "\n",
    "### Tipos de Mem√≥ria Neste Tutorial:\n",
    "\n",
    "- **Mem√≥ria Persistente**: Armazenamento de longo prazo no grafo de conhecimento\n",
    "- **Mem√≥ria de Sess√£o**: Contexto tempor√°rio da conversa no cache Redis\n",
    "- **Mem√≥ria Sem√¢ntica**: Busca baseada em similaridade vetorial em todos os dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadf87c",
   "metadata": {},
   "source": [
    "## üì¶ Instalar Pacotes Necess√°rios\n",
    "\n",
    "Instale o Cognee com suporte ao Redis para gerenciamento de sess√µes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"cognee[redis]==0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048beb",
   "metadata": {},
   "source": [
    "## üîß Inicializar Ambiente e Carregar Bibliotecas\n",
    "\n",
    "Certifique-se de que:\n",
    "1. O Redis est√° em execu√ß√£o (por exemplo, via Docker: `docker run -d -p 6379:6379 redis`)\n",
    "2. As vari√°veis de ambiente est√£o configuradas antes de importar os m√≥dulos de cache\n",
    "3. Se necess√°rio, reinicie o kernel e execute as c√©lulas na ordem\n",
    "\n",
    "A c√©lula a seguir ir√°:\n",
    "1. Carregar vari√°veis de ambiente do arquivo `.env`\n",
    "2. Configurar o Cognee com suas configura√ß√µes de LLM\n",
    "3. Habilitar o cache para gerenciamento de sess√£o\n",
    "4. Validar se todos os componentes est√£o devidamente conectados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# cognee Configuration\n",
    "os.environ[\"LLM_API_KEY\"] = os.getenv(\"LLM_API_KEY\", None)\n",
    "os.environ[\"CACHING\"] = os.getenv(\"CACHING\", \"true\")\n",
    "\n",
    "\n",
    "import cognee\n",
    "\n",
    "print(f\"Cognee version: {cognee.__version__}\")\n",
    "print(f\"CACHING: {os.environ.get('CACHING')}\")\n",
    "print(f\"LLM_API_KEY: {os.environ.get('LLM_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c029e9",
   "metadata": {},
   "source": [
    "## üìÅ Configurar Diret√≥rios de Armazenamento\n",
    "\n",
    "O Cognee utiliza dois diret√≥rios separados para suas opera√ß√µes:\n",
    "- **Raiz de Dados**: Armazena documentos ingeridos e dados processados\n",
    "- **Raiz do Sistema**: Cont√©m o banco de dados do grafo de conhecimento e os metadados do sistema\n",
    "\n",
    "Vamos criar diret√≥rios isolados para este tutorial da seguinte forma:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0011f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('.data_storage').resolve()\n",
    "SYSTEM_ROOT = Path('.cognee_system').resolve()\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "SYSTEM_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cognee.config.data_root_directory(str(DATA_ROOT))\n",
    "cognee.config.system_root_directory(str(SYSTEM_ROOT))\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"System root: {SYSTEM_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb31e1",
   "metadata": {},
   "source": [
    "## üßπ Redefinir Estado de Mem√≥ria\n",
    "\n",
    "Antes de come√ßarmos a construir nosso sistema de mem√≥ria, vamos garantir que estamos come√ßando do zero.\n",
    "\n",
    "> üí° **Dica**: Voc√™ pode pular esta etapa se quiser preservar as mem√≥rias existentes de execu√ß√µes anteriores ao usar este notebook novamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.prune.prune_data()\n",
    "await cognee.prune.prune_system(metadata=True)\n",
    "print('Cleared previous Cognee state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386bd5e",
   "metadata": {},
   "source": [
    "## üìö Parte 1: Construindo a Base de Conhecimento\n",
    "\n",
    "### Fontes de Dados para Nosso Assistente de Desenvolvedor\n",
    "\n",
    "Vamos utilizar tr√™s tipos de dados para criar uma base de conhecimento abrangente:\n",
    "\n",
    "1. **Perfil do Desenvolvedor**: Experi√™ncia pessoal e hist√≥rico t√©cnico\n",
    "2. **Melhores Pr√°ticas em Python**: O Zen do Python com diretrizes pr√°ticas\n",
    "3. **Conversas Hist√≥ricas**: Sess√µes de perguntas e respostas anteriores entre desenvolvedores e assistentes de IA\n",
    "\n",
    "Esses dados diversificados permitem que nosso agente:\n",
    "- Compreenda o contexto t√©cnico do usu√°rio\n",
    "- Aplique as melhores pr√°ticas nas recomenda√ß√µes\n",
    "- Aprenda com intera√ß√µes bem-sucedidas anteriores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_intro = (\n",
    "  \"Hi, I'm an AI/Backend engineer. \"\n",
    "  \"I build FastAPI services with Pydantic, heavy asyncio/aiohttp pipelines, \"\n",
    "  \"and production testing via pytest-asyncio. \"\n",
    "  \"I've shipped low-latency APIs on AWS, Azure, and GoogleCloud.\"\n",
    ")\n",
    "\n",
    "python_zen_principles = (\n",
    "  \"\"\"\n",
    "    # The Zen of Python: Practical Guide\n",
    "\n",
    "    ## Overview\n",
    "    Use these principles as a checklist during design, coding, and reviews.\n",
    "\n",
    "    ## Key Principles With Guidance\n",
    "\n",
    "    ### 1. Beautiful is better than ugly\n",
    "    Prefer descriptive names, clear structure, and consistent formatting.\n",
    "\n",
    "    ### 2. Explicit is better than implicit\n",
    "    Be clear about behavior, imports, and types.\n",
    "    ```python\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    def get_future_date(days_ahead: int) -> datetime:\n",
    "        return datetime.now() + timedelta(days=days_ahead)\n",
    "    ```\n",
    "\n",
    "    ### 3. Simple is better than complex\n",
    "    Choose straightforward solutions first.\n",
    "\n",
    "    ### 4. Complex is better than complicated\n",
    "    When complexity is needed, organize it with clear abstractions.\n",
    "\n",
    "    ### 5. Flat is better than nested\n",
    "    Use early returns to reduce indentation.\n",
    "\n",
    "    ## Modern Python Tie-ins\n",
    "    - Type hints reinforce explicitness\n",
    "    - Context managers enforce safe resource handling\n",
    "    - Dataclasses improve readability for data containers\n",
    "\n",
    "    ## Quick Review Checklist\n",
    "    - Is it readable and explicit?\n",
    "    - Is this the simplest working solution?\n",
    "    - Are errors explicit and logged?\n",
    "    - Are modules/namespaces used appropriately?\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "human_agent_conversations = (\n",
    "  \"\"\"\n",
    "  \"conversations\": [\n",
    "      {\n",
    "        \"id\": \"conv_001\",\n",
    "        \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "        \"topic\": \"async/await patterns\",\n",
    "        \"user_query\": \"I'm building a web scraper that needs to handle thousands of URLs concurrently. What's the best way to structure this with asyncio?\",\n",
    "        \"assistant_response\": \"Use asyncio with aiohttp, a semaphore to cap concurrency, TCPConnector for connection pooling, context managers for session lifecycle, and robust exception handling for failed requests.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"scraper.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"async/await\", \"context_managers\", \"semaphores\", \"aiohttp\", \"error_handling\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I add retry logic for failed requests?\",\n",
    "          \"What's the best way to parse the scraped HTML content?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_002\",\n",
    "        \"timestamp\": \"2024-01-16T14:20:00Z\",\n",
    "        \"topic\": \"dataclass vs pydantic\",\n",
    "        \"user_query\": \"When should I use dataclasses vs Pydantic models? I'm building an API and need to handle user input validation.\",\n",
    "        \"assistant_response\": \"For API input/output, prefer Pydantic: it provides runtime validation, type coercion, JSON serialization, enums for roles, field constraints, and custom validators; integrates cleanly with FastAPI for automatic request validation and error reporting.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"models.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pydantic\", \"dataclasses\", \"validation\", \"fastapi\", \"type_hints\", \"enums\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I handle nested validation with Pydantic?\",\n",
    "          \"Can I use Pydantic with SQLAlchemy models?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_003\",\n",
    "        \"timestamp\": \"2024-01-17T09:15:00Z\",\n",
    "        \"topic\": \"testing patterns\",\n",
    "        \"user_query\": \"I'm struggling with testing async code and database interactions. What's the best approach for pytest with async functions?\",\n",
    "        \"assistant_response\": \"Recommended using pytest-asyncio, async fixtures, and an isolated test database or mocks to reliably test async functions and database interactions in FastAPI.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"test_users.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"pytest\", \"async_testing\", \"fixtures\", \"mocking\", \"database_testing\", \"fastapi_testing\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I test WebSocket connections?\",\n",
    "          \"What's the best way to test database migrations?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_004\",\n",
    "        \"timestamp\": \"2024-01-18T16:45:00Z\",\n",
    "        \"topic\": \"performance optimization\",\n",
    "        \"user_query\": \"My FastAPI app is getting slow with large datasets. How can I optimize database queries and response times?\",\n",
    "        \"assistant_response\": \"Suggested optimizing database queries (indexes, pagination, selecting only needed columns), adding caching, streaming or chunked responses for large datasets, background tasks for heavy work, and monitoring to find bottlenecks.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"optimizations.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"performance_optimization\", \"caching\", \"database_optimization\", \"async_patterns\", \"monitoring\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I implement database connection pooling properly?\",\n",
    "          \"What's the best way to handle memory usage with large datasets?\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"conv_005\",\n",
    "        \"timestamp\": \"2024-01-19T11:30:00Z\",\n",
    "        \"topic\": \"error handling and logging\",\n",
    "        \"user_query\": \"I need to implement proper error handling and logging across my Python application. What's the best approach for production-ready error management?\",\n",
    "        \"assistant_response\": \"Proposed centralized error handling with custom exceptions, structured logging, FastAPI middleware or decorators, and integration points for external monitoring/alerting tools.\",\n",
    "        \"code_context\": {\n",
    "          \"file\": \"error_handling.py\",\n",
    "          \"language\": \"python\",\n",
    "          \"patterns_discussed\": [\"error_handling\", \"logging\", \"exceptions\", \"middleware\", \"decorators\", \"fastapi\"]\n",
    "        },\n",
    "        \"follow_up_questions\": [\n",
    "          \"How do I integrate this with external monitoring tools like Sentry?\",\n",
    "          \"What's the best way to handle errors in background tasks?\"\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "      \"total_conversations\": 5,\n",
    "      \"date_range\": \"2024-01-15 to 2024-01-19\",\n",
    "      \"topics_covered\": [\n",
    "        \"async/await patterns\",\n",
    "        \"dataclass vs pydantic\",\n",
    "        \"testing patterns\",\n",
    "        \"performance optimization\",\n",
    "        \"error handling and logging\"\n",
    "      ],\n",
    "      \"code_patterns_discussed\": [\n",
    "        \"asyncio\", \"aiohttp\", \"semaphores\", \"context_managers\",\n",
    "        \"pydantic\", \"fastapi\", \"type_hints\", \"validation\",\n",
    "        \"pytest\", \"async_testing\", \"fixtures\", \"mocking\",\n",
    "        \"performance_optimization\", \"caching\", \"database_optimization\",\n",
    "        \"error_handling\", \"logging\", \"exceptions\", \"middleware\"\n",
    "      ],\n",
    "      \"difficulty_levels\": {\n",
    "        \"beginner\": 1,\n",
    "        \"intermediate\": 2,\n",
    "        \"advanced\": 2\n",
    "      }\n",
    "    }\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8ae7",
   "metadata": {},
   "source": [
    "## üîÑ Processar Dados em um Grafo de Conhecimento\n",
    "\n",
    "Agora vamos transformar nosso texto bruto em uma mem√≥ria estruturada. Este processo:\n",
    "\n",
    "1. **Adiciona dados aos NodeSets**: Organiza informa√ß√µes em categorias l√≥gicas\n",
    "   - `developer_data`: Perfil do desenvolvedor e conversas\n",
    "   - `principles_data`: Melhores pr√°ticas e diretrizes de Python\n",
    "\n",
    "2. **Executa o Pipeline Cognify**: Extrai entidades, relacionamentos e cria embeddings\n",
    "   - Identifica conceitos-chave\n",
    "   - Cria conex√µes sem√¢nticas entre informa√ß√µes relacionadas\n",
    "   - Gera embeddings vetoriais\n",
    "\n",
    "Isso pode levar alguns momentos enquanto o LLM processa o texto e constr√≥i a estrutura do grafo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.add(developer_intro, node_set=[\"developer_data\"])\n",
    "await cognee.add(human_agent_conversations, node_set=[\"developer_data\"])\n",
    "await cognee.add(python_zen_principles, node_set=[\"principles_data\"])\n",
    "\n",
    "await cognee.cognify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816d20",
   "metadata": {},
   "source": [
    "## üìä Visualizar o Grafo de Conhecimento\n",
    "\n",
    "Vamos explorar a estrutura do nosso grafo de conhecimento. A visualiza√ß√£o mostra:\n",
    "- **N√≥s**: Entidades extra√≠das do texto (conceitos, tecnologias, pessoas)\n",
    "- **Arestas**: Rela√ß√µes e conex√µes entre as entidades\n",
    "- **Agrupamentos**: Conceitos relacionados agrupados por similaridade sem√¢ntica\n",
    "\n",
    "Abra o arquivo HTML gerado no seu navegador para explorar o grafo de forma interativa:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee import visualize_graph\n",
    "await visualize_graph('./visualization_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7365",
   "metadata": {},
   "source": [
    "## üß† Enriquecer a Mem√≥ria com Memify\n",
    "\n",
    "A fun√ß√£o `memify()` analisa o grafo de conhecimento e gera regras inteligentes sobre os dados. Este processo:\n",
    "- Identifica padr√µes e melhores pr√°ticas\n",
    "- Cria diretrizes acion√°veis com base no conte√∫do\n",
    "- Estabelece rela√ß√µes entre diferentes √°reas de conhecimento\n",
    "\n",
    "Essas regras ajudam o agente a tomar decis√µes mais informadas ao responder perguntas. Capturar uma segunda visualiza√ß√£o ajuda a comparar como o grafo se torna mais denso ap√≥s ser enriquecido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "await cognee.memify()\n",
    "\n",
    "await visualize_graph('./visualization_2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0da911",
   "metadata": {},
   "source": [
    "## üîç Parte 2: Recupera√ß√£o Inteligente de Mem√≥ria\n",
    "\n",
    "### Demonstra√ß√£o 1: Integra√ß√£o de Conhecimento entre Documentos\n",
    "\n",
    "Agora que nosso grafo de conhecimento est√° constru√≠do, vamos testar como o Cognee combina informa√ß√µes de v√°rias fontes para responder a perguntas complexas.\n",
    "\n",
    "A primeira consulta demonstra:\n",
    "- **Compreens√£o sem√¢ntica**: Encontrar conceitos relevantes mesmo quando n√£o mencionados explicitamente\n",
    "- **Referenciamento cruzado**: Combinar o perfil do desenvolvedor com os princ√≠pios do Python\n",
    "- **Racioc√≠nio contextual**: Aplicar melhores pr√°ticas a implementa√ß√µes espec√≠ficas\n",
    "\n",
    "### Demonstra√ß√£o 2: Pesquisa Filtrada com NodeSets\n",
    "\n",
    "A segunda consulta mostra como direcionar subconjuntos espec√≠ficos do grafo de conhecimento:\n",
    "- Usa o par√¢metro `node_name` para pesquisar apenas dentro de `principles_data`\n",
    "- Fornece respostas focadas de um dom√≠nio de conhecimento espec√≠fico\n",
    "- √ötil quando voc√™ precisa de informa√ß√µes espec√≠ficas de um dom√≠nio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate cross-document knowledge retrieval from multiple data sources\n",
    "from cognee.modules.search.types import SearchType\n",
    "\n",
    "results = await cognee.search(\n",
    "    query_text=\"How does my AsyncWebScraper implementation align with Python's design principles?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    ")\n",
    "print(\"Python Pattern Analysis:\", results)\n",
    "\n",
    "# demonstrate filtered search using NodeSet to query only specific subsets of memory\n",
    "from cognee.modules.engine.models.node_set import NodeSet\n",
    "results = await cognee.search(\n",
    "    query_text=\"How should variables be named?\",\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    node_type=NodeSet,\n",
    "    node_name=[\"principles_data\"],\n",
    ")\n",
    "print(\"Filtered search result:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dece6",
   "metadata": {},
   "source": [
    "## üîê Parte 3: Configura√ß√£o de Gerenciamento de Sess√£o\n",
    "\n",
    "### Habilitando Mem√≥ria de Conversa√ß√£o\n",
    "\n",
    "O gerenciamento de sess√£o √© essencial para manter o contexto em v√°rias intera√ß√µes. Aqui, vamos:\n",
    "\n",
    "1. **Inicializar o Contexto do Usu√°rio**: Criar ou recuperar um perfil de usu√°rio para rastreamento de sess√£o\n",
    "2. **Configurar o Motor de Cache**: Conectar ao Redis para armazenar o hist√≥rico de conversas\n",
    "3. **Habilitar Vari√°veis de Sess√£o**: Configurar vari√°veis de contexto que persistem entre consultas\n",
    "\n",
    "> ‚ö†Ô∏è **Importante**: Isso requer que o Redis esteja em execu√ß√£o e `CACHING=true` no seu ambiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.context_global_variables import set_session_user_context_variable \n",
    "from cognee.infrastructure.databases.cache import get_cache_engine\n",
    "\n",
    "user = await get_default_user()\n",
    "await set_session_user_context_variable(user)\n",
    "print(f\"Using user id: {getattr(user, 'id', 'unknown')}\")\n",
    "\n",
    "cache_engine = get_cache_engine()\n",
    "if cache_engine is None:\n",
    "    raise RuntimeError('Cache engine is not available. Double-check your cache configuration.')\n",
    "print('Session cache is ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9820b",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Fun√ß√£o Auxiliar: Visualizar Hist√≥rico de Sess√£o\n",
    "\n",
    "Esta fun√ß√£o utilit√°ria permite inspecionar o hist√≥rico de conversas armazenado no Redis. √â √∫til para:\n",
    "- Depurar o gerenciamento de sess√µes\n",
    "- Verificar se as conversas est√£o sendo armazenadas em cache\n",
    "- Entender qual contexto est√° dispon√≠vel para o agente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87384",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_history(session_id: str) -> None:\n",
    "    # Let's check the cache directly\n",
    "    cache_engine = get_cache_engine()\n",
    "    if cache_engine:\n",
    "        # Try to get history directly from cache\n",
    "        user_id = str(user.id) if hasattr(user, 'id') else None\n",
    "        if user_id:\n",
    "            history_entries = await cache_engine.get_latest_qa(user_id, session_id, last_n=10)\n",
    "            print(f\"\\nDirect cache query for user_id={user_id}, session_id={session_id}:\")\n",
    "            print(f\"Found {len(history_entries)} entries\")\n",
    "            if history_entries:\n",
    "                for i, entry in enumerate(history_entries, 1):\n",
    "                    print(f\"\\nEntry {i}:\")\n",
    "                    print(f\"  Question: {entry.get('question', 'N/A')[:100]}...\")\n",
    "                    print(f\"  Answer: {entry.get('answer', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"No user_id available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a744",
   "metadata": {},
   "source": [
    "## Sess√£o 1: Laborat√≥rio de Suporte Ass√≠ncrono ‚Äî Primeira Pergunta\n",
    "\n",
    "Inicie a sess√£o `async-support-lab` perguntando sobre padr√µes de asyncio que sejam compat√≠veis com telemetria para um web scraper em larga escala. O gr√°fico j√° conhece asyncio, aiohttp e pr√°ticas de monitoramento, ent√£o a resposta deve refletir conversas anteriores enquanto adapta a resposta √† nova consulta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6179fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_1 = \"async-support-lab\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"I'm building a web scraper that hits thousands of URLs concurrently. What's a reliable asyncio pattern with telemetry?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bc8c0",
   "metadata": {},
   "source": [
    "## Inspecionar a Mem√≥ria da Sess√£o 1 Ap√≥s a Primeira Troca\n",
    "\n",
    "Executar `show_history(session_1)` imediatamente ap√≥s a pergunta inicial confirma que o Cognee gravou tanto o prompt quanto a resposta no Redis. Voc√™ deve ver uma entrada com a orienta√ß√£o de concorr√™ncia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897156e8",
   "metadata": {},
   "source": [
    "## Sess√£o 1: Acompanhamento sobre Modelos de Dados\n",
    "\n",
    "A seguir, perguntamos: \"Quando devo escolher dataclasses em vez de Pydantic?\" usando o mesmo ID de sess√£o. Cognee deve reunir os princ√≠pios do Python junto com conversas anteriores sobre FastAPI para fornecer conselhos detalhados‚Äîdemonstrando que o contexto √© mantido dentro de uma sess√£o nomeada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"When should I pick dataclasses versus Pydantic for this work?\",\n",
    "    session_id=session_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805b433",
   "metadata": {},
   "source": [
    "## Confirmar que o Hist√≥rico da Sess√£o 1 Cont√©m Ambos os Turnos\n",
    "\n",
    "Outra chamada para `show_history(session_1)` deve revelar duas entradas de perguntas e respostas. Isso corresponde √† etapa de \"replay de mem√≥ria\" do laborat√≥rio Mem0 e prova que turnos adicionais estendem a mesma transcri√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686cbec",
   "metadata": {},
   "source": [
    "## Sess√£o 2: Discuss√£o de Revis√£o de Design ‚Äî Nova Sess√£o\n",
    "\n",
    "Para mostrar isolamento entre as discuss√µes, iniciamos `design-review-session` e solicitamos orienta√ß√µes de registro para revis√µes de incidentes. Embora a base de conhecimento subjacente seja a mesma, o novo ID de sess√£o mant√©m as transcri√ß√µes separadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_2 = \"design-review-session\"\n",
    "\n",
    "result = await cognee.search(\n",
    "    query_type=SearchType.GRAPH_COMPLETION,\n",
    "    query_text=\"We're drafting logging guidance for incident reviews. Capture the key principles please.\",\n",
    "    session_id=session_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c522c7",
   "metadata": {},
   "source": [
    "## Revis√£o da Sess√£o 2 de Hist√≥ria\n",
    "\n",
    "`show_history(session_2)` deve listar apenas o par de prompt/resposta da revis√£o de design. Compare isso com a Sess√£o 1 para destacar como o Cognee mant√©m transcri√ß√µes independentes enquanto reutiliza o grafo de conhecimento compartilhado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "await show_history(session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def225fb",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "Parab√©ns! Voc√™ acabou de dar ao seu assistente de codifica√ß√£o uma camada de mem√≥ria de longo prazo alimentada pelo Cognee.\n",
    "\n",
    "Neste tutorial, voc√™ pegou conte√∫do bruto de desenvolvedores (c√≥digo, documentos, conversas) e o transformou em um gr√°fico + mem√≥ria vetorial que seu agente pode pesquisar, raciocinar e melhorar continuamente.\n",
    "\n",
    "O que Voc√™ Aprendeu\n",
    "\n",
    "1. **De texto bruto para mem√≥ria de IA**: Como o Cognee processa dados n√£o estruturados e os transforma em uma mem√≥ria inteligente e pesquis√°vel usando uma arquitetura combinada de vetor + grafo de conhecimento.\n",
    "\n",
    "2. **Enriquecimento de grafo com memify**: Como ir al√©m da cria√ß√£o b√°sica de grafos e usar o memify para adicionar fatos derivados e relacionamentos mais ricos ao seu grafo existente.\n",
    "\n",
    "3. **M√∫ltiplas estrat√©gias de busca**: Como consultar a mem√≥ria com diferentes tipos de busca (Q&A com consci√™ncia de grafo, conclus√£o no estilo RAG, insights, fragmentos brutos, busca de c√≥digo, etc.) dependendo do que seu agente precisa.\n",
    "\n",
    "4. **Explora√ß√£o visual**: Como inspecionar e depurar o que o Cognee construiu usando visualiza√ß√µes de grafo e a interface do Cognee, para que voc√™ possa realmente ver como o conhecimento est√° estruturado.\n",
    "\n",
    "5. **Mem√≥ria sens√≠vel √† sess√£o**: Como combinar o contexto de cada sess√£o com uma mem√≥ria sem√¢ntica persistente para que os agentes possam lembrar entre execu√ß√µes sem vazar informa√ß√µes entre usu√°rios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959443",
   "metadata": {},
   "source": [
    "## Principais Pontos\n",
    "1. Mem√≥ria como um Grafo de Conhecimento apoiado por Embeddings\n",
    "\n",
    "    - **Compreens√£o estruturada**: Cognee combina um armazenamento vetorial e um armazenamento de grafo, permitindo que seus dados sejam pesquis√°veis por significado e conectados por rela√ß√µes. Por padr√£o, Cognee utiliza bancos de dados baseados em arquivos (LanceDB para vetores, Kuzu para banco de dados de grafos).\n",
    "\n",
    "    - **Recupera√ß√£o consciente de rela√ß√µes**: As respostas podem ser fundamentadas n√£o apenas em \"texto semelhante\", mas tamb√©m em como as entidades se relacionam.\n",
    "\n",
    "    - **Mem√≥ria viva**: A camada de mem√≥ria evolui, cresce e permanece consult√°vel como um grafo conectado.\n",
    "\n",
    "2. Modos de Busca e Racioc√≠nio\n",
    "    - **Recupera√ß√£o h√≠brida**: A busca combina similaridade vetorial, estrutura de grafo e racioc√≠nio de LLM, desde a busca de fragmentos brutos at√© respostas a perguntas conscientes do grafo.\n",
    "\n",
    "    - **Ajuste o modo ao trabalho**: Use modos de estilo de conclus√£o quando quiser respostas em linguagem natural, e modos de fragmento/resumo/grafo quando seu agente precisar de contexto bruto ou conduzir seu pr√≥prio racioc√≠nio.\n",
    "\n",
    "3. Agentes Personalizados e Conscientes de Sess√£o\n",
    "    - **Contexto de sess√£o + mem√≥ria de longo prazo**: Cognee mant√©m o contexto de \"thread\" de curto prazo separado da mem√≥ria de longo prazo, seja no n√≠vel do usu√°rio ou da organiza√ß√£o.\n",
    "\n",
    "## Aplica√ß√µes no Mundo Real\n",
    "\n",
    "1. **Agentes de IA Verticais**\n",
    "\n",
    "    Use o padr√£o deste notebook para criar copilotos inteligentes em dom√≠nios espec√≠ficos que utilizam Cognee como n√∫cleo de recupera√ß√£o e racioc√≠nio:\n",
    "\n",
    "- **Copilotos para desenvolvedores**: Assistentes de revis√£o de c√≥digo, an√°lise de incidentes e arquitetura que percorrem c√≥digo, APIs, documentos de design e tickets como um √∫nico grafo de mem√≥ria.\n",
    "\n",
    "- **Copilotos voltados para clientes**: Agentes de suporte ou sucesso que acessam documentos de produtos, FAQs, notas de CRM e tickets anteriores com recupera√ß√£o consciente de grafo e respostas citadas.\n",
    "\n",
    "- **Copilotos especialistas internos**: Assistentes de pol√≠tica, jur√≠dico ou seguran√ßa que raciocinam sobre regras interconectadas, diretrizes e decis√µes hist√≥ricas, em vez de PDFs isolados.\n",
    "\n",
    "    Cognee √© explicitamente posicionado como mem√≥ria persistente e precisa para agentes de IA, fornecendo um grafo de conhecimento vivo que se integra ao seu agente e substitui combina√ß√µes ad hoc de armazenamentos vetoriais e c√≥digo de grafo personalizado.\n",
    "\n",
    "2. **Unificando Silos de Dados em Uma Mem√≥ria**\n",
    "\n",
    "    A mesma abordagem tamb√©m ajuda a construir uma camada de mem√≥ria unificada a partir de fontes dispersas:\n",
    "\n",
    "- **De silos para um grafo √∫nico**: Ingest√£o de dados estruturados (por exemplo, bancos de dados) e n√£o estruturados (por exemplo, documentos, chats) em um √∫nico grafo apoiado por embeddings, em vez de √≠ndices separados para cada sistema.\n",
    "\n",
    "- **Racioc√≠nio entre fontes com cita√ß√µes**: Execute racioc√≠nio em v√°rias etapas sobre tudo‚Äî\"una\" logs, m√©tricas e documentos via o grafo‚Äîe ainda assim retorne respostas fundamentadas com proveni√™ncia.\n",
    "\n",
    "- **Hubs de conhecimento**: Para dom√≠nios como bancos ou educa√ß√£o, Cognee j√° √© usado para unificar PDFs, sistemas internos e dados de aplicativos em um grafo de conhecimento com vetores, permitindo que agentes respondam perguntas com contexto preciso e citado.\n",
    "\n",
    "## Pr√≥ximos Passos\n",
    "\n",
    "Voc√™ implementou o n√∫cleo do loop de mem√≥ria. Aqui est√£o extens√µes naturais que voc√™ pode experimentar por conta pr√≥pria (veja [documenta√ß√£o do Cognee](https://docs.cognee.ai/) para detalhes):\n",
    "\n",
    "1. **Experimente a consci√™ncia temporal**: Ative o \"temporal cognify\" para extrair eventos e marcas de tempo do texto.\n",
    "\n",
    "2. **Introduza racioc√≠nio baseado em ontologia**: Defina uma ontologia OWL para seu dom√≠nio. Use o suporte de ontologia do Cognee para que entidades e rela√ß√µes extra√≠das sejam fundamentadas nesse esquema, melhorando a qualidade do grafo e respostas espec√≠ficas do dom√≠nio.\n",
    "\n",
    "3. **Adicione um loop de feedback**: Permita que o Cognee ajuste os pesos das arestas do grafo com base no feedback real dos usu√°rios, para que a recupera√ß√£o melhore ao longo do tempo em vez de permanecer est√°tica.\n",
    "\n",
    "4. **Ajuste para personaliza√ß√£o e comportamento de sess√£o**: Use IDs de usu√°rios, locat√°rios e conjuntos de dados para oferecer a cada pessoa ou equipe sua pr√≥pria vis√£o sobre o motor de mem√≥ria compartilhado.\n",
    "\n",
    "5. **Expanda para agentes mais complexos**: Conecte o Cognee a frameworks de agentes para construir sistemas multiagentes que compartilhem a mesma camada de mem√≥ria. *Microsoft Agent Framework x Cognee plugin est√° chegando em breve.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "coopTranslator": {
   "original_hash": "8f66e98ab87f8d72c25e5525d85710a1",
   "translation_date": "2025-12-09T13:48:40+00:00",
   "source_file": "13-agent-memory/13-agent-memory-cognee.ipynb",
   "language_code": "br"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}